[
  {
    "objectID": "Themen/10/penguins.html",
    "href": "Themen/10/penguins.html",
    "title": "Einführung in R Markdown - Penguins",
    "section": "",
    "text": "#install.packages(\"palmerpenguins\")\n#install.packages(c(\"palmerpenguins\", \"ggplot2\", \"dplyr\", \"knitr\", \"DHARMa\", \"emmeans\", \"multcompView\", \"multcomp\", \"broom\", \"pander\"))"
  },
  {
    "objectID": "Themen/10/penguins.html#pakete-laden",
    "href": "Themen/10/penguins.html#pakete-laden",
    "title": "Einführung in R Markdown - Penguins",
    "section": "Pakete laden",
    "text": "Pakete laden\n\nlibrary(palmerpenguins)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(DHARMa)\nlibrary(emmeans)\nlibrary(multcompView)\nlibrary(multcomp)\nlibrary(broom)\nlibrary(pander)"
  },
  {
    "objectID": "Themen/10/penguins.html#daten-laden",
    "href": "Themen/10/penguins.html#daten-laden",
    "title": "Einführung in R Markdown - Penguins",
    "section": "Daten laden",
    "text": "Daten laden\n\ndata(penguins)\ndf=penguins"
  },
  {
    "objectID": "Themen/10/penguins.html#struktur-prüfen-daten-kennenlernen",
    "href": "Themen/10/penguins.html#struktur-prüfen-daten-kennenlernen",
    "title": "Einführung in R Markdown - Penguins",
    "section": "Struktur prüfen & Daten kennenlernen",
    "text": "Struktur prüfen & Daten kennenlernen\n\nstr(df)\nsummary(df)\n\nWir haben 344 Beobachtungen.\nWir haben 344 Beobachtungen.\n\n3 Faktoren\n5 kontinuierliche Variablen\n3 Arten\n3 Inseln\nMissing values\n\n\ncolSums(is.na(df))\ndf &lt;- df %&gt;%\n  mutate(species = factor(species, levels = c(\"Chinstrap\", \"Gentoo\", \"Adelie\")))\ndf1 = df %&gt;% filter(complete.cases(.))\ndf2 = df %&gt;% filter(complete.cases(body_mass_g))\ndf %&gt;%\n  count(species, island)\n\n\nTabelle Summary Statistics\n\ndf %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = sum(!is.na(body_mass_g)),\n    mean_body_mass_g = round(mean(body_mass_g, na.rm = TRUE), 1),\n    sd_body_mass_g   = round(sd(body_mass_g, na.rm = TRUE), 1),\n    median_body_mass_g = round(median(body_mass_g, na.rm = TRUE), 1),\n    min_body_mass_g  = min(body_mass_g, na.rm = TRUE),\n    max_body_mass_g  = max(body_mass_g, na.rm = TRUE)\n  )\n\n# A tibble: 3 × 7\n  species       n mean_body_mass_g sd_body_mass_g median_body_mass_g\n  &lt;fct&gt;     &lt;int&gt;            &lt;dbl&gt;          &lt;dbl&gt;              &lt;dbl&gt;\n1 Chinstrap    68            3733.           384.               3700\n2 Gentoo      123            5076            504.               5000\n3 Adelie      151            3701.           459.               3700\n# ℹ 2 more variables: min_body_mass_g &lt;int&gt;, max_body_mass_g &lt;int&gt;\n\n\nmit library(knitr) und der Funktion kable()\n\ndf %&gt;%\n  group_by(species) %&gt;%\n  summarise(\n    n = sum(!is.na(body_mass_g)),\n    mean_body_mass_g = round(mean(body_mass_g, na.rm = TRUE), 1),\n    sd_body_mass_g   = round(sd(body_mass_g, na.rm = TRUE), 1),\n    median_body_mass_g = round(median(body_mass_g, na.rm = TRUE), 1),\n    min_body_mass_g  = min(body_mass_g, na.rm = TRUE),\n    max_body_mass_g  = max(body_mass_g, na.rm = TRUE)\n  ) %&gt;%\n  kable(\n    caption = \"Zusammenfassung der Körpermasse pro Pinguinart (in g)\",\n    col.names = c(\"Art\", \"n\", \"Mittelwert\", \"StdAbw\", \"Median\", \"Min\", \"Max\")\n  )\n\n\nZusammenfassung der Körpermasse pro Pinguinart (in g)\n\n\nArt\nn\nMittelwert\nStdAbw\nMedian\nMin\nMax\n\n\n\n\nChinstrap\n68\n3733.1\n384.3\n3700\n2700\n4800\n\n\nGentoo\n123\n5076.0\n504.1\n5000\n3950\n6300\n\n\nAdelie\n151\n3700.7\n458.6\n3700\n2850\n4775\n\n\n\n\n\n\n\nAbbildungen\n\nggplot(df, aes(x = species, y = body_mass_g, fill = species)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.3)+\n  geom_boxplot(outlier.shape=NA, width=0.5) +\n  geom_jitter(width=0.1, height=0, shape=16, alpha=0.5)+\n  stat_summary(fun = \"mean\", colour = 1, fill=\"grey\", size = 1, shape=21) +\n  scale_y_sqrt()+\n  scale_fill_manual(values = species_colors)+\n  labs(x = \"Art\",\n       y = \"Körpergewicht (g)\") +\n  theme_bw()+\n  theme(legend.position = \"none\")\n\n\n\n\nAbb. 1: Körpergewicht je Pinguinart"
  },
  {
    "objectID": "Themen/10/penguins.html#anova",
    "href": "Themen/10/penguins.html#anova",
    "title": "Einführung in R Markdown - Penguins",
    "section": "ANOVA",
    "text": "ANOVA\n\nModell formulieren\n\nmod&lt;-lm(sqrt(body_mass_g) ~ species, data=df)\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: sqrt(body_mass_g)\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspecies     2 8437.2  4218.6  331.93 &lt; 2.2e-16 ***\nResiduals 339 4308.4    12.7                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(mod)\n\n\nCall:\nlm(formula = sqrt(body_mass_g) ~ species, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.0578 -2.6022 -0.1917  2.5277  8.3836 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    61.0193     0.4323 141.144   &lt;2e-16 ***\nspeciesGentoo  10.1394     0.5387  18.821   &lt;2e-16 ***\nspeciesAdelie  -0.3015     0.5206  -0.579    0.563    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.565 on 339 degrees of freedom\n  (2 Beobachtungen als fehlend gelöscht)\nMultiple R-squared:  0.662, Adjusted R-squared:   0.66 \nF-statistic: 331.9 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nModellannahmen prüfen\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df2$species)# NAs in df, besser gleich mit df2 rechnen\n\n\n\n\n\n\n\n\n\n\nModell interpretieren\n\ngeschätzte Koeffizienten\n\nmod%&gt;%\n  tidy() %&gt;%\n  kable(col.names = c(\"Predictor\", \"Est\", \"SE\", \"t\", \"p-value\"),\n               digits=c(0,2,2,1,4))\n\n\n\n\nPredictor\nEst\nSE\nt\np-value\n\n\n\n\n(Intercept)\n61.02\n0.43\n141.1\n0.0000\n\n\nspeciesGentoo\n10.14\n0.54\n18.8\n0.0000\n\n\nspeciesAdelie\n-0.30\n0.52\n-0.6\n0.5629\n\n\n\n\n\nDie Modellkoeffizienten beziehen sich auf das wurzel-transformierte Körpergewicht in g. Das R² des Modells beträgt 66.2.\n\n\nPostHoc-Test\n\nCIs=cld(emmeans(mod, ~species, type=\"response\"), adjust=\"sidak\", sort = FALSE, Letters=letters)\nCIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert\n\n[1] \" a \" \"  b\" \" a \"\n\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen\nCIs$.group # besser\n\n[1] \"a\" \"b\" \"a\"\n\nstr(CIs)\n\nClasses 'summary_emm' and 'data.frame': 3 obs. of  7 variables:\n $ species : Factor w/ 3 levels \"Chinstrap\",\"Gentoo\",..: 1 2 3\n $ response: num  3723 5064 3687\n $ SE      : num  52.8 45.7 35.2\n $ df      : num  339 339 339\n $ lower.CL: num  3598 4954 3603\n $ upper.CL: num  3851 5174 3772\n $ .group  : chr  \"a\" \"b\" \"a\"\n - attr(*, \"estName\")= chr \"response\"\n - attr(*, \"clNames\")= chr [1:2] \"lower.CL\" \"upper.CL\"\n - attr(*, \"pri.vars\")= chr \"species\"\n - attr(*, \"adjust\")= chr \"sidak\"\n - attr(*, \"side\")= num 0\n - attr(*, \"delta\")= num 0\n - attr(*, \"type\")= chr \"response\"\n - attr(*, \"mesg\")= chr [1:7] \"Confidence level used: 0.95\" \"Conf-level adjustment: sidak method for 3 estimates\" \"Intervals are back-transformed from the sqrt scale\" \"Note: contrasts are still on the sqrt scale. Consider using\\n      regrid() if you want contrasts of back-trans\"| __truncated__ ...\n - attr(*, \"linkname\")= chr \"sqrt\"\n\nCIs\n\n species   response   SE  df lower.CL upper.CL .group\n Chinstrap     3723 52.8 339     3598     3851 a     \n Gentoo        5064 45.7 339     4954     5174 b     \n Adelie        3687 35.2 339     3603     3772 a     \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\nCIp=data.frame(pairs(regrid(emmeans(mod, ~species)), adjust=\"sidak\"))\nCIp\n\n            contrast    estimate       SE  df     t.ratio  p.value\n1 Chinstrap - Gentoo -1340.20744 69.83099 339 -19.1921594 0.000000\n2 Chinstrap - Adelie    36.70404 63.44083 339   0.5785555 0.916703\n3    Gentoo - Adelie  1376.91148 57.74053 339  23.8465335 0.000000\n\n\n\n\nAbbildung Daten und geschätzte Mittelwerte und Konfidenzintervall\n\nggplot(df, aes(x = species, y = body_mass_g, fill = species)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.3)+\n  geom_boxplot(outlier.shape=NA, width=0.5) +\n  geom_jitter(width=0.1, height=0, shape=16, alpha=0.5)+\n  geom_errorbar(data=CIs, aes(y=response, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=\"grey50\", position = position_nudge(x = 0.4))+\n  geom_point(data=CIs, aes(y=response), \n             shape=16,  size=2, col=\"grey50\", \n             position = position_nudge(x = 0.4))+\n    geom_text(data=CIs, aes(y = 7000, label =.group))+\n  scale_y_sqrt()+\n  scale_fill_manual(values = species_colors)+\n  labs(x = \"Art\",\n       y = \"Körpergewicht (g)\") +\n  theme_bw()+\n  theme(legend.position = \"none\")\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\nRemoved 2 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nAbb. 1: Körpergewicht je Pinguinart\n\n\n\n\nDie geschätzten mittleren Körpermassen (mit 95%-Konfidenzintervallen) sind:\n\nkable(CIs[,c(1,2,5,6)], caption = \"Geschätztes mittlere Körpergewicht pro Art (g) .\",\n      col.names = c(\"Art\", \"geschätzter Mittelwert\", \"Untere 95%-Konfidenzgrenze\", \"Obere 95%-Konfidenzgrenze\"))\n\n\nGeschätztes mittlere Körpergewicht pro Art (g) .\n\n\n\n\n\n\n\n\nArt\ngeschätzter Mittelwert\nUntere 95%-Konfidenzgrenze\nObere 95%-Konfidenzgrenze\n\n\n\n\nChinstrap\n3723.358\n3597.833\n3851.036\n\n\nGentoo\n5063.565\n4954.386\n5173.935\n\n\nAdelie\n3686.654\n3602.600\n3771.677\n\n\n\n\n\nOder wir schreiben im Text:\nWir sehen, dass die Gentoo-Pinguine mit einem durchschnittlichen Körpergewicht von etwa 5064 g signifikant schwerer sind als Adelie (p &lt; 0.0001) und Chinstrap (p &lt; 0.0001) Pinguine, welche ein durchschnittliches Körpergewicht von rund 3687 g und 3723 g aufweisen. Adelie und Chinstrap unterscheiden sich nicht signifikant (p = 0.92).\nDank an “Artwork by @allison_horst”.\n\n\ncitation(\"palmerpenguins\")\n\nTo cite palmerpenguins in publications use:\n\n  Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer\n  Archipelago (Antarctica) penguin data. R package version 0.1.0.\n  https://allisonhorst.github.io/palmerpenguins/. doi:\n  10.5281/zenodo.3960218.\n\nEin BibTeX-Eintrag für LaTeX-Benutzer ist\n\n  @Manual{,\n    title = {palmerpenguins: Palmer Archipelago (Antarctica) penguin data},\n    author = {Allison Marie Horst and Alison Presmanes Hill and Kristen B Gorman},\n    year = {2020},\n    note = {R package version 0.1.0},\n    doi = {10.5281/zenodo.3960218},\n    url = {https://allisonhorst.github.io/palmerpenguins/},\n  }\n\n\nAbschließende sessionInfo\n\nsessionInfo()\n\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19044)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   \n[3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.utf8    \n\ntime zone: Europe/Berlin\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] pander_0.6.6         broom_1.0.10         multcomp_1.4-29     \n [4] TH.data_1.1-3        MASS_7.3-65          survival_3.8-3      \n [7] mvtnorm_1.3-3        multcompView_0.1-10  emmeans_2.0.0       \n[10] DHARMa_0.4.7         knitr_1.50           dplyr_1.1.4         \n[13] ggplot2_4.0.0        palmerpenguins_0.1.1\n\nloaded via a namespace (and not attached):\n [1] utf8_1.2.6         tidyr_1.3.1        sandwich_3.1-1     generics_0.1.4    \n [5] lattice_0.22-7     lme4_1.1-37        digest_0.6.37      magrittr_2.0.3    \n [9] evaluate_1.0.5     grid_4.5.1         estimability_1.5.1 RColorBrewer_1.1-3\n[13] fastmap_1.2.0      jsonlite_2.0.0     Matrix_1.7-3       backports_1.5.0   \n[17] purrr_1.1.0        scales_1.4.0       codetools_0.2-20   reformulas_0.4.1  \n[21] Rdpack_2.6.4       cli_3.6.5          rlang_1.1.6        rbibutils_2.3     \n[25] splines_4.5.1      withr_3.0.2        yaml_2.3.10        tools_4.5.1       \n[29] nloptr_2.2.1       coda_0.19-4.1      minqa_1.2.8        gap.datasets_0.0.6\n[33] boot_1.3-32        vctrs_0.6.5        R6_2.6.1           zoo_1.8-14        \n[37] lifecycle_1.0.4    htmlwidgets_1.6.4  pkgconfig_2.0.3    pillar_1.11.0     \n[41] gtable_0.3.6       glue_1.8.0         Rcpp_1.1.0         xfun_0.52         \n[45] tibble_3.3.0       tidyselect_1.2.1   rstudioapi_0.17.1  xtable_1.8-4      \n[49] farver_2.1.2       htmltools_0.5.8.1  nlme_3.1-168       labeling_0.4.3    \n[53] rmarkdown_2.29     compiler_4.5.1     gap_1.6            S7_0.2.0"
  },
  {
    "objectID": "Themen/10/10_RMark.html",
    "href": "Themen/10/10_RMark.html",
    "title": "R Markdown",
    "section": "",
    "text": "https://raw.githubusercontent.com/rstudio/cheatsheets/main/translations/german/rmarkdown_de.pdf\n\nhttps://posit.co/wp-content/uploads/2022/10/rmarkdown-1.pdf\n\nhttps://bookdown.org/yihui/rmarkdown-cookbook/"
  },
  {
    "objectID": "Themen/10/10_RMark.html#infos-im-netz",
    "href": "Themen/10/10_RMark.html#infos-im-netz",
    "title": "R Markdown",
    "section": "",
    "text": "https://raw.githubusercontent.com/rstudio/cheatsheets/main/translations/german/rmarkdown_de.pdf\n\nhttps://posit.co/wp-content/uploads/2022/10/rmarkdown-1.pdf\n\nhttps://bookdown.org/yihui/rmarkdown-cookbook/"
  },
  {
    "objectID": "Themen/10/10_RMark.html#rmd-files-für-den-kurs",
    "href": "Themen/10/10_RMark.html#rmd-files-für-den-kurs",
    "title": "R Markdown",
    "section": "Rmd-Files für den Kurs",
    "text": "Rmd-Files für den Kurs\nFolgende R Pakete benötigst Du für den Kurs.\n\ninstall.packages(c(\"palmerpenguins\", \"ggplot2\", \"dplyr\", \"knitr\", \"DHARMa\", \"emmeans\", \"multcompView\", \"multcomp\", \"broom\", \"pander\"))\n\nHier kannst du die Skripte und Dateien für den Kurs herunterladen.\nEinfuehrung_in_R_Markdown_V03.Rmd\npenguins.Rmd\npenguins.png\nWord Art RMarkdown.png"
  },
  {
    "objectID": "Themen/08/08_2f_LM.html",
    "href": "Themen/08/08_2f_LM.html",
    "title": "Analysis of two-factorial experiments with general linear (mixed effect) models",
    "section": "",
    "text": "library(ggplot2)# plotting\nlibrary(dplyr)# data management and summary statistics\nlibrary(ggpubr)# plotting\nlibrary(openxlsx)# import and export Excel files\nlibrary(forcats)# factor repordering\nlibrary(DHARMa) # model diagnostics\nlibrary(emmeans) # posthoc tests\nlibrary(multcomp) # cld\nlibrary(multcompView) #cld\nlibrary(glmmTMB) # mixed model\nlibrary(car) # anova for glmmTMB\nlibrary(lme4) # lmer and glmer mixed model\nlibrary(lmerTest) # test lmer\nlibrary(conflicted)\nconflicts_prefer(lmerTest::lmer)\n# Suppress summarise info\noptions(dplyr.summarise.inform = FALSE)\nSuppose we have a complete randomized design with three nitrogen fertilisation levels N (low, medium, high) and four genotypes geno (g1, g2, g3 and g4) and five replications rep. For each treatment crop yield yield was measured.\nThe research question is: Do yields differ between genotypes and nitrogen fertilisation? In particular, do genotypes respond differently to different nitrogen fertilisation?"
  },
  {
    "objectID": "Themen/08/08_2f_LM.html#linear-model-anova",
    "href": "Themen/08/08_2f_LM.html#linear-model-anova",
    "title": "Analysis of two-factorial experiments with general linear (mixed effect) models",
    "section": "Linear model (Anova)",
    "text": "Linear model (Anova)\nWe fit a linear model with yield as response and geno and N as explanatory variables. It is important that the dependent variable is continuous and the explanatory variables are factors. By using geno * N, we fit the main effect and interaction.\n\nmodel &lt;- lm(yield ~ geno * N, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = yield ~ geno * N, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.1180  -3.7234   0.0388   3.9731   9.9417 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   62.4910     2.5157  24.840  &lt; 2e-16 ***\ngenog2        -3.2606     3.5578  -0.916  0.36400    \ngenog3         1.4225     3.5578   0.400  0.69106    \ngenog4        -0.9117     3.5578  -0.256  0.79885    \nNmed           6.2378     3.5578   1.753  0.08594 .  \nNhigh         20.3527     3.5578   5.721 6.68e-07 ***\ngenog2:Nmed    1.1303     5.0315   0.225  0.82321    \ngenog3:Nmed    6.0655     5.0315   1.206  0.23392    \ngenog4:Nmed    2.0285     5.0315   0.403  0.68862    \ngenog2:Nhigh  10.9283     5.0315   2.172  0.03483 *  \ngenog3:Nhigh  -3.7315     5.0315  -0.742  0.46193    \ngenog4:Nhigh  14.9123     5.0315   2.964  0.00472 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.625 on 48 degrees of freedom\nMultiple R-squared:  0.8421,    Adjusted R-squared:  0.8059 \nF-statistic: 23.28 on 11 and 48 DF,  p-value: 1.381e-15\n\n\nBefore interpreting the model, we perform model diagnostics by plotting residuals against fitted values and explanatory variables.\nWe visually check the assumptions of the ANOVA for\n\napproximate normal distribution of errors (i.e. residuals)\nhomogeneity of variance\n\nI use the library(DHARMa) for this. https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\n\nThe first graph shows a QQ plot of the standardised residuals, which provides us with information about the normal distribution of the residuals. If the points lie approximately along the bisector (red line), this indicates that the residuals are approximately normally distributed. We are also shown p-values for the KS test (Kolmogorov-Smirnov test for normal distribution), a dispersion test and an outlier test.\nThe second graph plots the ‘residuals’ against the ‘fitted values’. We want to see here that the dispersion around 0.5 is approximately the same for both high and low values (variance homogeneity). The plot is also helpful for identifying peculiar samples. These are shown as red asterisks (but do not necessarily have to be labelled as outliers).\nTo check the variance homogeneity between the groups, we should plot the residuals against the explanatory variables.\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\n\nAs long as all tests are not significant (and no red lines or boxes are displayed), everything is (more or less) fine. BUT it should be noted that the power of the tests depends on the number of observations. The more observations we have, the higher the power of the test. This means that significant differences, e.g. in the variances, are often observed with a large sample size, although these are practically irrelevant. In addition, significant differences are often not observed with a small sample size, although there are significant differences.\nThe visual model diagnostics are therefore often regarded as more important than the p-value-based tests for normal distribution and variance homogeneity (Cochran, Bartlett and Levenes test).\n\nTest of significance and posthoc tests\n\nanova(model)\n\nAnalysis of Variance Table\n\nResponse: yield\n          Df Sum Sq Mean Sq  F value    Pr(&gt;F)    \ngeno       3  195.6    65.2   2.0602 0.1179439    \nN          2 6955.4  3477.7 109.8981 &lt; 2.2e-16 ***\ngeno:N     6  951.5   158.6   5.0114 0.0004664 ***\nResiduals 48 1518.9    31.6                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe have a significant interaction between genotype and nitrogen fertilisation, but we do not know which treatments differ from each other and we also do not know anything about the effect sizes, e.g. the difference in yield between low and medium nitrogen fertilisation for geno g1.\nThe library(emmeans) with the function emmeans() offers a variety of possibilities to perform a posthoc test on the fitted model and calculate confidence intervals.\n\nemmeans(model, ~geno*N)\n\n geno N    emmean   SE df lower.CL upper.CL\n g1   low    62.5 2.52 48     57.4     67.5\n g2   low    59.2 2.52 48     54.2     64.3\n g3   low    63.9 2.52 48     58.9     69.0\n g4   low    61.6 2.52 48     56.5     66.6\n g1   med    68.7 2.52 48     63.7     73.8\n g2   med    66.6 2.52 48     61.5     71.7\n g3   med    76.2 2.52 48     71.2     81.3\n g4   med    69.8 2.52 48     64.8     74.9\n g1   high   82.8 2.52 48     77.8     87.9\n g2   high   90.5 2.52 48     85.5     95.6\n g3   high   80.5 2.52 48     75.5     85.6\n g4   high   96.8 2.52 48     91.8    101.9\n\nConfidence level used: 0.95 \n\n\nWith the argument method=‘pairwise’ you can compare all treatments with each other using Tukey test.\n\ncontrast(emmeans(model, ~geno*N), method=\"pairwise\")\n\n contrast          estimate   SE df t.ratio p.value\n g1 low - g2 low      3.261 3.56 48   0.916  0.9986\n g1 low - g3 low     -1.423 3.56 48  -0.400  1.0000\n g1 low - g4 low      0.912 3.56 48   0.256  1.0000\n g1 low - g1 med     -6.238 3.56 48  -1.753  0.8340\n g1 low - g2 med     -4.107 3.56 48  -1.155  0.9900\n g1 low - g3 med    -13.726 3.56 48  -3.858  0.0159\n g1 low - g4 med     -7.355 3.56 48  -2.067  0.6470\n g1 low - g1 high   -20.353 3.56 48  -5.721  &lt;.0001\n g1 low - g2 high   -28.020 3.56 48  -7.876  &lt;.0001\n g1 low - g3 high   -18.044 3.56 48  -5.072  0.0004\n g1 low - g4 high   -34.353 3.56 48  -9.656  &lt;.0001\n g2 low - g3 low     -4.683 3.56 48  -1.316  0.9728\n g2 low - g4 low     -2.349 3.56 48  -0.660  0.9999\n g2 low - g1 med     -9.498 3.56 48  -2.670  0.2722\n g2 low - g2 med     -7.368 3.56 48  -2.071  0.6445\n g2 low - g3 med    -16.986 3.56 48  -4.774  0.0010\n g2 low - g4 med    -10.615 3.56 48  -2.984  0.1454\n g2 low - g1 high   -23.613 3.56 48  -6.637  &lt;.0001\n g2 low - g2 high   -31.281 3.56 48  -8.792  &lt;.0001\n g2 low - g3 high   -21.304 3.56 48  -5.988  &lt;.0001\n g2 low - g4 high   -37.614 3.56 48 -10.572  &lt;.0001\n g3 low - g4 low      2.334 3.56 48   0.656  0.9999\n g3 low - g1 med     -4.815 3.56 48  -1.353  0.9668\n g3 low - g2 med     -2.685 3.56 48  -0.755  0.9998\n g3 low - g3 med    -12.303 3.56 48  -3.458  0.0470\n g3 low - g4 med     -5.932 3.56 48  -1.667  0.8738\n g3 low - g1 high   -18.930 3.56 48  -5.321  0.0002\n g3 low - g2 high   -26.598 3.56 48  -7.476  &lt;.0001\n g3 low - g3 high   -16.621 3.56 48  -4.672  0.0013\n g3 low - g4 high   -32.931 3.56 48  -9.256  &lt;.0001\n g4 low - g1 med     -7.150 3.56 48  -2.010  0.6849\n g4 low - g2 med     -5.019 3.56 48  -1.411  0.9557\n g4 low - g3 med    -14.638 3.56 48  -4.114  0.0075\n g4 low - g4 med     -8.266 3.56 48  -2.323  0.4750\n g4 low - g1 high   -21.264 3.56 48  -5.977  &lt;.0001\n g4 low - g2 high   -28.932 3.56 48  -8.132  &lt;.0001\n g4 low - g3 high   -18.955 3.56 48  -5.328  0.0002\n g4 low - g4 high   -35.265 3.56 48  -9.912  &lt;.0001\n g1 med - g2 med      2.130 3.56 48   0.599  1.0000\n g1 med - g3 med     -7.488 3.56 48  -2.105  0.6220\n g1 med - g4 med     -1.117 3.56 48  -0.314  1.0000\n g1 med - g1 high   -14.115 3.56 48  -3.967  0.0116\n g1 med - g2 high   -21.783 3.56 48  -6.122  &lt;.0001\n g1 med - g3 high   -11.806 3.56 48  -3.318  0.0668\n g1 med - g4 high   -28.115 3.56 48  -7.902  &lt;.0001\n g2 med - g3 med     -9.618 3.56 48  -2.703  0.2558\n g2 med - g4 med     -3.247 3.56 48  -0.913  0.9987\n g2 med - g1 high   -16.245 3.56 48  -4.566  0.0019\n g2 med - g2 high   -23.913 3.56 48  -6.721  &lt;.0001\n g2 med - g3 high   -13.936 3.56 48  -3.917  0.0134\n g2 med - g4 high   -30.246 3.56 48  -8.501  &lt;.0001\n g3 med - g4 med      6.371 3.56 48   1.791  0.8148\n g3 med - g1 high    -6.627 3.56 48  -1.863  0.7752\n g3 med - g2 high   -14.295 3.56 48  -4.018  0.0100\n g3 med - g3 high    -4.318 3.56 48  -1.214  0.9852\n g3 med - g4 high   -20.627 3.56 48  -5.798  &lt;.0001\n g4 med - g1 high   -12.998 3.56 48  -3.653  0.0280\n g4 med - g2 high   -20.666 3.56 48  -5.809  &lt;.0001\n g4 med - g3 high   -10.689 3.56 48  -3.004  0.1389\n g4 med - g4 high   -26.999 3.56 48  -7.589  &lt;.0001\n g1 high - g2 high   -7.668 3.56 48  -2.155  0.5879\n g1 high - g3 high    2.309 3.56 48   0.649  0.9999\n g1 high - g4 high  -14.001 3.56 48  -3.935  0.0127\n g2 high - g3 high    9.977 3.56 48   2.804  0.2108\n g2 high - g4 high   -6.333 3.56 48  -1.780  0.8204\n g3 high - g4 high  -16.310 3.56 48  -4.584  0.0018\n\nP value adjustment: tukey method for comparing a family of 12 estimates \n\n\nHowever, these are quite a few comparisons and we may not want to compare all possible combinations, but rather be interested in how each genotype responds in yield to increasing nitrogen fertilisation.\n\ncontrast(emmeans(model, ~N|geno), method=\"pairwise\", infer=c(T,T)) \n\ngeno = g1:\n contrast   estimate   SE df lower.CL upper.CL t.ratio p.value\n low - med     -6.24 3.56 48    -14.8    2.367  -1.753  0.1963\n low - high   -20.35 3.56 48    -29.0  -11.748  -5.721  &lt;.0001\n med - high   -14.11 3.56 48    -22.7   -5.510  -3.967  0.0007\n\ngeno = g2:\n contrast   estimate   SE df lower.CL upper.CL t.ratio p.value\n low - med     -7.37 3.56 48    -16.0    1.236  -2.071  0.1067\n low - high   -31.28 3.56 48    -39.9  -22.676  -8.792  &lt;.0001\n med - high   -23.91 3.56 48    -32.5  -15.308  -6.721  &lt;.0001\n\ngeno = g3:\n contrast   estimate   SE df lower.CL upper.CL t.ratio p.value\n low - med    -12.30 3.56 48    -20.9   -3.699  -3.458  0.0032\n low - high   -16.62 3.56 48    -25.2   -8.017  -4.672  0.0001\n med - high    -4.32 3.56 48    -12.9    4.287  -1.214  0.4510\n\ngeno = g4:\n contrast   estimate   SE df lower.CL upper.CL t.ratio p.value\n low - med     -8.27 3.56 48    -16.9    0.338  -2.323  0.0621\n low - high   -35.26 3.56 48    -43.9  -26.660  -9.912  &lt;.0001\n med - high   -27.00 3.56 48    -35.6  -18.394  -7.589  &lt;.0001\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 3 estimates \nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nHere we see the difference between the treatment levels for each genotype (estimate), the confidence interval of the difference (if it does not include the 0 we usually have significant differences) and the p.value.\nThe emmean is the predicted value for each treatment level.\n\nemmeans(model, ~N|geno)\n\ngeno = g1:\n N    emmean   SE df lower.CL upper.CL\n low    62.5 2.52 48     57.4     67.5\n med    68.7 2.52 48     63.7     73.8\n high   82.8 2.52 48     77.8     87.9\n\ngeno = g2:\n N    emmean   SE df lower.CL upper.CL\n low    59.2 2.52 48     54.2     64.3\n med    66.6 2.52 48     61.5     71.7\n high   90.5 2.52 48     85.5     95.6\n\ngeno = g3:\n N    emmean   SE df lower.CL upper.CL\n low    63.9 2.52 48     58.9     69.0\n med    76.2 2.52 48     71.2     81.3\n high   80.5 2.52 48     75.5     85.6\n\ngeno = g4:\n N    emmean   SE df lower.CL upper.CL\n low    61.6 2.52 48     56.5     66.6\n med    69.8 2.52 48     64.8     74.9\n high   96.8 2.52 48     91.8    101.9\n\nConfidence level used: 0.95 \n\n\nWe can also swap the interpretation code to obtain pairwise differences for the genotypes for each nitrogen level.\n\ncontrast(emmeans(model, ~geno|N), method=\"pairwise\")\n\nN = low:\n contrast estimate   SE df t.ratio p.value\n g1 - g2     3.261 3.56 48   0.916  0.7962\n g1 - g3    -1.423 3.56 48  -0.400  0.9781\n g1 - g4     0.912 3.56 48   0.256  0.9940\n g2 - g3    -4.683 3.56 48  -1.316  0.5573\n g2 - g4    -2.349 3.56 48  -0.660  0.9114\n g3 - g4     2.334 3.56 48   0.656  0.9129\n\nN = med:\n contrast estimate   SE df t.ratio p.value\n g1 - g2     2.130 3.56 48   0.599  0.9319\n g1 - g3    -7.488 3.56 48  -2.105  0.1662\n g1 - g4    -1.117 3.56 48  -0.314  0.9891\n g2 - g3    -9.618 3.56 48  -2.703  0.0452\n g2 - g4    -3.247 3.56 48  -0.913  0.7982\n g3 - g4     6.371 3.56 48   1.791  0.2903\n\nN = high:\n contrast estimate   SE df t.ratio p.value\n g1 - g2    -7.668 3.56 48  -2.155  0.1507\n g1 - g3     2.309 3.56 48   0.649  0.9154\n g1 - g4   -14.001 3.56 48  -3.935  0.0015\n g2 - g3     9.977 3.56 48   2.804  0.0353\n g2 - g4    -6.333 3.56 48  -1.780  0.2953\n g3 - g4   -16.310 3.56 48  -4.584  0.0002\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nInstead of testing pairwise, we can test against one standard control, e.g. the low nitrogen level,\n\ncontrast(emmeans(model, ~N|geno), method=\"trt.vs.ctrl\")\n\ngeno = g1:\n contrast   estimate   SE df t.ratio p.value\n med - low      6.24 3.56 48   1.753  0.1557\n high - low    20.35 3.56 48   5.721  &lt;.0001\n\ngeno = g2:\n contrast   estimate   SE df t.ratio p.value\n med - low      7.37 3.56 48   2.071  0.0816\n high - low    31.28 3.56 48   8.792  &lt;.0001\n\ngeno = g3:\n contrast   estimate   SE df t.ratio p.value\n med - low     12.30 3.56 48   3.458  0.0023\n high - low    16.62 3.56 48   4.672  &lt;.0001\n\ngeno = g4:\n contrast   estimate   SE df t.ratio p.value\n med - low      8.27 3.56 48   2.323  0.0463\n high - low    35.26 3.56 48   9.912  &lt;.0001\n\nP value adjustment: dunnettx method for 2 tests \n\n\nor the high nitrogen level.\n\ncontrast(emmeans(model, ~N|geno), method=\"trt.vs.ctrl\", ref=3)\n\ngeno = g1:\n contrast   estimate   SE df t.ratio p.value\n low - high   -20.35 3.56 48  -5.721  &lt;.0001\n med - high   -14.11 3.56 48  -3.967  0.0005\n\ngeno = g2:\n contrast   estimate   SE df t.ratio p.value\n low - high   -31.28 3.56 48  -8.792  &lt;.0001\n med - high   -23.91 3.56 48  -6.721  &lt;.0001\n\ngeno = g3:\n contrast   estimate   SE df t.ratio p.value\n low - high   -16.62 3.56 48  -4.672  &lt;.0001\n med - high    -4.32 3.56 48  -1.214  0.3841\n\ngeno = g4:\n contrast   estimate   SE df t.ratio p.value\n low - high   -35.26 3.56 48  -9.912  &lt;.0001\n med - high   -27.00 3.56 48  -7.589  &lt;.0001\n\nP value adjustment: dunnettx method for 2 tests \n\n\nThe compact letter display can be used to indicate or visualise group differences in an easily understandable way. For this we need the library(multcompView) and library(multcomp).\n\ncld(emmeans(model, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\n\ngeno = g1:\n N    emmean   SE df lower.CL upper.CL .group\n low    62.5 2.52 48     56.3     68.7  a    \n med    68.7 2.52 48     62.5     75.0  a    \n high   82.8 2.52 48     76.6     89.1   b   \n\ngeno = g2:\n N    emmean   SE df lower.CL upper.CL .group\n low    59.2 2.52 48     53.0     65.5  a    \n med    66.6 2.52 48     60.4     72.8  a    \n high   90.5 2.52 48     84.3     96.7   b   \n\ngeno = g3:\n N    emmean   SE df lower.CL upper.CL .group\n low    63.9 2.52 48     57.7     70.1  a    \n med    76.2 2.52 48     70.0     82.4   b   \n high   80.5 2.52 48     74.3     86.8   b   \n\ngeno = g4:\n N    emmean   SE df lower.CL upper.CL .group\n low    61.6 2.52 48     55.4     67.8  a    \n med    69.8 2.52 48     63.6     76.1  a    \n high   96.8 2.52 48     90.6    103.1   b   \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nGroups that do not share a letter are significantly different according to the posthoc test, which is corrected for multiple testing using the Sidak method. (former Tukey)\n\n\nPresentation of results\nWe calculate the confidence intervals and perform posthoc tests for each genotype.\n\nCIs=cld(emmeans(model, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)\nCIs\n\ngeno = g1:\n N    emmean   SE df lower.CL upper.CL .group\n low    62.5 2.52 48     56.3     68.7 a     \n med    68.7 2.52 48     62.5     75.0 a     \n high   82.8 2.52 48     76.6     89.1 b     \n\ngeno = g2:\n N    emmean   SE df lower.CL upper.CL .group\n low    59.2 2.52 48     53.0     65.5 a     \n med    66.6 2.52 48     60.4     72.8 a     \n high   90.5 2.52 48     84.3     96.7 b     \n\ngeno = g3:\n N    emmean   SE df lower.CL upper.CL .group\n low    63.9 2.52 48     57.7     70.1 a     \n med    76.2 2.52 48     70.0     82.4 b     \n high   80.5 2.52 48     74.3     86.8 b     \n\ngeno = g4:\n N    emmean   SE df lower.CL upper.CL .group\n low    61.6 2.52 48     55.4     67.8 a     \n med    69.8 2.52 48     63.6     76.1 a     \n high   96.8 2.52 48     90.6    103.1 b     \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAnd plot the data together with estimated marginal means and confidence intervals and mention that the letters display differences between nitrogen levels for each genotype according to the posthoc test.\n\nggplot(df, aes(y=yield, x=N, col=N)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.6)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0, \n                                            dodge.width=0.6), shape=1, size=1)+\n  geom_point(data=CIs, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 110, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Dry matter yield (dt/ha)\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\nAs we have 5 observations per treatment level, we can use a boxplot. However, having fewer that 5, it may be better to display just the observations as points, and skip the summary stats that a boxplot displays.\n\nggplot(df, aes(y=yield, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n  geom_point(data=CIs, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 110, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Dry matter yield (dt/ha)\")+\n  xlab(\"Nitrogen fertilisation\")"
  },
  {
    "objectID": "Themen/08/08_2f_LM.html#linear-model-with-block-as-fixed-effect",
    "href": "Themen/08/08_2f_LM.html#linear-model-with-block-as-fixed-effect",
    "title": "Analysis of two-factorial experiments with general linear (mixed effect) models",
    "section": "Linear model with block as fixed effect",
    "text": "Linear model with block as fixed effect\nIn addition to the geno * N effects, we fit block as predictor variable in the model. Block should be coded as factor.\n\nmodel2 &lt;- lm(yield ~ geno * N + block, data = df)\nsummary(model2)\n\n\nCall:\nlm(formula = yield ~ geno * N + block, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.670 -2.537  0.149  2.322  7.600 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   58.5065     2.0255  28.885  &lt; 2e-16 ***\ngenog2        -3.2606     2.4807  -1.314 0.195523    \ngenog3         1.4225     2.4807   0.573 0.569274    \ngenog4        -0.9117     2.4807  -0.368 0.714996    \nNmed           6.2378     2.4807   2.515 0.015648 *  \nNhigh         20.3527     2.4807   8.204 2.06e-10 ***\nblock2         1.5365     1.6013   0.960 0.342530    \nblock3         7.7468     1.6013   4.838 1.64e-05 ***\nblock4         1.4096     1.6013   0.880 0.383479    \nblock5         9.2300     1.6013   5.764 7.49e-07 ***\ngenog2:Nmed    1.1303     3.5082   0.322 0.748847    \ngenog3:Nmed    6.0655     3.5082   1.729 0.090834 .  \ngenog4:Nmed    2.0285     3.5082   0.578 0.566067    \ngenog2:Nhigh  10.9283     3.5082   3.115 0.003233 ** \ngenog3:Nhigh  -3.7315     3.5082  -1.064 0.293296    \ngenog4:Nhigh  14.9123     3.5082   4.251 0.000109 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.922 on 44 degrees of freedom\nMultiple R-squared:  0.9296,    Adjusted R-squared:  0.9057 \nF-statistic: 38.76 on 15 and 44 DF,  p-value: &lt; 2.2e-16\n\nanova(model2)\n\nAnalysis of Variance Table\n\nResponse: yield\n          Df Sum Sq Mean Sq  F value    Pr(&gt;F)    \ngeno       3  195.6    65.2   4.2376   0.01025 *  \nN          2 6955.4  3477.7 226.0497 &lt; 2.2e-16 ***\nblock      4  842.0   210.5  13.6828 2.503e-07 ***\ngeno:N     6  951.5   158.6  10.3080 4.111e-07 ***\nResiduals 44  676.9    15.4                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nModel diagnostics should be extended to plotting residuals against the block.\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model2, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\nPosthoc test as before for the N-effect for each genotype.\n\nCI2s=cld(emmeans(model2, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI2s$.group =gsub(\" \", \"\", CI2s$.group, fixed = TRUE)\nCI2s\n\ngeno = g1:\n N    emmean   SE df lower.CL upper.CL .group\n low    62.5 1.75 44     58.1     66.8 a     \n med    68.7 1.75 44     64.4     73.1 b     \n high   82.8 1.75 44     78.5     87.2 c     \n\ngeno = g2:\n N    emmean   SE df lower.CL upper.CL .group\n low    59.2 1.75 44     54.9     63.6 a     \n med    66.6 1.75 44     62.2     71.0 b     \n high   90.5 1.75 44     86.2     94.9 c     \n\ngeno = g3:\n N    emmean   SE df lower.CL upper.CL .group\n low    63.9 1.75 44     59.6     68.3 a     \n med    76.2 1.75 44     71.9     80.6 b     \n high   80.5 1.75 44     76.2     84.9 b     \n\ngeno = g4:\n N    emmean   SE df lower.CL upper.CL .group\n low    61.6 1.75 44     57.2     65.9 a     \n med    69.8 1.75 44     65.5     74.2 b     \n high   96.8 1.75 44     92.5    101.2 c     \n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=yield, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n  geom_point(data=CI2s, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI2s, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI2s, aes(y = 110, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Dry matter yield (dt/ha)\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\nLet’s compare both models\n\nCI.comp=rbind(CIs, CI2s)\nCI.comp$model=rep(c(\"model\", \"model2\"), each=12)\n\n\nggplot(data=CI.comp, aes(y=emmean, x=N, col=model, group=model))+\n  geom_point(position=position_dodge(width=0.4))+\n  geom_errorbar(aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.4, \n                position=position_dodge(width=0.4))+\n  facet_grid(~geno)+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\nThe estimated marginal means do not differ, but the width of the confidence interval does. model 2, which takes the block effect into account, has narrower CIs.\n\n\n\n\n\n\nImportant\n\n\n\nIn a complete randomized design (CRD), replication is implicit in the random assignment, so there’s no need to include it explicitly in the model. In an randomized complete block design (RCBD) or any design with a blocking structure, blocking should be included as a factor in the model to account for the additional structure and prevent confounding treatment effects with block-based variability."
  },
  {
    "objectID": "Themen/08/08_2f_LM.html#linear-mixed-effect-model-with-block-as-random-effect-glmmtmb",
    "href": "Themen/08/08_2f_LM.html#linear-mixed-effect-model-with-block-as-random-effect-glmmtmb",
    "title": "Analysis of two-factorial experiments with general linear (mixed effect) models",
    "section": "Linear mixed effect model with block as random effect (glmmTMB)",
    "text": "Linear mixed effect model with block as random effect (glmmTMB)\nBlock may be also used as random effect:\n\nwhen your block represents a random sample from a larger population, e.g. when you test the treatments on multiple fields, and you are not interested in the field (block) effects, i.e. you like to generalize the findings to all fields and not just the ones you used in the study.\nwhen you have many blocks (&gt;4-8 levels) and you are rather interested in the variance that the block is attributed to (variance partitioning),\nor you have incomplete blocks or repeated measures.\n\nHere I present examples for mixed effect models using the libraries glmmTMB and lme4.\n\nmodel3 &lt;- glmmTMB(yield ~ geno * N + (1|block), data = df, REML=T)\nsummary(model3)\n\n Family: gaussian  ( identity )\nFormula:          yield ~ geno * N + (1 | block)\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   325.2    354.5   -148.6    297.2       46 \n\nRandom effects:\n\nConditional model:\n Groups   Name        Variance Std.Dev.\n block    (Intercept) 16.26    4.032   \n Residual             15.38    3.922   \nNumber of obs: 60, groups:  block, 5\n\nDispersion estimate for gaussian family (sigma^2): 15.4 \n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   62.4910     2.5157  24.840  &lt; 2e-16 ***\ngenog2        -3.2606     2.4807  -1.314  0.18871    \ngenog3         1.4225     2.4807   0.573  0.56635    \ngenog4        -0.9117     2.4807  -0.368  0.71323    \nNmed           6.2378     2.4807   2.515  0.01192 *  \nNhigh         20.3527     2.4807   8.204 2.32e-16 ***\ngenog2:Nmed    1.1303     3.5082   0.322  0.74732    \ngenog3:Nmed    6.0655     3.5082   1.729  0.08382 .  \ngenog4:Nmed    2.0285     3.5082   0.578  0.56312    \ngenog2:Nhigh  10.9283     3.5082   3.115  0.00184 ** \ngenog3:Nhigh  -3.7315     3.5082  -1.064  0.28749    \ngenog4:Nhigh  14.9123     3.5082   4.251 2.13e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAnova(model3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: yield\n         Chisq Df Pr(&gt;Chisq)    \ngeno    12.713  3   0.005301 ** \nN      452.100  2  &lt; 2.2e-16 ***\ngeno:N  61.848  6  1.895e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCI3s=cld(emmeans(model3, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI3s$.group =gsub(\" \", \"\", CI3s$.group, fixed = TRUE)\nCI3s\n\ngeno = g1:\n N    emmean   SE df lower.CL upper.CL .group\n low    62.5 2.52 46     56.3     68.7 a     \n med    68.7 2.52 46     62.5     75.0 b     \n high   82.8 2.52 46     76.6     89.1 c     \n\ngeno = g2:\n N    emmean   SE df lower.CL upper.CL .group\n low    59.2 2.52 46     53.0     65.5 a     \n med    66.6 2.52 46     60.4     72.8 b     \n high   90.5 2.52 46     84.3     96.7 c     \n\ngeno = g3:\n N    emmean   SE df lower.CL upper.CL .group\n low    63.9 2.52 46     57.7     70.1 a     \n med    76.2 2.52 46     70.0     82.5 b     \n high   80.5 2.52 46     74.3     86.8 b     \n\ngeno = g4:\n N    emmean   SE df lower.CL upper.CL .group\n low    61.6 2.52 46     55.3     67.8 a     \n med    69.8 2.52 46     63.6     76.1 b     \n high   96.8 2.52 46     90.6    103.1 c     \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=yield, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n  geom_point(data=CI3s, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI3s, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI3s, aes(y = 110, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Dry matter yield (dt/ha)\")+\n  xlab(\"Nitrogen fertilisation\")"
  },
  {
    "objectID": "Themen/08/08_2f_LM.html#linear-mixed-effect-model-with-block-as-random-effect-lme4",
    "href": "Themen/08/08_2f_LM.html#linear-mixed-effect-model-with-block-as-random-effect-lme4",
    "title": "Analysis of two-factorial experiments with general linear (mixed effect) models",
    "section": "Linear mixed effect model with block as random effect (lme4)",
    "text": "Linear mixed effect model with block as random effect (lme4)\n\nmodel4 &lt;- lmer(yield ~ geno * N + (1|block), data = df, REML=T)\nsummary(model4)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: yield ~ geno * N + (1 | block)\n   Data: df\n\nREML criterion at convergence: 297.2\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.51098 -0.59464  0.02494  0.68972  1.86338 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n block    (Intercept) 16.26    4.032   \n Residual             15.38    3.922   \nNumber of obs: 60, groups:  block, 5\n\nFixed effects:\n             Estimate Std. Error      df t value Pr(&gt;|t|)    \n(Intercept)   62.4910     2.5157 12.2943  24.840 7.01e-12 ***\ngenog2        -3.2606     2.4807 44.0000  -1.314 0.195523    \ngenog3         1.4225     2.4807 44.0000   0.573 0.569274    \ngenog4        -0.9117     2.4807 44.0000  -0.368 0.714996    \nNmed           6.2378     2.4807 44.0000   2.515 0.015648 *  \nNhigh         20.3527     2.4807 44.0000   8.204 2.06e-10 ***\ngenog2:Nmed    1.1303     3.5082 44.0000   0.322 0.748847    \ngenog3:Nmed    6.0655     3.5082 44.0000   1.729 0.090834 .  \ngenog4:Nmed    2.0285     3.5082 44.0000   0.578 0.566067    \ngenog2:Nhigh  10.9283     3.5082 44.0000   3.115 0.003233 ** \ngenog3:Nhigh  -3.7315     3.5082 44.0000  -1.064 0.293296    \ngenog4:Nhigh  14.9123     3.5082 44.0000   4.251 0.000109 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) genog2 genog3 genog4 Nmed   Nhigh  gng2:Nm gng3:Nm gng4:Nm\ngenog2      -0.493                                                           \ngenog3      -0.493  0.500                                                    \ngenog4      -0.493  0.500  0.500                                             \nNmed        -0.493  0.500  0.500  0.500                                      \nNhigh       -0.493  0.500  0.500  0.500  0.500                               \ngenog2:Nmed  0.349 -0.707 -0.354 -0.354 -0.707 -0.354                        \ngenog3:Nmed  0.349 -0.354 -0.707 -0.354 -0.707 -0.354  0.500                 \ngenog4:Nmed  0.349 -0.354 -0.354 -0.707 -0.707 -0.354  0.500   0.500         \ngenog2:Nhgh  0.349 -0.707 -0.354 -0.354 -0.354 -0.707  0.500   0.250   0.250 \ngenog3:Nhgh  0.349 -0.354 -0.707 -0.354 -0.354 -0.707  0.250   0.500   0.250 \ngenog4:Nhgh  0.349 -0.354 -0.354 -0.707 -0.354 -0.707  0.250   0.250   0.500 \n            gng2:Nh gng3:Nh\ngenog2                     \ngenog3                     \ngenog4                     \nNmed                       \nNhigh                      \ngenog2:Nmed                \ngenog3:Nmed                \ngenog4:Nmed                \ngenog2:Nhgh                \ngenog3:Nhgh  0.500         \ngenog4:Nhgh  0.500   0.500 \n\nanova(model4)\n\nType III Analysis of Variance Table with Satterthwaite's method\n       Sum Sq Mean Sq NumDF DenDF  F value    Pr(&gt;F)    \ngeno    195.6    65.2     3    44   4.2376   0.01025 *  \nN      6955.4  3477.7     2    44 226.0497 &lt; 2.2e-16 ***\ngeno:N  951.5   158.6     6    44  10.3080 4.111e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCI4s=cld(emmeans(model4, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI4s$.group =gsub(\" \", \"\", CI3s$.group, fixed = TRUE)\nCI4s\n\ngeno = g1:\n N    emmean   SE   df lower.CL upper.CL .group\n low    62.5 2.52 12.3     55.5     69.4 a     \n med    68.7 2.52 12.3     61.8     75.7 b     \n high   82.8 2.52 12.3     75.9     89.8 c     \n\ngeno = g2:\n N    emmean   SE   df lower.CL upper.CL .group\n low    59.2 2.52 12.3     52.3     66.2 a     \n med    66.6 2.52 12.3     59.7     73.5 b     \n high   90.5 2.52 12.3     83.6     97.5 c     \n\ngeno = g3:\n N    emmean   SE   df lower.CL upper.CL .group\n low    63.9 2.52 12.3     57.0     70.9 a     \n med    76.2 2.52 12.3     69.3     83.2 b     \n high   80.5 2.52 12.3     73.6     87.5 b     \n\ngeno = g4:\n N    emmean   SE   df lower.CL upper.CL .group\n low    61.6 2.52 12.3     54.6     68.5 a     \n med    69.8 2.52 12.3     62.9     76.8 b     \n high   96.8 2.52 12.3     89.9    103.8 c     \n\nDegrees-of-freedom method: kenward-roger \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nP value adjustment: sidak method for 3 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=yield, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n  geom_point(data=CI4s, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI4s, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI4s, aes(y = 110, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Dry matter yield (dt/ha)\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\n\nLet’s compare the models\n\nCI.comp=rbind(CIs, CI2s, CI3s, CI4s)\nCI.comp$model=factor(rep(c(\"lm crd\", \"lm rcbd\", \"glmmTMB\",  \"lmer\"), each=12), levels =c(\"lm crd\", \"lm rcbd\", \"glmmTMB\",  \"lmer\"))\n\n\nggplot(data=CI.comp, aes(y=emmean, x=N, col=model, group=model))+\n  geom_point(position=position_dodge(width=0.4))+\n  geom_errorbar(aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.4, \n                position=position_dodge(width=0.4))+\n  facet_grid(~geno)+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\nAgain, the estimated marginal means do not differ, but the width of the confidence interval does. model2 (lm rcbd), which takes the block as fixed effect into account, has narrower CIs. model3 (glmmTMB) with block as random effect has similar CIs compared to the model without any block affect and model4 (lme4) has the widest CIs (due to df-method Kenward Roger)."
  },
  {
    "objectID": "Themen/06/06_StatMod.html",
    "href": "Themen/06/06_StatMod.html",
    "title": "Statistische Modellierung",
    "section": "",
    "text": "Alle Modelle sind falsch.\nManche Modelle sind besser als andere.\nDas richtige Modell kann niemals mit absoluter Sicherheit bestimmt werden.\nJe einfacher ein Modell ist, desto besser. “the principle of parsimony: the correct explanation is the simplest explanation”\n“Man muss die Dinge so einfach wie möglich machen. Aber nicht einfacher.” Albert Einstein"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#prinzip-der-parsimonität---wie-viele-parameter-bedarf-es-um-einen-elefanten-zu-modellieren",
    "href": "Themen/06/06_StatMod.html#prinzip-der-parsimonität---wie-viele-parameter-bedarf-es-um-einen-elefanten-zu-modellieren",
    "title": "Statistische Modellierung",
    "section": "Prinzip der Parsimonität - Wie viele Parameter bedarf es um einen Elefanten zu modellieren?",
    "text": "Prinzip der Parsimonität - Wie viele Parameter bedarf es um einen Elefanten zu modellieren?\n\n\n36, B) 5, C) 10, D) 20 und E) 30 Parameter\n\nThe 30-term elephant “may not satisfy the third-grade art teacher, but would carry most chemical engineers into preliminary design.”\naus:\nBurnham K, Anderson D. 2002. Model selection and multimodel inference. Springer, USA.\nWei J. 1975. Least square fitting of an elephant. Chemtech 5: 128-129."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#ziel-der-statistischen-modellierung",
    "href": "Themen/06/06_StatMod.html#ziel-der-statistischen-modellierung",
    "title": "Statistische Modellierung",
    "section": "Ziel der statistischen Modellierung",
    "text": "Ziel der statistischen Modellierung\n\nSelektion des minimalen adäquaten Modells aus einem großen Pool verschieden komplexer Modelle"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modelltypen",
    "href": "Themen/06/06_StatMod.html#modelltypen",
    "title": "Statistische Modellierung",
    "section": "Modelltypen",
    "text": "Modelltypen\n\nVolles Model (full model, maximales Modell, globales Modell, alle Erklärungsvariablen inkl. Interaktionen, Freiheitsgrade = n - p - 1)\ncandidate model (verschiedene mögliche Modelle die subsets des globalen Modells sind, d.h. unterschiedliche Erklärungsvariablen beinhalten)\nMinimales adäquates Modell (mimimal adequate model, vereinfachtes oder “bestes” Modell entsprechend dem Prinzip der Parsimonität)\nNullmodell (null model, nur Intercept ~1, i.e. Mittelwert, wird gefittet)\nGesättigtes Modell (saturated model, eine Erklärungsvariable für jeden Punkt = keine Freiheitsgrade)"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#erklärungsvariablen",
    "href": "Themen/06/06_StatMod.html#erklärungsvariablen",
    "title": "Statistische Modellierung",
    "section": "Erklärungsvariablen",
    "text": "Erklärungsvariablen\n\nWelche Erklärungsvariablen?\n\nbiologisch sinnvoll\nentsprechend Fragestellung und Literatur\nDesignvariablen\n\nKorrelation zwischen Erklärungsvariablen prüfen\n\nkann zu verzerrten Schätzungen der Modellparameter und Fehler führen\nDaumenregel r &lt; 0,7\nvariance inflation factor VIF &lt; 3\n\nAnzahl Erklärungsvariablen an Stichprobenumfang anpassen\n\nGefahr der Überparametrisierung\nDaumenregel je Parameter 10 Stichproben (häufig nicht realisierbar)\nin landwirtschaftlichen Versuchen häufig 4 Wdh\n\nBeziehungen zwischen Abhängigen und Erklärungsvariable überprüfen\n\nLinearität vs. Kurvatur Übung 5\nVerteilung der kontinierlichen Erklärungsvariable (Schiefe, Länge des Gradienten)\nN bei kategorialen Erklärungsvariable (balanciert, Anzahl Stichproben je Gruppe)\n\nWelche Interaktionen? (alle, keine, nur zweifach, entsprechend Fragestellung)"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#statistische-interaktion-wechselwirkung",
    "href": "Themen/06/06_StatMod.html#statistische-interaktion-wechselwirkung",
    "title": "Statistische Modellierung",
    "section": "Statistische Interaktion (Wechselwirkung)",
    "text": "Statistische Interaktion (Wechselwirkung)\nwenn der Effekt einer Erklärungsvariable von dem Wert der anderen Erklärungsvariable abhängt"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#mehrere-erklärungsvariablen-im-modell",
    "href": "Themen/06/06_StatMod.html#mehrere-erklärungsvariablen-im-modell",
    "title": "Statistische Modellierung",
    "section": "Mehrere Erklärungsvariablen im Modell",
    "text": "Mehrere Erklärungsvariablen im Modell\n\n\n\n\n\n\n\n\nNr\nModellformel\nModellparameter\n\n\n\n\n1\nlm(y~x+z)\nzwei Erklärungsvariablen\n\n\n2\nlm(y~x*z)\nzwei Erklärungsvariablen und deren Interaktion\n\n\n3\nlm(y~x+z+x:z)\nzwei Erklärungsvariablen und deren Interaktion\n\n\n4\nlm(y~x+z+w)\ndrei Erklärungsvariablen\n\n\n5\nlm(y~x+z+w+x:z+z:w+w:x)\ndrei Erklärungsvariablen und alle Zweifach-Interaktionen\n\n\n6\nlm(y~(x+z+w)^2)\ndrei Erklärungsvariablen und alle Zweifach-Interaktionen\n\n\n7\nlm(y~x+z+w+x:z+z:w+w:x+z:w:x)\ndrei Erklärungsvariablen und alle Interaktionen\n\n\n8\nlm(y~x*z*w)\ndrei Erklärungsvariablen und alle Interaktionen\n\n\n\nModell Nr. 2 und 3 sind identische Modelle, ebenso Nr. 5 und 6 und Nr. 7 und 8."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#beispiel-modell--und-variablenselektion",
    "href": "Themen/06/06_StatMod.html#beispiel-modell--und-variablenselektion",
    "title": "Statistische Modellierung",
    "section": "Beispiel: Modell- und Variablenselektion",
    "text": "Beispiel: Modell- und Variablenselektion\nWir wollen nun verschiedene Modell- und Variablenselektionsstrategien an einem Beispieldatensatz zur Pflanzendiversität in Weizenfeldern rechnen.\nLiteratur zum Thema:\nHeinze et al. (2018) Variable selection – A review and recommendations for the practicing statistician\n\nFragestellung:\nWie beeinflusst Bewirtschaftung (ökologisch vs. konventionell), Bodengüte (ertragreich vs. ertragsarm) und Landschaftsstruktur (strukturreich vs. strukturarm) die Pflanzendiversität in Weizenfeldern?\n\n\nUntersuchungsdesign:\nIn 36 ökologisch und konventionell bewirtschafteten Weizenflächen (Man = con vs. org), welche sowohl in ihrer Bodengüte (Soil quality = SQ) als auch in der umgebenden Landschaftsstruktur (% Ackeranteil = Arab) variierten, wurde die Shannon-Diversität von Ackerwildkräutern (Weeds) ermittelt.\n\n\nDaten einlesen, kennenlernen, plotten\n\nlibrary(openxlsx)\nof=read.xlsx(\"organic_farming.xlsx\")\nstr(of)\n\n'data.frame':   36 obs. of  5 variables:\n $ ID   : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Man  : chr  \"con\" \"org\" \"con\" \"org\" ...\n $ Arab : num  21.2 21.4 24.3 26.3 31.3 29.4 36.1 34.6 38.9 41.9 ...\n $ SQ   : num  82 63 52 40 94 74 69 53 83 86 ...\n $ Weeds: num  3.35 3.5 3.28 3.57 2.96 3.35 3 3.5 3 3.54 ...\n\nof$Man=as.factor(of$Man)\nsummary(of)\n\n       ID         Man          Arab             SQ            Weeds      \n Min.   : 1.00   con:18   Min.   :21.20   Min.   :38.00   Min.   :1.410  \n 1st Qu.: 9.75   org:18   1st Qu.:41.15   1st Qu.:54.75   1st Qu.:2.438  \n Median :18.50            Median :60.50   Median :62.50   Median :2.980  \n Mean   :18.50            Mean   :59.89   Mean   :65.83   Mean   :2.789  \n 3rd Qu.:27.25            3rd Qu.:80.65   3rd Qu.:79.25   3rd Qu.:3.290  \n Max.   :36.00            Max.   :94.10   Max.   :95.00   Max.   :3.570  \n\n\nWir plotten zunächst die Daten entsprechend unserer Fragestellung:\n\nlibrary(ggplot2)\nlibrary(ggpubr)\np1=ggplot(of, aes(x=Man, y=Weeds, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np2=ggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\np3=ggplot(of, aes(x=SQ, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\np4=ggplot(of, aes(x=Man, y=Arab, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np5=ggplot(of, aes(x=Man, y=SQ, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np6=ggplot(of, aes(x=SQ, y=Arab, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\nggarrange(p1, p2, p3, p4, p5, p6, common.legend = TRUE, legend = \"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIm Plot oben rechts sehen wir, dass die Diversität in ökologisch bewirtschafteten Flächen höher ist als in konventionellen. Wir sehen aber auch, dass die Variabilität sich deutlich (und um ein Vielfaches) zwischen org und con unterscheidet.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlibrary(dplyr)\nof %&gt;% \n  group_by(Man) %&gt;% \n  summarise(MW=mean(Weeds),\n            VAR=var(Weeds))\n\n# A tibble: 2 × 3\n  Man      MW    VAR\n  &lt;fct&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 con    2.35 0.441 \n2 org    3.23 0.0558\n\n\n\n\n\nIst das ein Problem? NEIN. Wir müssen die Residuen nach der Analyse auf Varianzhomogenität checken. Wenn unsere Erklärungsvariablen die Variabilität in den Daten erklären, dann sollte der Restfehler varianzhomogen sein.\nAusserdem sehen wir einen negativen Zusammenhang zwischen Weedsund Arab für org und con sowie eine mögliche Interaktion zwischen Weeds und SQ für org und con. Wir plotten ausserdem die Erklärungsvariablen gegeneinander, um mögliche Muster oder Zusammenhänge zu erkennen. Wir sehen, dass die Erklärungsvariablen Arab und SQ einen ähnlich weiten Wertebereich in orgund con aufweisen. Außerdem scheint es keinen Zusammenhang zwischen Arab und SQ zu geben. Gut so."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#korrelation-zwischen-erklärungsvariablen-testen",
    "href": "Themen/06/06_StatMod.html#korrelation-zwischen-erklärungsvariablen-testen",
    "title": "Statistische Modellierung",
    "section": "Korrelation zwischen Erklärungsvariablen testen",
    "text": "Korrelation zwischen Erklärungsvariablen testen\nBevor wir ein Modell formulieren, sollten wir die Korrelation zwischen den Erklärungsvariablen prüfen. Eng korrelierte Erklärungsvariablen können zu verzerrten Modellkoeffizienten, hohen Standardfehlern der Koeffizienten und damit zu instabilen Modellen und den falschen Schlussfolgerungen führen.\nsiehe auch Dormann et al. (2012) Collinearity: a review of methods to deal with it and a simulation study evaluating their performance\n\nmit der ggpairs() und library(GGally)\n\nlibrary(GGally)\nggpairs(of, columns = c(2:4), ggplot2::aes(colour = Man))\n\n\n\n\n\n\n\n\n\n\nmit einer Korrelationsmatrix\nUm eine Korrelationsmatrix zu erstellen, müssen alle Variablen numerisch sein. Ich codiere hier die Variable Man in eine dummy-Variable um. Da sie nur zwei Levels hat, wird eine Spalte mit der Information Man = 1 und org = 0 ausreichen.\n\nof$Man.con=ifelse(of$Man == \"con\", 1, 0)\n\nSollte man einen Faktor mit mehr als zwei Levels haben, könnte man so fortfahren: of$Man.org=ifelse(of$Man == \"org\", 1, 0).\n\nlibrary(Hmisc)\nrcorr(as.matrix(of[,c(3:4, 6)]), type=\"pearson\")\n\n         Arab    SQ Man.con\nArab     1.00 -0.16    0.00\nSQ      -0.16  1.00    0.13\nMan.con  0.00  0.13    1.00\n\nn= 36 \n\n\nP\n        Arab   SQ     Man.con\nArab           0.3495 0.9978 \nSQ      0.3495        0.4609 \nMan.con 0.9978 0.4609        \n\n\nDie Pearson Korrelationskoeffizienten sind alle &lt; 0,7 bzw. &gt;-0,7. Pearson Korrelationskoeffizienten nutzt man für lineare Zusammenhänge. Alternativ kann man die Spearman Rang-Korrelation nutzen, welche auf Rängen basiert und für monotone Zusammenhänge, i.e. monoton steigend oder fallend, eine Aussage trifft.\n\nrcorr(as.matrix(of[,c(3:4, 6)]), type=\"spearman\")\n\n         Arab    SQ Man.con\nArab     1.00 -0.17    0.01\nSQ      -0.17  1.00    0.11\nMan.con  0.01  0.11    1.00\n\nn= 36 \n\n\nP\n        Arab   SQ     Man.con\nArab           0.3172 0.9753 \nSQ      0.3172        0.5142 \nMan.con 0.9753 0.5142        \n\n\nEine gute Möglichkeit zur Abbildung einer Korrelationsmatrix bietet die library(corrplot) mit der Funktion corrplot() und corrplot.mixed().\n\nlibrary(corrplot)\ncorrplot(cor(of[,c(3:4, 6)]), method = \"ellipse\")\n\n\n\n\n\n\n\ncorrplot.mixed(cor(of[,c(3:4, 6)]), upper = \"ellipse\", tl.col =1, tl.cex=0.75)\n\n\n\n\n\n\n\n\n\n\nmit dem Variance Inflation Factor (VIF)\nDie potentielle Korrelation zwischen Erklärungsvariablen kann auch mit dem Variance Inflation Factor (VIF) getestet werden. Der VIF ist ein Maß für die Multikollineraität und gibt an, wie gut die einzelnen Erklärungsvariablen durch die anderen Erklärungsvariablen erklärt werden. Der VIF steht also für die Redundanz innerhalb der Erklärungsvariablen. Ich fitte ein Modell mit den Haupteffekten ohne Interaktionen. Solange alle VIFs &lt; 3 sind, ist alles in Ordnung. Es gibt auch Quellen, die &lt;5 oder gar &lt;10 angeben. Sollte ein VIF höher als dein gewähltes Kriterium sein, dann entfernst du schrittweise die Variable mit dem höchsten VIF, berechnest den VIF erneut und führst dies fort, bis alle Variablen unterhalb dem gewählten Kriterium sind.\n\nlibrary(car)\n\nLade nötiges Paket: carData\n\n\n\nAttache Paket: 'car'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    recode\n\nvif(lm(Weeds~Man+Arab+SQ, data=of))\n\n     Man     Arab       SQ \n1.016819 1.026933 1.043731 \n\n\nAlle Methoden führen zu dem Schluss, dass wir ein Modell mit allen drei Erklärungsvariablen formulieren können."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modell-formulieren",
    "href": "Themen/06/06_StatMod.html#modell-formulieren",
    "title": "Statistische Modellierung",
    "section": "Modell formulieren",
    "text": "Modell formulieren\nIch fitte hier ein Modell inklusive Dreifachinteraktion, obwohl der Stichprobenumfang schon relativ klein ist und es auch Argumente dafür gibt, mit einem Modell nur mit Zweifachinteraktionen zu starten, i.e. ohne Dreifachinteraktion.\n\nmod&lt;-lm(Weeds~Arab*Man*SQ, data=of)\nsummary(mod)\n\n\nCall:\nlm(formula = Weeds ~ Arab * Man * SQ, data = of)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.271803 -0.100298  0.008768  0.093416  0.257560 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     3.748e+00  5.252e-01   7.136 9.15e-08 ***\nArab           -2.440e-02  7.899e-03  -3.090  0.00449 ** \nManorg         -1.398e-01  7.234e-01  -0.193  0.84813    \nSQ              3.181e-03  7.190e-03   0.442  0.66161    \nArab:Manorg     2.073e-02  1.121e-02   1.849  0.07505 .  \nArab:SQ        -3.852e-05  1.140e-04  -0.338  0.73805    \nManorg:SQ      -1.419e-03  1.070e-02  -0.133  0.89538    \nArab:Manorg:SQ -3.233e-05  1.695e-04  -0.191  0.85012    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1554 on 28 degrees of freedom\nMultiple R-squared:  0.956, Adjusted R-squared:  0.945 \nF-statistic: 86.88 on 7 and 28 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellvereinfachung--selektion",
    "href": "Themen/06/06_StatMod.html#modellvereinfachung--selektion",
    "title": "Statistische Modellierung",
    "section": "Modellvereinfachung, -selektion",
    "text": "Modellvereinfachung, -selektion\nWir werden nun verschiedene Methoden der Modell- und Variablenselektion kennenlernen.\n\nSchrittweise Modellvereinfachung mit drop1() basierend auf Teststatistik\n\nDer klassische Weg: backward selection\nmaximales Modell fitten\nschrittweises Entfernen von nicht-signifikanten Interaktionen\n\ndabei mit der Interaktion der höchsten Ordnung beginnen (Dreifach- vor Zweifach-Interaktionen)\nhöchster p-Wert\naltes mit neuem Modell vergleichen (Fehler/deviance)\n\nEntfernen von nicht-signifikanten Erklärungsvariablen (Haupteffekte)\n\nwenn nicht in signifikanter Interaktion enthalten\n\nDas minimale adäquate Modell enthält nur noch signifikante Parameter*.\n\n*nicht signifikante Haupteffekte sind im Modell möglich, wenn sie Teil einer signifikanten Interaktion sind\nWir testen mit der Funktion drop1() die Dreifachinteraktion.\n\ndrop1(mod, test=\"F\") # Signifikanztest für Dreifachinteraktion\n\nSingle term deletions\n\nModel:\nWeeds ~ Arab * Man * SQ\n            Df  Sum of Sq     RSS     AIC F value Pr(&gt;F)\n&lt;none&gt;                    0.67648 -127.08               \nArab:Man:SQ  1 0.00087887 0.67736 -129.03  0.0364 0.8501\n\n\nDer p-Wert ist größer 0.05. Also können wir die Dreifachinteraktion entfernen, indem ein neues Modell mod1 durch die Funktion update() gefittet wird, welches alle Effekte wie mod besitzt ~., außer (daher das -) die Interaktion Arab:Man:SQ.\n\nmod1&lt;-update(mod, ~.-Arab:Man:SQ) # Term wird aus Model entfernt \n\nWenn wir nun die Funktion drop1() für mod1 nutzen, werden uns alle p-Werte für die Zweifachinteraktionen angezeigt.\n\ndrop1(mod1, test=\"F\")\n\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man + Arab:SQ + Man:SQ\n         Df Sum of Sq     RSS      AIC F value    Pr(&gt;F)    \n&lt;none&gt;                0.67736 -129.030                      \nArab:Man  1   1.48614 2.16351  -89.224 63.6264 8.501e-09 ***\nArab:SQ   1   0.00958 0.68695 -130.525  0.4103    0.5268    \nMan:SQ    1   0.02171 0.69908 -129.894  0.9297    0.3429    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nArab:SQ hat den höchsten p-Wert (und &gt; 0,05), also raus damit.\n\nmod2&lt;-update(mod1, ~.-Arab:SQ )\ndrop1(mod2, test=\"F\")\n\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man + Man:SQ\n         Df Sum of Sq     RSS      AIC F value    Pr(&gt;F)    \n&lt;none&gt;                0.68695 -130.525                      \nArab:Man  1   1.59208 2.27903  -89.352 69.5286 2.628e-09 ***\nMan:SQ    1   0.02135 0.70830 -131.423  0.9324     0.342    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMan:SQ hat den höchsten p-Wert (und &gt; 0,05), also raus damit.\n\nmod3&lt;-update(mod2, ~.-Man:SQ)\ndrop1(mod3, test=\"F\")\n\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man\n         Df Sum of Sq     RSS      AIC F value    Pr(&gt;F)    \n&lt;none&gt;                0.70830 -131.423                      \nSQ        1   0.00188 0.71018 -133.327  0.0824     0.776    \nArab:Man  1   1.66223 2.37052  -89.935 72.7506 1.238e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer p-Wert für SQ als Haupteffekt erscheint, weil SQ nicht mehr in einer Interaktion enthalten ist. SQ hat den höchsten p-Wert (und &gt; 0,05), also raus damit.\n\nmod4&lt;-update(mod3, ~.-SQ)\ndrop1(mod4, test=\"F\") # \n\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + Arab:Man\n         Df Sum of Sq     RSS     AIC F value   Pr(&gt;F)    \n&lt;none&gt;                0.71018 -133.33                     \nArab:Man  1    1.7458 2.45599  -90.66  78.665 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\np &lt; 0,05, wir sollten keine weitere Variable entfernen.\n\nsummary(mod4)\n\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\nAnalog gibt es auch eine Funktion add1() bei der eine forward selection durchgeführt werden kann.\nSowohl die klassische backward also auch die forward selection sind für Modelle mit wenigen Erklärungsvariablen denkbar."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#übung-6.1.",
    "href": "Themen/06/06_StatMod.html#übung-6.1.",
    "title": "Statistische Modellierung",
    "section": "Übung 6.1.",
    "text": "Übung 6.1.\nDie Aktivität von Lurchen wurde in den drei Habitattypen (Teichumgebung, Hecke und Wald) bei unterschiedlichen Witterungsbedingungen (Temperatur und Luftfeuchte) gemessen.\n\nImportiere die Daten Lurche.xlsx und mach dich mit den Daten vertraut.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlibrary(openxlsx)\ndat=read.xlsx(\"Lurche.xlsx\")\nstr(dat)\n\n'data.frame':   90 obs. of  4 variables:\n $ Hab : chr  \"Teich\" \"Teich\" \"Teich\" \"Teich\" ...\n $ Temp: num  14.3 18.3 15.3 19.1 19.5 12.4 16.2 19.1 16.4 15.7 ...\n $ Hum : num  45 57.4 53.9 51.2 60.3 46.3 50.7 56.6 51.1 48.7 ...\n $ Akt : num  39.9 50.4 52.7 53.6 54.8 47.1 49.2 46.9 43.9 43.6 ...\n\n\n\nlibrary(GGally)\nggpairs(dat, columns = 1:4, ggplot2::aes(colour = Hab))\n\n\n\n\n\n\n\n\nim obigen Plot ist zu erkennen:\n\ndrei Habitate mit jeweils 30 Beobachtungen\nTemperatur, Luftfeuchte und Aktivität variieren zwischen den Habitaten\nTemperatur und Luftfeuchte sind positiv korreliert (r = 0.86)\n\nIch plotte die Daten entsprechend der Fragestellung:\n\nggplot(dat, aes(x=Hab, y=Akt, colour=Hab)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\n\n\n\n\n\n\n\n\nDie Aktivität scheint sich zwischen den verschienen Habitattypen zu unterscheiden.\n\nggplot(dat, aes(x=Temp, y=Akt, colour=Hab)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nEs scheint einen positiven Zusammenhang zwischen der Temperatur und der Aktivität in den verschiedenen Habitaten zu geben.\n\nggplot(data=dat, aes(y=Akt, x=Hum, col=Hab))+\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nGleiches Muster für den Zusammenhang zwischen Aktivität und Luftfeuchte.\nDie Korrelationsmatrix zeigen eine enge Korrelation (r = 0.86) zwischen Temperatur und Luftfeuchte. Die Korrelationskoeffizienten der Dummy-Variablen zeigen die Unterschiele der kontinuierlichen Variablen in den jeweiligen Habitattypen an. z.B. ist in Habitattyp Teich die die Temperatur höher (r = 0,47) und im Wald kälter (r = 0,37).\n\nlibrary(Hmisc)\ndat$Hab.H=ifelse(dat$Hab == \"Hecke\", 1, 0)\ndat$Hab.T=ifelse(dat$Hab == \"Teich\", 1, 0)\ndat$Hab.W=ifelse(dat$Hab == \"Wald\", 1, 0)\nrcorr(as.matrix(dat[,c(2:7)]), type=\"pearson\")\n\n       Temp   Hum   Akt Hab.H Hab.T Hab.W\nTemp   1.00  0.86  0.63 -0.11  0.47 -0.37\nHum    0.86  1.00  0.49 -0.21  0.39 -0.18\nAkt    0.63  0.49  1.00 -0.18  0.88 -0.70\nHab.H -0.11 -0.21 -0.18  1.00 -0.50 -0.50\nHab.T  0.47  0.39  0.88 -0.50  1.00 -0.50\nHab.W -0.37 -0.18 -0.70 -0.50 -0.50  1.00\n\nn= 90 \n\n\nP\n      Temp   Hum    Akt    Hab.H  Hab.T  Hab.W \nTemp         0.0000 0.0000 0.3097 0.0000 0.0004\nHum   0.0000        0.0000 0.0470 0.0001 0.0863\nAkt   0.0000 0.0000        0.0955 0.0000 0.0000\nHab.H 0.3097 0.0470 0.0955        0.0000 0.0000\nHab.T 0.0000 0.0001 0.0000 0.0000        0.0000\nHab.W 0.0004 0.0863 0.0000 0.0000 0.0000       \n\nrcorr(as.matrix(dat[,c(2:7)]), type=\"spearman\")\n\n       Temp   Hum   Akt Hab.H Hab.T Hab.W\nTemp   1.00  0.86  0.60 -0.11  0.46 -0.34\nHum    0.86  1.00  0.45 -0.23  0.38 -0.15\nAkt    0.60  0.45  1.00 -0.03  0.81 -0.77\nHab.H -0.11 -0.23 -0.03  1.00 -0.50 -0.50\nHab.T  0.46  0.38  0.81 -0.50  1.00 -0.50\nHab.W -0.34 -0.15 -0.77 -0.50 -0.50  1.00\n\nn= 90 \n\n\nP\n      Temp   Hum    Akt    Hab.H  Hab.T  Hab.W \nTemp         0.0000 0.0000 0.2851 0.0000 0.0009\nHum   0.0000        0.0000 0.0289 0.0002 0.1590\nAkt   0.0000 0.0000        0.7534 0.0000 0.0000\nHab.H 0.2851 0.0289 0.7534        0.0000 0.0000\nHab.T 0.0000 0.0002 0.0000 0.0000        0.0000\nHab.W 0.0009 0.1590 0.0000 0.0000 0.0000       \n\n\nAufgrund der engen Korrelation zwischen Temperatur und Luftfeuchte sollten wir nur eine der beiden Variablen ins Modell nehmen. Aber welche? Das können wir basierend auf unserem Fachwissen entscheiden. Oder den Variance Inflation Faktor nutzen:\n\nlibrary(car)\nvif(lm(Akt~Temp+Hum+Hab, data=dat))\n\n         GVIF Df GVIF^(1/(2*Df))\nTemp 4.839203  1        2.199819\nHum  4.302632  1        2.074279\nHab  1.458039  2        1.098860\n\n\nBasierend auf VIF sollten wir Temperatur aus dem Modell entfernen, weil es am stärksten durch die anderen beiden Erklärungsvariablen erklärt werden kann. Ob das so gut ist, werden wir weiter unten sehen.\n\nvif(lm(Akt~Hab+Hum, data=dat))# ok\n\n        GVIF Df GVIF^(1/(2*Df))\nHab 1.181775  2        1.042638\nHum 1.181775  1        1.087095\n\nvif(lm(Akt~Temp+Hab, data=dat))# ok\n\n         GVIF Df GVIF^(1/(2*Df))\nTemp 1.329152  1        1.152888\nHab  1.329152  2        1.073726\n\nvif(lm(Akt~Temp+Hum, data=dat))# nicht ok, nur zu Demo\n\n    Temp      Hum \n3.922289 3.922289 \n\n\n\n\n\n\nModelliere die Aktivität der Lurche mit einer backward selektion.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir haben nun die drei Optionen:\n\nwir ignorieren erstmal die Korrelation zwischen Luftfeuchte und Temperatur und beginnen mit diesem Modell Akt~Temp*Hum*Hab.\n\nwir nutzen das Modell, welches laut VIF besser ist Akt~Hum*Hab.\n\nwir sind stärker an dem Temperatureffekt interessiert und weniger am Luftfeuchteeffekt Akt~Temp*Hab.\nOption\n\n\n\nMod=lm(Akt~Temp*Hab*Hum, data=dat)\nsummary(Mod)\n\n\nCall:\nlm(formula = Akt ~ Temp * Hab * Hum, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7350  -2.7489  -0.5331   2.4653  11.0886 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)        44.58138   44.73999   0.996    0.322\nTemp               -0.34632    3.04932  -0.114    0.910\nHabTeich          -94.39330   77.21012  -1.223    0.225\nHabWald            40.79471   82.99665   0.492    0.624\nHum                -0.92737    0.97549  -0.951    0.345\nTemp:HabTeich       4.94912    4.60881   1.074    0.286\nTemp:HabWald       -5.37073    6.14458  -0.874    0.385\nTemp:Hum            0.04262    0.06108   0.698    0.487\nHabTeich:Hum        2.45347    1.66790   1.471    0.145\nHabWald:Hum        -0.68025    1.77685  -0.383    0.703\nTemp:HabTeich:Hum  -0.10959    0.09360  -1.171    0.245\nTemp:HabWald:Hum    0.08468    0.12569   0.674    0.503\n\nResidual standard error: 4.585 on 78 degrees of freedom\nMultiple R-squared:  0.9165,    Adjusted R-squared:  0.9047 \nF-statistic: 77.82 on 11 and 78 DF,  p-value: &lt; 2.2e-16\n\n\n\ndrop1(Mod, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp * Hab * Hum\n             Df Sum of Sq    RSS    AIC F value Pr(&gt;F)\n&lt;none&gt;                    1639.9 285.23               \nTemp:Hab:Hum  2    54.349 1694.2 284.17  1.2926 0.2804\n\nMod1&lt;-update(Mod, ~.-Temp:Hab:Hum) ; drop1(Mod1, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum + Hab:Hum\n         Df Sum of Sq    RSS    AIC F value Pr(&gt;F)\n&lt;none&gt;                1694.2 284.17               \nTemp:Hab  2    38.176 1732.4 282.17  0.9013 0.4101\nTemp:Hum  1     2.864 1697.1 282.32  0.1353 0.7140\nHab:Hum   2    31.542 1725.8 281.82  0.7447 0.4781\n\n\n\nMod2&lt;-update(Mod1, ~.-Temp:Hum) ; drop1(Mod2, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab + Hab:Hum\n         Df Sum of Sq    RSS    AIC F value Pr(&gt;F)\n&lt;none&gt;                1697.1 282.32               \nTemp:Hab  2    38.137 1735.2 280.32  0.9101 0.4065\nHab:Hum   2    36.434 1733.5 280.23  0.8695 0.4230\n\n\n\nMod3&lt;-update(Mod2, ~.-Hab:Hum) ; drop1(Mod3, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab\n         Df Sum of Sq    RSS    AIC F value  Pr(&gt;F)  \n&lt;none&gt;                1733.5 280.23                  \nHum       1      0.29 1733.8 278.24  0.0139 0.90640  \nTemp:Hab  2    147.81 1881.3 283.59  3.5386 0.03351 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nMod4&lt;-update(Mod3, ~.-Hum) ; drop1(Mod4, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Temp:Hab\n         Df Sum of Sq    RSS    AIC F value Pr(&gt;F)  \n&lt;none&gt;                1733.8 278.24                 \nTemp:Hab  2    148.93 1882.7 281.66  3.6076 0.0314 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(Mod4)\n\n\nCall:\nlm(formula = Akt ~ Temp + Hab + Temp:Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp:HabTeich   0.9145     0.5128   1.783  0.07812 . \nTemp:HabWald   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,    Adjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: &lt; 2.2e-16\n\n\n\nOption\n\n\nMod.H=lm(Akt~Hum*Hab, data=dat)\ndrop1(Mod.H, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Hum * Hab\n        Df Sum of Sq    RSS    AIC F value  Pr(&gt;F)  \n&lt;none&gt;               1887.0 285.86                  \nHum:Hab  2    164.72 2051.7 289.39  3.6665 0.02974 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(Mod.H)\n\n\nCall:\nlm(formula = Akt ~ Hum * Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.5959  -2.9024   0.0721   3.1631  10.2446 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   10.2926     7.2294   1.424   0.1582  \nHum            0.3191     0.1515   2.106   0.0382 *\nHabTeich      -4.7113    10.9687  -0.430   0.6686  \nHabWald       -6.1098    11.4749  -0.532   0.5958  \nHum:HabTeich   0.4825     0.2181   2.212   0.0297 *\nHum:HabWald   -0.1044     0.2402  -0.434   0.6650  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 84 degrees of freedom\nMultiple R-squared:  0.9039,    Adjusted R-squared:  0.8982 \nF-statistic:   158 on 5 and 84 DF,  p-value: &lt; 2.2e-16\n\n\n\nOption\n\n\n\nMod.T=lm(Akt~Temp*Hab, data=dat)\ndrop1(Mod.T, test=\"F\")\n\nSingle term deletions\n\nModel:\nAkt ~ Temp * Hab\n         Df Sum of Sq    RSS    AIC F value Pr(&gt;F)  \n&lt;none&gt;                1733.8 278.24                 \nTemp:Hab  2    148.93 1882.7 281.66  3.6076 0.0314 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(Mod.T)\n\n\nCall:\nlm(formula = Akt ~ Temp * Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp:HabTeich   0.9145     0.5128   1.783  0.07812 . \nTemp:HabWald   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,    Adjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: &lt; 2.2e-16\n\n\nOption 1 und 3 führen zum gleichen Modell. Aber auch Option 2 liefert ein sehr gutes Modell mit hohem R² und signifikannter Interaktion.\nWir könnten beide Modelle per AIC vergleichen. Mod.T hat den niedrigeren AIC und wäre damit besser. Mehr zum AIC kommt weiter unten.\n\nAIC(Mod.H, Mod.T)\n\n      df      AIC\nMod.H  7 543.2706\nMod.T  7 535.6523"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellselektion-basierend-auf-informationskriterien",
    "href": "Themen/06/06_StatMod.html#modellselektion-basierend-auf-informationskriterien",
    "title": "Statistische Modellierung",
    "section": "Modellselektion basierend auf Informationskriterien",
    "text": "Modellselektion basierend auf Informationskriterien\nWenn wir eine Vielzahl an Erklärungsvariablen haben und damit eine Vielzahl an potentiellen Erklärungsmodellen, führt eine schrittweise Vereinfachung zu vielen aufeinanderfolgenden Signifikanztests. Die durchgeführten Signifikanztests sind nicht voneinander unabhängig. Das Problem des multiplen Testens tritt auf. Der p-Wert verliert seine eigentliche Bedeutung und müsste um die Anzahl der Tests korrigiert werden. Daher steht diese Vorgehensweise bei vielen Anwendern in der Kritik.\nBesser ist es, die Modell- bzw. Variablenselektion basierend auf Informationskriterien durchzuführen.\nInformationskriterien wägen für uns zwischen der Anpassungsgüte (fit) und der Komplexität (Anzahl Parameter k) des Modells ab:\n\nDas Akaikes Informationskriterium (Akaike Information Criterion - AIC) berechnet sich aus der Log-Likelihood und der Anzahl Modellparameter.\n\nDas korrigierte Akaikes Informationskriterium (AICc) bestraft stärker um die Anzahl der Modellparameter, wenn der Stichprobenumfang klein ist und verhindert damit stärker den Overfit als AIC. Daumenregel: Nutze AICc wenn das Verhältnis aus Stichprobenumfang (n) zu Anzahl Modellparameter (k) n/k &lt; 40 ist.\n\nBayessches Informationskriterium (Bayesian Information Criterion - BIC) berücksichtigt neben Log-likelihood und Anzahl Modellparametern auch den Stichprobenumfang.\n\n\n\n\n\n\n\nWichtig\n\n\n\nJe niedriger der AIC (AICc, BIC), desto besser das Modell. Es zählt nicht der absolute Wert (z.B. AIC = 100 ist unwichtig).\n\n\nBeispiel:\n\n\n\nModell\nAIC\n\n\n\n\nModell 1\n100\n\n\nModell 2\n98.8\n\n\nModell 3\n108\n\n\n\nDamit wäre Modell 2 das bessere Modell.\nWährend die absoluten AIC-Werte also keine Bedeutung haben, können die delta AIC-Werte genutzt werden, um das Level of Empirical Support des jeweiligen Modells einzuordnen. Burnham und Anderson (2002) Model Selection and Multimodel Inference Seite 170 geben folgende Kennwerte an:\n\n\n\ndelta AIC\nLevel of Empirical Support\n\n\n\n\n0-2\nsubstantial\n\n\n4-7\nconsiderably less\n\n\n&gt; 10\nnone\n\n\n\nEntsprechend wären Modell 2 und Modell 1 von Bedeutung, während Modell 3 keine Berücksichtigung erfahren muss.\n\n\n\n\n\n\nWichtig\n\n\n\nEs können nur Modelle verglichen werden, die auf den gleichen Datensatz (i.e. gleiche Abhängige y) gefittet wurden.\n\n\nVon einem Vergleich von Modellen, die mit verschiedenen R-Packages gefitted wurden, würde ich abraten.\nAuch negative AIC-Werte können auftreten. Auch hier gilt, je kleiner desto besser."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#schrittweise-verfahren-basierend-auf-aic-mit-step",
    "href": "Themen/06/06_StatMod.html#schrittweise-verfahren-basierend-auf-aic-mit-step",
    "title": "Statistische Modellierung",
    "section": "Schrittweise Verfahren basierend auf AIC mit step()",
    "text": "Schrittweise Verfahren basierend auf AIC mit step()\nMit der Funktion step() kann eine Modellselektion automatisiert auf Basis des AIC erfolgen. Hier ein Beispiel für eine Rückwärtsselektion, bei dem ausgehend vom vollen Modell schrittweise Erklärungsvariablen entfernt werden und die daraus resultierenden Modelle via AIC verglichen werden. Diese Prozedur stoppt, wenn beim Entfernen der Variablen der AIC (wieder) ansteigen würde.\n\nstep backward\n\nmod.b&lt;-step(mod)\n\nStart:  AIC=-127.08\nWeeds ~ Arab * Man * SQ\n\n              Df  Sum of Sq     RSS     AIC\n- Arab:Man:SQ  1 0.00087887 0.67736 -129.03\n&lt;none&gt;                      0.67648 -127.08\n\nStep:  AIC=-129.03\nWeeds ~ Arab + Man + SQ + Arab:Man + Arab:SQ + Man:SQ\n\n           Df Sum of Sq     RSS      AIC\n- Arab:SQ   1   0.00958 0.68695 -130.525\n- Man:SQ    1   0.02171 0.69908 -129.894\n&lt;none&gt;                  0.67736 -129.030\n- Arab:Man  1   1.48614 2.16351  -89.224\n\nStep:  AIC=-130.52\nWeeds ~ Arab + Man + SQ + Arab:Man + Man:SQ\n\n           Df Sum of Sq     RSS      AIC\n- Man:SQ    1   0.02135 0.70830 -131.423\n&lt;none&gt;                  0.68695 -130.525\n- Arab:Man  1   1.59208 2.27903  -89.352\n\nStep:  AIC=-131.42\nWeeds ~ Arab + Man + SQ + Arab:Man\n\n           Df Sum of Sq     RSS      AIC\n- SQ        1   0.00188 0.71018 -133.327\n&lt;none&gt;                  0.70830 -131.423\n- Arab:Man  1   1.66223 2.37052  -89.935\n\nStep:  AIC=-133.33\nWeeds ~ Arab + Man + Arab:Man\n\n           Df Sum of Sq     RSS     AIC\n&lt;none&gt;                  0.71018 -133.33\n- Arab:Man  1    1.7458 2.45599  -90.66\n\nsummary(mod.b)\n\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nstep forward\nBeim Vorwärtsverfahren müssen wir zunächst das Null-Modell fitten\n\nmod0&lt;-lm(Weeds~1, data=of) \n\nund dann die Argumente scope und direction bedienen.\n\nmod.fw=step(mod0, scope=list(lower=mod0, upper=mod), direction=\"forward\")\n\nStart:  AIC=-28.64\nWeeds ~ 1\n\n       Df Sum of Sq     RSS     AIC\n+ Man   1    6.9169  8.4531 -48.164\n+ Arab  1    6.0033  9.3667 -44.469\n&lt;none&gt;              15.3700 -28.640\n+ SQ    1    0.1196 15.2504 -26.921\n\nStep:  AIC=-48.16\nWeeds ~ Man\n\n       Df Sum of Sq    RSS     AIC\n+ Arab  1    5.9971 2.4560 -90.660\n+ SQ    1    0.4693 7.9838 -48.220\n&lt;none&gt;              8.4531 -48.164\n\nStep:  AIC=-90.66\nWeeds ~ Man + Arab\n\n           Df Sum of Sq     RSS      AIC\n+ Arab:Man  1   1.74581 0.71018 -133.327\n&lt;none&gt;                  2.45599  -90.660\n+ SQ        1   0.08547 2.37052  -89.935\n\nStep:  AIC=-133.33\nWeeds ~ Man + Arab + Man:Arab\n\n       Df Sum of Sq     RSS     AIC\n&lt;none&gt;              0.71018 -133.33\n+ SQ    1  0.001882 0.70830 -131.42\n\n\n\nsummary(mod.fw)\n\n\nCall:\nlm(formula = Weeds ~ Man + Arab + Man:Arab, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg:Arab  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nstep both\nMit dem Argument direction=\"both\" wird die Vorwärts- und Rückwärtsselektion kombiniert.\n\nmod.both=step(mod0, scope=list(upper=mod), direction=\"both\")\n\nStart:  AIC=-28.64\nWeeds ~ 1\n\n       Df Sum of Sq     RSS     AIC\n+ Man   1    6.9169  8.4531 -48.164\n+ Arab  1    6.0033  9.3667 -44.469\n&lt;none&gt;              15.3700 -28.640\n+ SQ    1    0.1196 15.2504 -26.921\n\nStep:  AIC=-48.16\nWeeds ~ Man\n\n       Df Sum of Sq     RSS     AIC\n+ Arab  1    5.9971  2.4560 -90.660\n+ SQ    1    0.4693  7.9838 -48.220\n&lt;none&gt;               8.4531 -48.164\n- Man   1    6.9169 15.3700 -28.640\n\nStep:  AIC=-90.66\nWeeds ~ Man + Arab\n\n           Df Sum of Sq    RSS      AIC\n+ Arab:Man  1    1.7458 0.7102 -133.327\n&lt;none&gt;                  2.4560  -90.660\n+ SQ        1    0.0855 2.3705  -89.935\n- Arab      1    5.9971 8.4531  -48.164\n- Man       1    6.9107 9.3667  -44.469\n\nStep:  AIC=-133.33\nWeeds ~ Man + Arab + Man:Arab\n\n           Df Sum of Sq     RSS     AIC\n&lt;none&gt;                  0.71018 -133.33\n+ SQ        1   0.00188 0.70830 -131.42\n- Man:Arab  1   1.74581 2.45599  -90.66\n\n\n\nsummary(mod.both)\n\n\nCall:\nlm(formula = Weeds ~ Man + Arab + Man:Arab, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg:Arab  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\nAlle drei Verfahren haben zum gleichen besten Modell geführt. Das ist nicht immer so. Zusätzlich wird mit der Funktion step() immer nur ein bestes Modell selektiert und es bleibt offen, ob es noch andere ähnlich gute Modelle gibt."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#übung-6.2.",
    "href": "Themen/06/06_StatMod.html#übung-6.2.",
    "title": "Statistische Modellierung",
    "section": "Übung 6.2.",
    "text": "Übung 6.2.\n\nModelliere die Aktivität der Lurche mit der step-Funktion.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nstep(Mod)\n\nStart:  AIC=285.23\nAkt ~ Temp * Hab * Hum\n\n               Df Sum of Sq    RSS    AIC\n- Temp:Hab:Hum  2    54.349 1694.2 284.17\n&lt;none&gt;                      1639.9 285.23\n\nStep:  AIC=284.16\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum + Hab:Hum\n\n           Df Sum of Sq    RSS    AIC\n- Hab:Hum   2    31.542 1725.8 281.82\n- Temp:Hab  2    38.176 1732.4 282.17\n- Temp:Hum  1     2.864 1697.1 282.32\n&lt;none&gt;                  1694.2 284.17\n\nStep:  AIC=281.82\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum\n\n           Df Sum of Sq    RSS    AIC\n- Temp:Hum  1     7.757 1733.5 280.23\n- Temp:Hab  2    71.066 1796.8 281.46\n&lt;none&gt;                  1725.8 281.82\n\nStep:  AIC=280.23\nAkt ~ Temp + Hab + Hum + Temp:Hab\n\n           Df Sum of Sq    RSS    AIC\n- Hum       1      0.29 1733.8 278.24\n&lt;none&gt;                  1733.5 280.23\n- Temp:Hab  2    147.81 1881.3 283.59\n\nStep:  AIC=278.24\nAkt ~ Temp + Hab + Temp:Hab\n\n           Df Sum of Sq    RSS    AIC\n&lt;none&gt;                  1733.8 278.24\n- Temp:Hab  2    148.93 1882.7 281.66\n\n\n\nCall:\nlm(formula = Akt ~ Temp + Hab + Temp:Hab, data = dat)\n\nCoefficients:\n  (Intercept)           Temp       HabTeich        HabWald  Temp:HabTeich  \n       9.3750         1.1049         4.6331        -2.6065         0.9145  \n Temp:HabWald  \n      -0.5432  \n\n\n\nMod0&lt;-lm(Akt~1, data=dat) \nMod.fw=step(Mod0, scope=list(lower=Mod0, upper=Mod), direction=\"forward\")\n\nStart:  AIC=486.68\nAkt ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ Hab   2   17034.7  2602.6 308.80\n+ Temp  1    7778.7 11858.7 443.29\n+ Hum   1    4794.1 14843.3 463.49\n&lt;none&gt;              19637.4 486.68\n\nStep:  AIC=308.8\nAkt ~ Hab\n\n       Df Sum of Sq    RSS    AIC\n+ Temp  1    719.91 1882.7 281.66\n+ Hum   1    550.96 2051.7 289.39\n&lt;none&gt;              2602.6 308.80\n\nStep:  AIC=281.66\nAkt ~ Hab + Temp\n\n           Df Sum of Sq    RSS    AIC\n+ Temp:Hab  2   148.927 1733.8 278.24\n&lt;none&gt;                  1882.7 281.66\n+ Hum       1     1.406 1881.3 283.59\n\nStep:  AIC=278.24\nAkt ~ Hab + Temp + Hab:Temp\n\n       Df Sum of Sq    RSS    AIC\n&lt;none&gt;              1733.8 278.24\n+ Hum   1    0.2905 1733.5 280.23\n\n\n\nMod.both=step(Mod0, scope=list(upper=Mod), direction=\"both\")\n\nStart:  AIC=486.68\nAkt ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ Hab   2   17034.7  2602.6 308.80\n+ Temp  1    7778.7 11858.7 443.29\n+ Hum   1    4794.1 14843.3 463.49\n&lt;none&gt;              19637.4 486.68\n\nStep:  AIC=308.8\nAkt ~ Hab\n\n       Df Sum of Sq     RSS    AIC\n+ Temp  1     719.9  1882.7 281.66\n+ Hum   1     551.0  2051.7 289.39\n&lt;none&gt;               2602.6 308.80\n- Hab   2   17034.7 19637.4 486.68\n\nStep:  AIC=281.66\nAkt ~ Hab + Temp\n\n           Df Sum of Sq     RSS    AIC\n+ Temp:Hab  2     148.9  1733.8 278.24\n&lt;none&gt;                   1882.7 281.66\n+ Hum       1       1.4  1881.3 283.59\n- Temp      1     719.9  2602.6 308.80\n- Hab       2    9976.0 11858.7 443.29\n\nStep:  AIC=278.24\nAkt ~ Hab + Temp + Hab:Temp\n\n           Df Sum of Sq    RSS    AIC\n&lt;none&gt;                  1733.8 278.24\n+ Hum       1      0.29 1733.5 280.23\n- Hab:Temp  2    148.93 1882.7 281.66"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-dregde",
    "href": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-dregde",
    "title": "Statistische Modellierung",
    "section": "Modellvergleiche basierend auf AIC mit dregde()",
    "text": "Modellvergleiche basierend auf AIC mit dregde()\nMit der Funktion dredge() aus dem Paket MuMIn können verschiedene candidate models (i.e. alle Kombinationsmöglichkeiten zwischen den Erklärungsvariablen) anhand eines Informationskriteriums z.B. rank = \"AICc\" verglichen werden. Weitere Informationskriterien werden über das Argument extra = alist(AICc, AIC, BIC, Cp, \"R^2\") berechnet. Zudem wird auch das Akaike Gewicht (weight) angegeben, welches eine relatives Maß für die Wahrscheinlichkeit (englisch: rate of support or evidence) ist, dass das jeweilige Modell das bessere unter den candidate models ist. Im Allgemeinen haben Modelle innerhalb von delta AIC &lt; 2 einen ähnlich guten support.\n\nlibrary(MuMIn)\n\nRegistered S3 method overwritten by 'MuMIn':\n  method        from \n  nobs.multinom broom\n\ndd=dredge(mod)\n\nError in dredge(mod): 'global.model''s 'na.action' argument is not set and options('na.action') is \"na.omit\"\n\n\nWir müssen im globalen Modell mod das Argument na.action = na.fail setzen oder die R-Optionen mit options(na.action = \"na.fail\") verändern.\n\n\n\n\n\n\nWichtig\n\n\n\nEs dürfen keine missing values (NA) sowohl in der Abhängigen als auch in den Erklärungsvariablen vorkommen. Nutze ggfls. die Funktion complete.cases().\n\n\n\nmod&lt;-lm(Weeds~Arab*Man*SQ, data=of, na.action=na.fail)\ndd=dredge(mod, rank = \"AICc\", extra = alist(AICc, AIC, BIC, \"R^2\")) \n\nFixed term is \"(Intercept)\"\n\n\nMit dem Argument m.lim=c(0,4) kann man die Anzahl der Parameter beschränken, z.B. auf minimal 0 und maximal 4 Parameter. Die obige Funktion würde dann so aussehen: dredge(mod, rank = \"AICc\", extra = alist(AICc, AIC, BIC, \"R^2\"), m.lim=c(0,4)). Da wir aber ein recht überschaubares Modell haben, ist dies nicht nötig.\n\ndd\n\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n    (Int)       Arb Man         SQ Arb:Man     Arb:SQ Man:SQ Arb:Man:SQ   AICc\n12  3.984 -0.027250   +                  +                              -27.16\n16  4.025 -0.027390   + -0.0004843       +                              -24.36\n48  3.910 -0.027010   +  0.0008750       +                 +            -22.36\n32  3.807 -0.023870   +  0.0026240       + -5.212e-05                   -21.73\n64  3.687 -0.023420   +  0.0040560       + -5.315e-05      +            -19.53\n128 3.748 -0.024400   +  0.0031810       + -3.852e-05      +          + -15.99\n4   3.408 -0.017640   +                                                  14.79\n8   3.173 -0.017290   +  0.0031580                                       16.23\n24  2.453 -0.005464   +  0.0138700         -1.828e-04                    17.29\n40  2.961 -0.016800   +  0.0058460                         +             17.71\n56  2.251 -0.005091   +  0.0164200         -1.810e-04      +             18.94\n3   2.351             +                                                  56.75\n39  1.399             +  0.0140300                         +             56.85\n7   1.856             +  0.0073020                                       57.23\n2   3.847 -0.017650                                                      60.44\n6   3.884 -0.017710     -0.0005160                                       62.98\n22  4.612 -0.030090     -0.0116100          1.917e-04                    65.15\n1   2.789                                                                75.89\n5   2.549                0.0036570                                       77.99\n       AIC     BIC      R^2 df  logLik   AICc  delta weight\n12  -29.16 -21.250 0.953800  5  19.582 -27.16   0.00  0.700\n16  -27.26 -17.760 0.953900  6  19.630 -24.36   2.80  0.172\n48  -26.36 -15.280 0.955300  7  20.181 -22.36   4.80  0.063\n32  -25.73 -14.650 0.954500  7  19.865 -21.73   5.43  0.046\n64  -24.87 -12.200 0.955900  8  20.433 -19.53   7.63  0.015\n128 -22.91  -8.662 0.956000  9  20.457 -15.99  11.17  0.003\n4    13.50  19.840 0.840200  4  -2.752  14.79  41.96  0.000\n8    14.23  22.150 0.845800  5  -2.114  16.23  43.39  0.000\n24   14.39  23.900 0.853400  6  -1.197  17.29  44.45  0.000\n40   14.81  24.310 0.851700  6  -1.406  17.71  44.87  0.000\n56   14.94  26.020 0.859200  7  -0.470  18.94  46.10  0.000\n3    56.00  60.750 0.450000  3 -25.000  56.75  83.91  0.000\n39   54.85  62.770 0.523400  5 -22.424  56.85  84.01  0.000\n7    55.94  62.280 0.480600  4 -23.972  57.23  84.40  0.000\n2    59.69  64.450 0.390600  3 -26.847  60.44  87.61  0.000\n6    61.69  68.020 0.390700  4 -26.843  62.98  90.14  0.000\n22   63.15  71.060 0.399800  5 -26.573  65.15  92.31  0.000\n1    75.52  78.690 0.000000  2 -35.762  75.89 103.05  0.000\n5    77.24  81.990 0.007784  3 -35.621  77.99 105.16  0.000\nModels ranked by AICc(x) \n\n\nWurden sehr viele Modelle gefittet, kann man mit dem folgenden Befehl die Top 5 sehen.\n\ndd[1:5]# die besten 5 Modelle nach AICc\n\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n   (Int)      Arb Man         SQ Arb:Man     Arb:SQ Man:SQ   AICc    AIC    BIC\n12 3.984 -0.02725   +                  +                   -27.16 -29.16 -21.25\n16 4.025 -0.02739   + -0.0004843       +                   -24.36 -27.26 -17.76\n48 3.910 -0.02701   +  0.0008750       +                 + -22.36 -26.36 -15.28\n32 3.807 -0.02387   +  0.0026240       + -5.212e-05        -21.73 -25.73 -14.65\n64 3.687 -0.02342   +  0.0040560       + -5.315e-05      + -19.53 -24.87 -12.20\n      R^2 df logLik   AICc delta weight\n12 0.9538  5 19.582 -27.16  0.00  0.702\n16 0.9539  6 19.630 -24.36  2.80  0.173\n48 0.9553  7 20.181 -22.36  4.80  0.064\n32 0.9545  7 19.865 -21.73  5.43  0.046\n64 0.9559  8 20.433 -19.53  7.63  0.015\nModels ranked by AICc(x) \n\n\nDer Output zeigt uns\n\ndas Modell\ndie Modellparameter: (Int) für Intercept, Arb, Man, SQ, Arb:Ma, Arb:SQ, und Man:SQ\n\nwobei für Faktoren nur ein + angezeigt wird, wenn diese im Modell enthalten sind\nfür kontinuierliche Erklärungsvariablen wird der geschätzte Koeffizient angezeigt\n\ndie Informationskriterien: AICc, AIC, BIC, R²\ndie degree of freedoms und die Log-Likelihood\ndas Informationskriterium, welches zum Vergleich der Modelle genutzt wurde (hier AICc)\ndas daraus berechnete delta (hier delta AICc)\ndas Akaike weight, welches alle candidate models vergleicht (die Summe ergibt 1) und damit ein Maß für relative Güte der Modelle ist.\n\nMit der Funktion subset() werden die Top-Modelle innerhalb delta AICc &lt; 4 (oder &lt;2) angezeigt.\n\nsubset(dd, delta &lt; 4) \n\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n   (Int)      Arb Man         SQ Arb:Man   AICc    AIC    BIC    R^2 df logLik\n12 3.984 -0.02725   +                  + -27.16 -29.16 -21.25 0.9538  5 19.582\n16 4.025 -0.02739   + -0.0004843       + -24.36 -27.26 -17.76 0.9539  6 19.630\n     AICc delta weight\n12 -27.16   0.0  0.802\n16 -24.36   2.8  0.198\nModels ranked by AICc(x) \n\n\nZur Präsentation der Ergebnisse würde man zur obigen Tabelle noch das globale Modell und das Nullmodell hinzufügen.\nDas beste Modell mit dem niedrigsten AICc ist wieder:\nWeeds ~ Arab + Man + Arab:Man\nWir können auf das beste Model mit der Funktion get.models() zugreifen.\n\nsummary(get.models(dd, 1)[[1]])\n\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man + 1, data = of, na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\n\nmod.dd=get.models(dd, 1)[[1]]\n\nDie Bedeutung der Erklärungsvariablen (Importance) kann durch das sum of Akaike weight berechnet werden, indem für alle Variablen die Akaike Gewichte der Modelle aufsummiert werden, in denen die Variable enthalten ist. Die entsprechenden sum of Akaike weights variieren dann zwischen 1 (wichtig) und 0 (unwichtig).\nMit der Funktion sw() wird das sum of Akaike weight über alle Modelle berechnet:\n\nsw(dd)\n\n                     Arab  Man   Arab:Man SQ    Man:SQ Arab:SQ Arab:Man:SQ\nSum of weights:          1     1     1      0.3  0.08   0.06   &lt;0.01      \nN containing models:    14    14     6       14     6      6       1      \n\n\nMit dem Argument subset wird das sum of Akaike weight über alle Modelle innerhalb delta AICc &lt; 4 berechnet:\n\nsw(subset(dd, delta &lt;= 4))\n\n                     Arab Man Arab:Man SQ \nSum of weights:      1.0  1.0 1.0      0.2\nN containing models:   2    2   2        1\n\n\nBurnham and Anderson (2002) empfehlen die erste Methode."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-eigenem-set-an-candidate-models",
    "href": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-eigenem-set-an-candidate-models",
    "title": "Statistische Modellierung",
    "section": "Modellvergleiche basierend auf AIC mit eigenem Set an Candidate Models",
    "text": "Modellvergleiche basierend auf AIC mit eigenem Set an Candidate Models\nWenn man ein sehr komplexes globales Modell mit vielen Erklärungsvariablen und Interaktionen hat, kann das zu sehr vielen candidate models führen. Das wird dann auch gerne als “fishing” bezeichnet und wird ebenso wenig gern gesehen. Daher empfehlen Burnham und Anderson (2002) a priori ein Set an candidate models zu erstellen und diese zu vergleichen.\nAuch hierfür kann das Packet MuMIn genutzt werden.\nBeispiel angepasst aus: https://sites.google.com/site/rforfishandwildlifegrads/home/mumin_usage_examples\n\nlibrary(MuMIn)\noptions(na.action = \"na.fail\") # wir ändern die globalen Optionen\n\nWir erstellen das globale Modell mod und verschiedene candidate models mod1 bis mod11 und das Nullmodell mod0. Natürlich können nur Modelle als “beste” Modelle identifiziert werden, wenn sie vorher auch gefittet wurden. Daher ist die Wahl der geeigneten candidate models die größte wissenschaftliche Herausforderung.\n\nmod&lt;-lm(Weeds~Arab*Man*SQ, data=of)\nmod1&lt;-lm(Weeds~Arab*Man+SQ, data=of)\nmod2&lt;-lm(Weeds~Arab+Man*SQ, data=of)\nmod3&lt;-lm(Weeds~Arab*SQ+Man, data=of)\nmod4&lt;-lm(Weeds~Arab*Man, data=of)\nmod5&lt;-lm(Weeds~Man*SQ, data=of)\nmod6&lt;-lm(Weeds~Arab*SQ, data=of)\nmod7&lt;-lm(Weeds~Arab+Man, data=of)\nmod8&lt;-lm(Weeds~Man+SQ, data=of)\nmod9&lt;-lm(Weeds~Arab+SQ, data=of)\nmod10&lt;-lm(Weeds~Arab+Man+SQ, data=of)\nmod0&lt;-lm(Weeds~1, data=of)\nmod11&lt;-lm(Weeds~(Arab+Man+SQ)^2, data=of)# ist das gleiche wie Arab*Man+Arab*SQ+Man*SQ\n\nWir nutzen die Funktion mod.sel(), um für alle Modelle das AICc, delta AICc und das Akaike weight zu berechnen und ins Objekt out.put zu schreiben.\n\nout.put&lt;-model.sel(mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, mod,mod0)\nout.put \n\nModel selection table \n      (Int)       Arb Man         SQ Arb:Man Man:SQ     Arb:SQ Arb:Man:SQ df\nmod4  3.984 -0.027250   +                  +                               5\nmod1  4.025 -0.027390   + -0.0004843       +                               6\nmod11 3.687 -0.023420   +  0.0040560       +      + -5.315e-05             8\nmod   3.748 -0.024400   +  0.0031810       +      + -3.852e-05          +  9\nmod7  3.408 -0.017640   +                                                  4\nmod10 3.173 -0.017290   +  0.0031580                                       5\nmod3  2.453 -0.005464   +  0.0138700                -1.828e-04             6\nmod2  2.961 -0.016800   +  0.0058460              +                        6\nmod5  1.399             +  0.0140300              +                        5\nmod8  1.856             +  0.0073020                                       4\nmod9  3.884 -0.017710     -0.0005160                                       4\nmod6  4.612 -0.030090     -0.0116100                 1.917e-04             5\nmod0  2.789                                                                2\n       logLik  AICc  delta weight\nmod4   19.582 -27.2   0.00  0.786\nmod1   19.630 -24.4   2.80  0.194\nmod11  20.433 -19.5   7.63  0.017\nmod    20.457 -16.0  11.17  0.003\nmod7   -2.752  14.8  41.96  0.000\nmod10  -2.114  16.2  43.39  0.000\nmod3   -1.197  17.3  44.45  0.000\nmod2   -1.406  17.7  44.87  0.000\nmod5  -22.424  56.8  84.01  0.000\nmod8  -23.972  57.2  84.40  0.000\nmod9  -26.843  63.0  90.14  0.000\nmod6  -26.573  65.1  92.31  0.000\nmod0  -35.762  75.9 103.05  0.000\nModels ranked by AICc(x) \n\n\nMit dem Argument rank können wir auch ein anderes Informationskriterium wählen.\n\nout.put2&lt;-model.sel(mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, mod,mod0, rank=\"AIC\")\nout.put2\n\nModel selection table \n      (Int)       Arb Man         SQ Arb:Man Man:SQ     Arb:SQ Arb:Man:SQ df\nmod4  3.984 -0.027250   +                  +                               5\nmod1  4.025 -0.027390   + -0.0004843       +                               6\nmod11 3.687 -0.023420   +  0.0040560       +      + -5.315e-05             8\nmod   3.748 -0.024400   +  0.0031810       +      + -3.852e-05          +  9\nmod7  3.408 -0.017640   +                                                  4\nmod10 3.173 -0.017290   +  0.0031580                                       5\nmod3  2.453 -0.005464   +  0.0138700                -1.828e-04             6\nmod2  2.961 -0.016800   +  0.0058460              +                        6\nmod5  1.399             +  0.0140300              +                        5\nmod8  1.856             +  0.0073020                                       4\nmod9  3.884 -0.017710     -0.0005160                                       4\nmod6  4.612 -0.030090     -0.0116100                 1.917e-04             5\nmod0  2.789                                                                2\n       logLik   AIC  delta weight\nmod4   19.582 -29.2   0.00  0.647\nmod1   19.630 -27.3   1.90  0.250\nmod11  20.433 -24.9   4.30  0.075\nmod    20.457 -22.9   6.25  0.028\nmod7   -2.752  13.5  42.67  0.000\nmod10  -2.114  14.2  43.39  0.000\nmod3   -1.197  14.4  43.56  0.000\nmod2   -1.406  14.8  43.98  0.000\nmod5  -22.424  54.8  84.01  0.000\nmod8  -23.972  55.9  85.11  0.000\nmod9  -26.843  61.7  90.85  0.000\nmod6  -26.573  63.1  92.31  0.000\nmod0  -35.762  75.5 104.69  0.000\nModels ranked by AIC(x) \n\n\nWir erstellen nun eine Tabelle mit den Informationskriterien und den Erklärungsvariablen der Modelle.\nDie [c(9,11:13)] greifen auf 4 Spalten zu und müssen bei anderen Beispielen entsprechend der Anzahl Spalten (i.e. Erklärungsvariablen) ggfls. angepasst werden.\n\nsel.table&lt;-as.data.frame(out.put)[c(9,11:13)]\nsel.table \n\n      df      AICc      delta       weight\nmod4   5 -27.16372   0.000000 7.860065e-01\nmod1   6 -24.36270   2.801024 1.937276e-01\nmod11  8 -19.53353   7.630191 1.732013e-02\nmod    9 -15.99053  11.173195 2.945762e-03\nmod7   4  14.79426  41.957989 6.086458e-10\nmod10  5  16.22886  43.392586 2.970611e-10\nmod3   6  17.29047  44.454197 1.747108e-10\nmod2   6  17.70841  44.872130 1.417643e-10\nmod5   5  56.84831  84.012037 4.492046e-19\nmod8   4  57.23396  84.397687 3.704258e-19\nmod9   4  62.97609  90.139816 2.098040e-20\nmod6   5  65.14594  92.309661 7.089866e-21\nmod0   2  75.88754 103.051259 3.297080e-23\n\n\nZur besseren Lesbarkeit runden wir die Spalten 2 und 3 auf 1 Kommastelle und Spalten 4 auf 2 Kommastellen.\n\nsel.table[,2:3]&lt;- round(sel.table[,2:3],1)\nsel.table[,4]&lt;- round(sel.table[,4],2)\n\nWir schreiben den Modellnamen in Spalte Model\n\nsel.table$Model&lt;-rownames(sel.table)\nsel.table\n\n      df  AICc delta weight Model\nmod4   5 -27.2   0.0   0.79  mod4\nmod1   6 -24.4   2.8   0.19  mod1\nmod11  8 -19.5   7.6   0.02 mod11\nmod    9 -16.0  11.2   0.00   mod\nmod7   4  14.8  42.0   0.00  mod7\nmod10  5  16.2  43.4   0.00 mod10\nmod3   6  17.3  44.5   0.00  mod3\nmod2   6  17.7  44.9   0.00  mod2\nmod5   5  56.8  84.0   0.00  mod5\nmod8   4  57.2  84.4   0.00  mod8\nmod9   4  63.0  90.1   0.00  mod9\nmod6   5  65.1  92.3   0.00  mod6\nmod0   2  75.9 103.1   0.00  mod0\n\n\n… und schreiben nun die Modellformel in diese Spalte:\n\nfor(i in 1:nrow(sel.table)) sel.table$Model[i]&lt;- as.character(formula(noquote(sel.table$Model[i]))$call)[2]\n\n\nsel.table \n\n      df  AICc delta weight                       Model\nmod4   5 -27.2   0.0   0.79          Weeds ~ Arab * Man\nmod1   6 -24.4   2.8   0.19     Weeds ~ Arab * Man + SQ\nmod11  8 -19.5   7.6   0.02 Weeds ~ (Arab + Man + SQ)^2\nmod    9 -16.0  11.2   0.00     Weeds ~ Arab * Man * SQ\nmod7   4  14.8  42.0   0.00          Weeds ~ Arab + Man\nmod10  5  16.2  43.4   0.00     Weeds ~ Arab + Man + SQ\nmod3   6  17.3  44.5   0.00     Weeds ~ Arab * SQ + Man\nmod2   6  17.7  44.9   0.00     Weeds ~ Arab + Man * SQ\nmod5   5  56.8  84.0   0.00            Weeds ~ Man * SQ\nmod8   4  57.2  84.4   0.00            Weeds ~ Man + SQ\nmod9   4  63.0  90.1   0.00           Weeds ~ Arab + SQ\nmod6   5  65.1  92.3   0.00           Weeds ~ Arab * SQ\nmod0   2  75.9 103.1   0.00                   Weeds ~ 1\n\n\nAuch hier könnten wir wieder die Tabelle auf die Modelle reduzieren innerhalb delta AICc &lt; 4 plus globales Modell und Nullmodell.\n\nsel.table[c(1,2,4,13),c(5,1:4)]\n\n                       Model df  AICc delta weight\nmod4      Weeds ~ Arab * Man  5 -27.2   0.0   0.79\nmod1 Weeds ~ Arab * Man + SQ  6 -24.4   2.8   0.19\nmod  Weeds ~ Arab * Man * SQ  9 -16.0  11.2   0.00\nmod0               Weeds ~ 1  2  75.9 103.1   0.00"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-glmulti",
    "href": "Themen/06/06_StatMod.html#modellvergleiche-basierend-auf-aic-mit-glmulti",
    "title": "Statistische Modellierung",
    "section": "Modellvergleiche basierend auf AIC mit glmulti()",
    "text": "Modellvergleiche basierend auf AIC mit glmulti()\nEin weiteres Package für Modellvergleiche ist glmulti mit gleichnamiger Funktion. Hier können wir eine Vielzahl an Erklärungsvariablen in einem Vektor (hier pred.var) im Argument xr angeben. Mit maxsize legen wir die maximale Anzahl an Erklärungsvariablen fest. Mit level=1 werden nur Haupteffekte gefittet (Bsp. models1), mit level=2 werden Haupteffekte und Zweifachinteraktionen gefittet (Bsp. models2).\n\nlibrary(glmulti)\npred.var=c(\"Arab\", \"Man\", \"SQ\")# alle Erklärungsvariablen\n\nmodels1 &lt;- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8, # max 8 Erklärungsvariablen im Modell -&gt; hier nicht wichtig   \n                     level = 1,  #  nur Haupteffekte\n                     fitfunc = lm,  # lineares Model\n                     confsetsize = 10,  # damit kann man die Anzahl der besten Modelle, die in models1 gespeichert werden, begrenzen\n                     marginality=TRUE,  # zur Erklärung vergleiche Bsp. models2 mit models3\n                     plotty = F, report = F)\ntmp_1 &lt;- weightable(models1)\ntmp_1\n\n                        model     aicc      weights\n1      Weeds ~ 1 + Man + Arab 14.79426 6.720119e-01\n2 Weeds ~ 1 + Man + Arab + SQ 16.22886 3.279881e-01\n3             Weeds ~ 1 + Man 56.75004 5.209496e-10\n4        Weeds ~ 1 + Man + SQ 57.23396 4.089908e-10\n5            Weeds ~ 1 + Arab 60.44469 8.213205e-11\n6       Weeds ~ 1 + Arab + SQ 62.97609 2.316467e-11\n7                   Weeds ~ 1 75.88754 3.640339e-14\n8              Weeds ~ 1 + SQ 77.99259 1.270677e-14\n\n\n\nmodels2 &lt;- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8, \n                     level = 2,  # fit Haupteffekte und Zweifachinteraktionen  \n                     confsetsize = 10,  \n                     marginality=TRUE,  \n                  plotty = F, report = F)\ntmp_2 &lt;- weightable(models2)\ntmp_2\n\n                                                       model      aicc\n1                          Weeds ~ 1 + Man + Arab + Man:Arab -27.16372\n2                     Weeds ~ 1 + Man + Arab + SQ + Man:Arab -24.36270\n3            Weeds ~ 1 + Man + Arab + SQ + Man:Arab + Man:SQ -22.36104\n4           Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:Arab -21.73091\n5  Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:Arab + Man:SQ -19.53353\n6                                     Weeds ~ 1 + Man + Arab  14.79426\n7                                Weeds ~ 1 + Man + Arab + SQ  16.22886\n8                      Weeds ~ 1 + Man + Arab + SQ + SQ:Arab  17.29047\n9                       Weeds ~ 1 + Man + Arab + SQ + Man:SQ  17.70841\n10            Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:SQ  18.93916\n        weights\n1  7.016487e-01\n2  1.729359e-01\n3  6.356687e-02\n4  4.638730e-02\n5  1.546125e-02\n6  5.433232e-10\n7  2.651791e-10\n8  1.559601e-10\n9  1.265495e-10\n10 6.839188e-11\n\n\nMit dem Argument marginality=FALSE werden auch Modelle mit Interaktionen ohne Haupteffekte gefittet. Hierzu gibt es geteilte Meinungen. Es entstehen mehr mögliche Modelle aus denen das/die beste/n Modell/e gewählt werden können. Gleichzeitig kann aber damit auch ein einfacheres Modell mit weniger Erklärungsvariablen gewählt werden.\nIm Bespiel models3 sieht man als zweitbestes Modell Weeds ~ Arab + Man:Arab, welches ohne Haupteffekt Man gefittet ist.\n\nmodels3 &lt;- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8,  \n                     level = 2, \n                     confsetsize = 10,  \n                     marginality=FALSE,  # fit interaction even if main term is not in the model\n                  plotty = F, report = F)\ntmp_3 &lt;- weightable(models3)\ntmp_3\n\n                                                 model      aicc    weights\n1                    Weeds ~ 1 + Man + Arab + Man:Arab -27.16372 0.32769924\n2                          Weeds ~ 1 + Arab + Man:Arab -25.96858 0.18028255\n3            Weeds ~ 1 + Arab + SQ + Man:Arab + Man:SQ -25.43742 0.13823316\n4          Weeds ~ 1 + Man + Arab + SQ:Arab + Man:Arab -24.53325 0.08795781\n5               Weeds ~ 1 + Man + Arab + SQ + Man:Arab -24.36270 0.08076828\n6                     Weeds ~ 1 + Arab + SQ + Man:Arab -23.32596 0.04809674\n7                Weeds ~ 1 + Arab + SQ:Arab + Man:Arab -23.27813 0.04696025\n8  Weeds ~ 1 + Arab + SQ + SQ:Arab + Man:Arab + Man:SQ -22.86406 0.03817823\n9      Weeds ~ 1 + Man + Arab + SQ + Man:Arab + Man:SQ -22.36104 0.02968838\n10          Weeds ~ 1 + Arab + SQ + SQ:Arab + Man:Arab -21.77388 0.02213536\n\n\nAlle hier aufgeführten Wege haben zum gleichen besten Modell geführt.\n\nsummary(mod4)\n\n\nCall:\nlm(formula = Weeds ~ Arab * Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.983767   0.097888  40.697  &lt; 2e-16 ***\nArab        -0.027254   0.001525 -17.868  &lt; 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,    Adjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nTip\n\n\n\nDie Wahl des besten Modells basiert zwar immer auf einem Informationskriterium (AIC, BIC), der/die R-UserIn kann sich aber auch für das zweit- oder drittbeste Modell entscheiden, wenn darin bspw. Erklärungsvariablen sind, die einfacher oder schneller zu messen sind und das Modell für zukünftige Vorhersagen genutzt werden soll."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#übung-6.3.",
    "href": "Themen/06/06_StatMod.html#übung-6.3.",
    "title": "Statistische Modellierung",
    "section": "Übung 6.3.",
    "text": "Übung 6.3.\n\nModelliere die Aktivität der Lurche mit der dredge-Funktion.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nBitte schau Dir die Lösung bis ganz zum Ende an.\n\nlibrary(MuMIn)\nMod=lm(Akt~Temp*Hab*Hum, data=dat, na.action = na.fail) # Modell mit korrelierten Erklärungsvaribalen\n\n\ndd=dredge(Mod)\n\nFixed term is \"(Intercept)\"\n\ndd\n\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n      (Int) Hab      Hum      Tmp Hab:Hum Hab:Tmp Hum:Tmp Hab:Hum:Tmp df\n22    9.375   +           1.10500               +                      7\n24    9.053   +  0.02051  1.06000               +                      8\n16   12.600   + -0.07901  1.14000       +                              8\n6     6.560   +           1.29900                                      5\n40   52.490   + -0.93190 -1.82300                 0.06228              7\n56   25.740   + -0.33500 -0.03249               + 0.02292              9\n48   23.910   + -0.31840  0.38980       +         0.01563              9\n8     5.786   +  0.04491  1.20600                                      6\n32   13.770   + -0.27980  1.71600       +       +                     10\n12   10.290   +  0.31910                +                              7\n64   25.150   + -0.51900  0.95400       +       + 0.01574             11\n128  44.580   + -0.92740 -0.34630       +       + 0.04262           + 13\n4     3.336   +  0.46600                                               5\n2    25.410   +                                                        4\n5   -26.060               3.70300                                      3\n39   82.750     -2.53700 -1.81600                 0.13170              5\n7   -16.430     -0.49340  4.68300                                      4\n3   -32.960      1.26400                                               3\n1    29.100                                                            2\n      logLik  AICc  delta weight\n22  -260.826 537.0   0.00  0.410\n24  -260.819 539.4   2.40  0.124\n16  -260.863 539.5   2.49  0.118\n6   -264.534 539.8   2.76  0.103\n40  -262.433 540.2   3.21  0.082\n56  -260.617 541.5   4.47  0.044\n48  -260.789 541.8   4.81  0.037\n8   -264.501 542.0   5.00  0.034\n32  -259.863 542.5   5.49  0.026\n12  -264.635 544.6   7.62  0.009\n64  -259.787 545.0   7.94  0.008\n128 -258.319 547.4  10.41  0.002\n4   -268.402 547.5  10.50  0.002\n2   -279.106 566.7  29.66  0.000\n5   -347.350 701.0 163.96  0.000\n39  -345.135 701.0 163.97  0.000\n7   -346.638 701.7 164.73  0.000\n3   -357.452 721.2 184.16  0.000\n1   -370.047 744.2 207.21  0.000\nModels ranked by AICc(x) \n\n\n\ndd[1:5]\n\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n    (Int) Hab      Hum    Tmp Hab:Hum Hab:Tmp Hum:Tmp df   logLik  AICc delta\n22  9.375   +           1.105               +          7 -260.826 537.0  0.00\n24  9.053   +  0.02051  1.060               +          8 -260.819 539.4  2.40\n16 12.600   + -0.07901  1.140       +                  8 -260.863 539.5  2.49\n6   6.560   +           1.299                          5 -264.534 539.8  2.76\n40 52.490   + -0.93190 -1.823                 0.06228  7 -262.433 540.2  3.21\n   weight\n22  0.490\n24  0.148\n16  0.141\n6   0.123\n40  0.098\nModels ranked by AICc(x) \n\n\nWir haben 5 Modelle innerhalb dAICc&lt;4 und ein bestes Modell innerhalb dAICc&lt;2.\nDas beste Modell hat die Erklärungsvariablen Habitattype und Temperatur und deren Zweifachinteraktion. Sowohl im zweit- als auch drittbesten Modell sind beide korrelierte Erklärungsvariablen enthalten.\nSchauen wir uns die Modellkoeffizienten und die Effektplots an:\n\nbestes Modell\n\n\nlibrary(effects)\n\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n\nsummary(get.models(dd, 1)[[1]])\n\n\nCall:\nlm(formula = Akt ~ Hab + Temp + Hab:Temp + 1, data = dat, na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich:Temp   0.9145     0.5128   1.783  0.07812 . \nHabWald:Temp   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,    Adjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: &lt; 2.2e-16\n\nplot(allEffects(get.models(dd, 1)[[1]]))\n\n\n\n\n\n\n\n\n\nzweitbestes Modell\n\n\nsummary(get.models(dd, 2)[[1]])\n\n\nCall:\nlm(formula = Akt ~ Hab + Hum + Temp + Hab:Temp + 1, data = dat, \n    na.action = na.fail)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.821  -2.713  -0.283   2.507  10.263 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    9.05305    6.02059   1.504   0.1365  \nHabTeich       4.60112    8.12537   0.566   0.5727  \nHabWald       -2.73638    8.05836  -0.340   0.7350  \nHum            0.02051    0.17389   0.118   0.9064  \nTemp           1.06011    0.52679   2.012   0.0474 *\nHabTeich:Temp  0.91598    0.51598   1.775   0.0795 .\nHabWald:Temp  -0.53702    0.56699  -0.947   0.3463  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.57 on 83 degrees of freedom\nMultiple R-squared:  0.9117,    Adjusted R-squared:  0.9053 \nF-statistic: 142.9 on 6 and 83 DF,  p-value: &lt; 2.2e-16\n\nplot(allEffects(get.models(dd, 2)[[1]]))\n\n\n\n\n\n\n\n\n\ndrittbestes Modell\n\n\nsummary(get.models(dd, 3)[[1]])\n\n\nCall:\nlm(formula = Akt ~ Hab + Hum + Temp + Hab:Hum + 1, data = dat, \n    na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.3545  -2.7392   0.1654   2.8545  10.4962 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  12.60260    7.02675   1.794  0.07653 . \nHabTeich     -4.18843   10.58337  -0.396  0.69330   \nHabWald      -6.13322   11.06999  -0.554  0.58104   \nHum          -0.07901    0.20786  -0.380  0.70482   \nTemp          1.14035    0.42328   2.694  0.00854 **\nHabTeich:Hum  0.46479    0.21054   2.208  0.03003 * \nHabWald:Hum  -0.07998    0.23187  -0.345  0.73103   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.572 on 83 degrees of freedom\nMultiple R-squared:  0.9116,    Adjusted R-squared:  0.9052 \nF-statistic: 142.7 on 6 and 83 DF,  p-value: &lt; 2.2e-16\n\nplot(allEffects(get.models(dd, 3)[[1]]))\n\n\n\n\n\n\n\n\nDas zweitbeste Modell zeigt sehr breite Konfidenzintervalle für die Luftfeuchte und das drittbeste Modell sehr unwahrscheinliche Zusammenhänge mit der Luftfeuchte in den verschiedenen Habitaten.\nDaher würde ich diese Modelle nicht interpretieren. Um diese Modelle aufgrund der engen Korrelation aus den candidate models auszuschließen, gibt es folgende Möglichkeit:\n\ndd1=dredge(Mod, subset = !(Temp & Hum))\n\nFixed term is \"(Intercept)\"\n\ndd1\n\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n     (Int) Hab    Hum   Tmp Hab:Hum Hab:Tmp df   logLik  AICc  delta weight\n22   9.375   +        1.105               +  7 -260.826 537.0   0.00  0.782\n6    6.560   +        1.299                  5 -264.534 539.8   2.76  0.196\n12  10.290   + 0.3191             +          7 -264.635 544.6   7.62  0.017\n4    3.336   + 0.4660                        5 -268.402 547.5  10.50  0.004\n2   25.410   +                               4 -279.106 566.7  29.66  0.000\n5  -26.060            3.703                  3 -347.350 701.0 163.96  0.000\n3  -32.960     1.2640                        3 -357.452 721.2 184.16  0.000\n1   29.100                                   2 -370.047 744.2 207.21  0.000\nModels ranked by AICc(x) \n\n\nHier werden nur Modelle verglichen, die entweder Temperatur oder Luftfeuchte enthalten."
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modelldiagnostik",
    "href": "Themen/06/06_StatMod.html#modelldiagnostik",
    "title": "Statistische Modellierung",
    "section": "Modelldiagnostik",
    "text": "Modelldiagnostik\nBevor wir das Modell interpretieren, sollten die Modellannahmen visuell überprüft werden, indem wir die Residuen des Modells plotten.\n\nlibrary(DHARMa)\n\nThis is DHARMa 0.4.7. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod4, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\nKeine Auffälligkeiten.\nNun plotten wir noch die Residuen gegen die Erklärungsvariablen\n\nplotResiduals(simulationOutput, form = of$Man)\n\n\n\n\n\n\n\n\nDie Varianzen der Residuen sind sehr ähnlich. Wir erinnern uns an den Plot Weeds ~ Man, wo starke Unterschiede in den Varianzen vorkamen. Offensichtlich hat die Erklärungsvariable Arab einen Großteil dieser Variabilität erklärt.\n\nplotResiduals(simulationOutput, form = of$Arab)\n\n\n\n\n\n\n\n\nHier sehen wir eine leichte Kurvatur bei niedrigen Werten in Arab, aber es scheint noch ok zu sein. Wir können zusätzlich noch die vom Modell vorhergesagten vs. gemessenen Daten plotten. Je enger die Beziehung, desto besser.\n\nof$fit=predict(mod4)\nggplot(of, aes(y=Weeds, x=fit, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=\"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#modellinterpretation",
    "href": "Themen/06/06_StatMod.html#modellinterpretation",
    "title": "Statistische Modellierung",
    "section": "Modellinterpretation",
    "text": "Modellinterpretation\n\nschnell und einfach mit library(effects)\n\nlibrary(effects)\nplot(allEffects(mod4))\n\n\n\n\n\n\n\n\n\nplot(Effect(c(\"Man\"), mod4))\n\n\n\n\n\n\n\nplot(Effect(c(\"Arab\"), mod4, partial.residuals=TRUE))\n\n\n\n\n\n\n\n\n\nef=allEffects(mod4, xlevels=100)    \nef1=as.data.frame(ef[[1]])  \nhead(ef1)   \n\n  Arab Man      fit         se    lower    upper\n1 21.2 con 3.405986 0.06869007 3.266069 3.545903\n2 21.9 con 3.386908 0.06777461 3.248856 3.524961\n3 22.7 con 3.365105 0.06673391 3.229173 3.501038\n4 23.4 con 3.346027 0.06582835 3.211939 3.480115\n5 24.1 con 3.326950 0.06492773 3.194696 3.459203\n6 24.9 con 3.305147 0.06390474 3.174977 3.435316\n\ntail(ef1)   \n\n    Arab Man      fit         se    lower    upper\n195 90.4 org 2.976989 0.05793205 2.858985 3.094992\n196 91.2 org 2.970414 0.05889737 2.850444 3.090384\n197 91.9 org 2.964662 0.05974927 2.842956 3.086367\n198 92.6 org 2.958909 0.06060762 2.835455 3.082363\n199 93.4 org 2.952334 0.06159616 2.826867 3.077802\n200 94.1 org 2.946582 0.06246746 2.819340 3.073824\n\n\n\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = ef1, aes(x = Arab, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Man), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef1, aes(x = Arab, y = fit))+\n  geom_point()+\n  ylab(\"Shannondiversität\")+xlab(\"Ackeranteil (%)\")\n\n\n\n\n\n\n\n\nWir sehen, dass die Diversität\n\nmit zunehmendem Ackeranteil sinkt\ngenerell höher in öko vs. konventionell ist\naber je strukturreicher eine Landschaft (je niedriger der Ackeranteil) desto kleiner fallen auch die Unterschiede zwischen öko vs. konventionell bewirtschafteten Feldern aus.\n\nWir können dies auch gezielt mit einem Posthoc-Test testen.\n\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(mod4, ~Man|Arab, at=list(Arab=c(22,80))), Letters=letters)\n\nArab = 22:\n Man emmean     SE df lower.CL upper.CL .group\n con   3.38 0.0676 32     3.25     3.52  a    \n org   3.54 0.0671 32     3.40     3.68  a    \n\nArab = 80:\n Man emmean     SE df lower.CL upper.CL .group\n con   1.80 0.0466 32     1.71     1.90  a    \n org   3.06 0.0464 32     2.97     3.16   b   \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nHier wird nun an zwei gewählten Punkten (i.e. Ackeranteil von 22% und 80%) die vorhergesagte Diversität in öko vs. kon gestestet. Bei 22% Ackeranteil unterscheidet sich die Diversität nicht signifikant zwischen öko und konventionall, bei 80% Ackeranteil schon.\nMan beachte den Unterschied zu folgendem Test, bei dem alle vorhergesagten Levels miteinander verglichen werden.\n\ncld(emmeans(mod4, ~Man+Arab, at=list(Arab=c(22,80))), sort=F, Letters=letters)\n\n Man Arab emmean     SE df lower.CL upper.CL .group\n con   22   3.38 0.0676 32     3.25     3.52  a    \n org   22   3.54 0.0671 32     3.40     3.68  a    \n con   80   1.80 0.0466 32     1.71     1.90   b   \n org   80   3.06 0.0464 32     2.97     3.16    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 4 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nDie 22% und 80% sind hier relativ willkürlich gewählt (i.e. zur Demonstration). Man hätte auch das 20- und 80-Perzentil wählen können.\n\ncld(emmeans(mod4, ~Man|Arab, at=list(Arab=quantile(of$Arab, p=c(0.2,0.8)))), sort=F, Letters=letters)\n\nArab = 36.1:\n Man emmean     SE df lower.CL upper.CL .group\n con   3.00 0.0505 32     2.90     3.10  a    \n org   3.42 0.0502 32     3.32     3.53   b   \n\nArab = 84.5:\n Man emmean     SE df lower.CL upper.CL .group\n con   1.68 0.0514 32     1.58     1.79  a    \n org   3.03 0.0511 32     2.92     3.13   b   \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\n\nWeitere Alternativen zur Modellinterpretation, i.e. Abbildung der Ergebnisse:\n\nmit geom_smooth\n\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nmit predict\nWir erstellen einen Testdatensatz td mit allen im besten Modell (mod4) enthaltenen Variablen.\n\nsummary(of)\n\n       ID         Man          Arab             SQ            Weeds      \n Min.   : 1.00   con:18   Min.   :21.20   Min.   :38.00   Min.   :1.410  \n 1st Qu.: 9.75   org:18   1st Qu.:41.15   1st Qu.:54.75   1st Qu.:2.438  \n Median :18.50            Median :60.50   Median :62.50   Median :2.980  \n Mean   :18.50            Mean   :59.89   Mean   :65.83   Mean   :2.789  \n 3rd Qu.:27.25            3rd Qu.:80.65   3rd Qu.:79.25   3rd Qu.:3.290  \n Max.   :36.00            Max.   :94.10   Max.   :95.00   Max.   :3.570  \n    Man.con         fit       \n Min.   :0.0   Min.   :1.419  \n 1st Qu.:0.0   1st Qu.:2.373  \n Median :0.5   Median :3.006  \n Mean   :0.5   Mean   :2.789  \n 3rd Qu.:1.0   3rd Qu.:3.295  \n Max.   :1.0   Max.   :3.544  \n\ntd&lt;-expand.grid(Arab=seq(21,94,length=10), Man=c(\"con\",\"org\")) \ntd\n\n       Arab Man\n1  21.00000 con\n2  29.11111 con\n3  37.22222 con\n4  45.33333 con\n5  53.44444 con\n6  61.55556 con\n7  69.66667 con\n8  77.77778 con\n9  85.88889 con\n10 94.00000 con\n11 21.00000 org\n12 29.11111 org\n13 37.22222 org\n14 45.33333 org\n15 53.44444 org\n16 61.55556 org\n17 69.66667 org\n18 77.77778 org\n19 85.88889 org\n20 94.00000 org\n\n\nund nutzen in der predict-Funktion das Argument interval = \"confidence\" für die Berechnung des Konfidenzintervalls.\nDas Konfidenzintervall\n\nzeigt an, in welchem Bereich mit 95 %-er Wahrscheinlichkeit unser “wahrer” Mittelwert liegt\nwird kleiner mit größer werdendem Stichprobenumfang\n\n\ntd&lt;-data.frame(td, predict(mod4, newdata=td, interval = \"confidence\"))\ntd\n\n       Arab Man      fit      lwr      upr\n1  21.00000 con 3.411437 3.270985 3.551888\n2  29.11111 con 3.190378 3.070923 3.309832\n3  37.22222 con 2.969319 2.868908 3.069730\n4  45.33333 con 2.748260 2.663611 2.832909\n5  53.44444 con 2.527201 2.452914 2.601488\n6  61.55556 con 2.306142 2.234435 2.377849\n7  69.66667 con 2.085083 2.007396 2.162771\n8  77.77778 con 1.864025 1.773477 1.954572\n9  85.88889 con 1.642966 1.535111 1.750820\n10 94.00000 con 1.421907 1.294093 1.549721\n11 21.00000 org 3.547325 3.407978 3.686672\n12 29.11111 org 3.480667 3.362037 3.599297\n13 37.22222 org 3.414009 3.314143 3.513875\n14 45.33333 org 3.347351 3.262982 3.431721\n15 53.44444 org 3.280693 3.206479 3.354908\n16 61.55556 org 3.214035 3.142327 3.285744\n17 69.66667 org 3.147377 3.069782 3.224973\n18 77.77778 org 3.080719 2.990472 3.170967\n19 85.88889 org 3.014061 2.906763 3.121360\n20 94.00000 org 2.947404 2.820416 3.074391\n\n\nAlternativ nutzen wir die predict-Funktion mit dem Argument se.fit für die Berechnung der Standardfehler, die wir für die Berechnung des Konfidenzintervalls nutzen.\n\np&lt;-predict(mod4, newdata=td, se.fit=T) \nstr(p)\n\nList of 4\n $ fit           : Named num [1:20] 3.41 3.19 2.97 2.75 2.53 ...\n  ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ...\n $ se.fit        : Named num [1:20] 0.069 0.0586 0.0493 0.0416 0.0365 ...\n  ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ...\n $ df            : int 32\n $ residual.scale: num 0.149\n\ntd$p&lt;-p$fit\ntd$p.se&lt;-p$se.fit\n#t-Wert für Konfidenzintervall\nt.val&lt;-qt(0.975, mod4$df)\nmod4$df\n\n[1] 32\n\n#berechnet Konfidenzintervall t * SE\ntd$CI.lwr&lt;-td$p-t.val*td$p.se\ntd$CI.upr&lt;-td$p+t.val*td$p.se\n\nDas Vorhersageintervall\n\nzeigt an, in welchem Bereich mit 95 %-er Wahrscheinlichkeit zukünftige Beobachtungen liegen\nim Allgemeinen größer (weiter) als das Konfidenzintervall\n\n\ntd$PI2=predict(mod4, td, interval=\"prediction\")\nhead(td)\n\n      Arab Man      fit      lwr      upr        p       p.se   CI.lwr   CI.upr\n1 21.00000 con 3.411437 3.270985 3.551888 3.411437 0.06895243 3.270985 3.551888\n2 29.11111 con 3.190378 3.070923 3.309832 3.190378 0.05864438 3.070923 3.309832\n3 37.22222 con 2.969319 2.868908 3.069730 2.969319 0.04929514 2.868908 3.069730\n4 45.33333 con 2.748260 2.663611 2.832909 2.748260 0.04155695 2.663611 2.832909\n5 53.44444 con 2.527201 2.452914 2.601488 2.527201 0.03647013 2.452914 2.601488\n6 61.55556 con 2.306142 2.234435 2.377849 2.306142 0.03520344 2.234435 2.377849\n   PI2.fit  PI2.lwr  PI2.upr\n1 3.411437 3.077060 3.745813\n2 3.190378 2.864263 3.516492\n3 2.969319 2.649689 3.288949\n4 2.748260 2.433226 3.063294\n5 2.527201 2.214791 2.839611\n6 2.306142 1.994336 2.617948\n\n\nund jetzt die Abbildung mit den berechneten Intervallen\n\nmit Konfidenzintervall\n\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = lwr, ymax = upr, linetype=NA), \n              alpha = 0.2, show.legend = F)+\n  geom_line(data = td, aes(x = Arab, y = fit))+\n  geom_point()\n\n\n\n\n\n\n\n\n\n\nmit Konfidenz- und Vorhersageintervall\n\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = lwr, ymax = upr, linetype=NA), \n              alpha = 0.2, show.legend = F)+\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = PI2[,2], ymax = PI2[,3], linetype=NA), \n              alpha = 0.2, show.legend = F) +\n  geom_line(data = td, aes(x = Arab, y = fit)) +\n  geom_point()"
  },
  {
    "objectID": "Themen/06/06_StatMod.html#übung-6.4.",
    "href": "Themen/06/06_StatMod.html#übung-6.4.",
    "title": "Statistische Modellierung",
    "section": "Übung 6.4.",
    "text": "Übung 6.4.\n\nInterpretiere das beste Modell.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nBevor wir das Modell interpretieren, sollten wir die Residuen plotten und auf annähernde Normalverteilung und Varianzhomogenität prüfen.\n\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = Mod4, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = dat$Temp)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = dat$Hab)\n\nWarning in ensurePredictor(simulationOutput, form): DHARMa:::ensurePredictor:\ncharacter string was provided as predictor. DHARMa has converted to factor\nautomatically. To remove this warning, please convert to factor before\nattempting to plot with DHARMa.\n\n\n\n\n\n\n\n\n\ngut.\njetzt die Interpretation:\n\nef=allEffects(get.models(dd, 1)[[1]], xlevels=100)    \nef1=as.data.frame(ef[[1]])  \nhead(ef1) \n\n    Hab Temp      fit       se     lower    upper\n1 Hecke 10.0 20.42370 1.835987 16.772635 24.07476\n2 Teich 10.0 34.20223 2.522392 29.186182 39.21829\n3  Wald 10.0 12.38511 1.746992  8.911021 15.85919\n4 Hecke 10.1 20.53418 1.803662 16.947405 24.12096\n5 Teich 10.1 34.40418 2.488231 29.456055 39.35230\n6  Wald 10.1 12.44127 1.709455  9.041833 15.84071\n\n\n\nggplot(data=dat, aes(y=Akt, x=Temp, col=Hab))+\n  geom_ribbon(data = ef1, aes(x = Temp, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Hab), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef1, aes(x = Temp, y = fit))+\n  geom_point()\n\n\n\n\n\n\n\n\nDie Konfidenzintervalle und Regressionslinien gehen über den Wertebereich der einzelnen Habitate hinaus.\n\nlibrary(data.table) \n\n\nAttache Paket: 'data.table'\n\n\nDie folgenden Objekte sind maskiert von 'package:dplyr':\n\n    between, first, last\n\ndat1=ef1[FALSE,] \nfor(i in unique(levels(ef1$Hab)))\n  { dat2&lt;-ef1[(ef1$Hab==i & ef1$Temp %between% c(min(dat$Temp[dat$Hab==i]), \n                                                 max(dat$Temp[dat$Hab==i]))),] \n  dat1=rbind(dat1, dat2) } \nef11=dat1[complete.cases(dat1), ]\n\nMit diesem Code entferne ich Werte ausserhalb des beobachteten Wertebereiches.\n\nggplot(data=dat, aes(y=Akt, x=Temp, col=Hab))+\n  geom_ribbon(data = ef11, aes(x = Temp, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Hab), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef11, aes(x = Temp, y = fit))+\n  geom_point()+\n  ylab(\"Aktivität der Lurche (m/h)\") + xlab(\"Lufttemperatur (°C)\")+\n  scale_color_manual(values=c(\"lightgreen\", \"blue\", \"darkgreen\"))+ \n  scale_fill_manual(values=c(\"lightgreen\", \"blue\", \"darkgreen\"))\n\n\n\n\n\n\n\n\nWir sehen, dass die Aktivität der Lurche\n\nam Teich höher ist als in der Hecke und im Wald (siehe Posthoc test)\nmit zunehmender Lufttemperatur steigt\ndiese Zunahme am Teich stärkerer ist als in der Hecke und Wald.\n\nPosthoc-Test für Habitattyp bei 15°C Lufttemperatur\n\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(Mod4, ~Hab|Temp, at=list(Temp=c(15))), Letters=letters)\n\nTemp = 15:\n Hab   emmean    SE df lower.CL upper.CL .group\n Wald    15.2 1.020 84     13.2     17.2  a    \n Hecke   25.9 0.848 84     24.3     27.6   b   \n Teich   44.3 1.010 84     42.3     46.3    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nWie stark nimmt die Aktivität mit zunehmender Temperatur zu?\n\nemmeans(Mod4, ~Temp|Hab, at=list(Temp=c(15,16)))\n\nHab = Hecke:\n Temp emmean    SE df lower.CL upper.CL\n   15   25.9 0.848 84     24.3     27.6\n   16   27.1 0.990 84     25.1     29.0\n\nHab = Teich:\n Temp emmean    SE df lower.CL upper.CL\n   15   44.3 1.010 84     42.3     46.3\n   16   46.3 0.856 84     44.6     48.0\n\nHab = Wald:\n Temp emmean    SE df lower.CL upper.CL\n   15   15.2 1.020 84     13.2     17.2\n   16   15.8 1.320 84     13.1     18.4\n\nConfidence level used: 0.95 \n\n\n\npairs(emmeans(Mod4, ~Temp|Hab, at=list(Temp=c(16,15))))\n\nHab = Hecke:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    1.105 0.363 84   3.042  0.0031\n\nHab = Teich:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    2.019 0.362 84   5.578  &lt;.0001\n\nHab = Wald:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    0.562 0.428 84   1.313  0.1929\n\n\nMit zunehmender Temperatur (je °C) steigt die Aktivität am Teich um 2,02 Einheiten, in der Hecke um 1,11 Einheiten und im Wald um 0,56 Einheiten."
  },
  {
    "objectID": "Themen/04/04_Anova.html",
    "href": "Themen/04/04_Anova.html",
    "title": "ANOVA",
    "section": "",
    "text": "library(dplyr)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(ggpubr)\nlibrary(ggfortify)\nlibrary(stringr)"
  },
  {
    "objectID": "Themen/04/04_Anova.html#beispiel-anova-proteingehalt",
    "href": "Themen/04/04_Anova.html#beispiel-anova-proteingehalt",
    "title": "ANOVA",
    "section": "Beispiel ANOVA Proteingehalt",
    "text": "Beispiel ANOVA Proteingehalt\nDie Proteingehalte von jeweils 8 zufällig ausgewählten Weizenproben der 4 Qualitätsklassen E, A, B und C wurden ermittelt. Unterscheiden sich die Qualitätsklassen im Proteingehalt?"
  },
  {
    "objectID": "Themen/04/04_Anova.html#daten-einlesen-kennenlernen-und-plotten",
    "href": "Themen/04/04_Anova.html#daten-einlesen-kennenlernen-und-plotten",
    "title": "ANOVA",
    "section": "Daten einlesen, kennenlernen und plotten",
    "text": "Daten einlesen, kennenlernen und plotten\nProtein.xlsx\n\nlibrary(openxlsx)\nmd&lt;-read.xlsx(\"Protein.xlsx\")\n\n\nStruktur der eingelesenen Daten überprüfen\n\nstr(md)\n\n'data.frame':   32 obs. of  3 variables:\n $ ID   : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Quali: chr  \"E\" \"E\" \"E\" \"E\" ...\n $ Prot : num  15.4 15.6 14.3 13.8 15.4 ...\n\nunique(md$Quali)\n\n[1] \"E\" \"A\" \"B\" \"C\"\n\nmd$Quali=as.factor(md$Quali)# Erklärungsvariable muss als Faktor deklariert sein\nlevels(md$Quali)\n\n[1] \"A\" \"B\" \"C\" \"E\"\n\n\n\n\nDaten plotten (Ausreißer, Eingabefehler, Varianzhomogenität visuell überprüfen)\n\nggplot(md, aes(x=Quali, y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\")"
  },
  {
    "objectID": "Themen/04/04_Anova.html#modell-formulieren",
    "href": "Themen/04/04_Anova.html#modell-formulieren",
    "title": "ANOVA",
    "section": "Modell formulieren",
    "text": "Modell formulieren\nWichtig ist, dass die Abhängige kontinuierlich und die Erklärungsvariable ein Faktor ist.\n\nmod&lt;-lm(Prot ~ Quali, data=md) # Prot ist die Abhängige, Quali die Erklärungsvariable\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: Prot\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nQuali      3 35.666 11.8888  5.0814 0.006198 **\nResiduals 28 65.511  2.3397                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuali hat einen signifikanten Effekt auf den Proteingehalt.\nMit der Funktion summary()können wir die geschätzten Effekte sehen.\n\nsummary(mod) \n\n\nCall:\nlm(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  13.2728     0.5408  24.543   &lt;2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,    Adjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198\n\n\nBevor wir hier aber ins Detail gehen, müssen wir zunächst eine Modelldiagnostik durchführen.\n\n\n\n\n\n\nalternative Funktion aov\n\n\n\n\n\n… gelangt zu den gleichen Ergebnissen und wird hier lediglich der Vollständigkeit halber erwähnt.\n\nmod.a&lt;-aov(Prot ~ Quali, data=md) # \nsummary(mod.a)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)   \nQuali        3  35.67   11.89   5.081 0.0062 **\nResiduals   28  65.51    2.34                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.lm(mod.a)\n\n\nCall:\naov(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  13.2728     0.5408  24.543   &lt;2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,    Adjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198"
  },
  {
    "objectID": "Themen/04/04_Anova.html#modelldiagnostik",
    "href": "Themen/04/04_Anova.html#modelldiagnostik",
    "title": "ANOVA",
    "section": "Modelldiagnostik",
    "text": "Modelldiagnostik\nWir überprüfen die Annahmen der ANOVA visuell auf:\n\nannähernde Normalverteilung der Fehler (i.e. Residuen)\nVarianzhomogenität\n\nIch nutze hierfür die library(DHARMa).\nhttps://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html\n\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\n\nDie erste Grafik zeigt einen QQ-Plot der standardisierten Residuen, der uns Informationen über die Normalverteilung der Residuen liefert. Wenn die Punkte ungefähr entlang der Winkelhalbierenden (rote Linie) liegen, deutet dies darauf hin, dass die Residuen approximativ normalverteilt sind. Außerdem werden uns p-Werte für den KS-Test (Kolmogorov-Smirnov-Test auf Normalverteilung), ein Dispersion- und Ausreißertest angezeigt.\nDie zweite Grafik plottet die Residuen gegen die Fitted Values. Wir wollen hier sehen, dass die Streuung um die 0.5 sowohl bei hohen als auch bei niedrigen Werten in etwa gleich ist (Varianzhomogenität). Hier scheint ein leichter Trend vorzuliegen (ist aber m.E. noch ok). Der Plot ist auch hilfreich zum Identifizieren von auffälligen Stichproben. Diese werden als rote Sternchen abgebildet (müssen aber noch nicht zwingend als Ausreißer bezeichnet werden).\nUm die Varianzhomogenität zwischen den Gruppen zu prüfen, sollten wir die Residuen gegen die Erklärungsvariablen plotten.\n\n\nplotResiduals(simulationOutput, form = md$Quali)\n\n\n\n\n\n\n\n\nSolange alle Tests nicht signifikant sind (und keine roten Linien oder Boxen angezeigt werden), ist alles (mehr oder weniger) gut. ABER es sei angemerkt, dass die Teststärke (Power) der Tests von der Anzahl der Beobachtungen abhängt. Je mehr Beobachtungen wir haben, umso höher ist die Power des Tests. Damit werden häufig signifikante Unterschiede z.B. der Varianzen bei großem Stichprobenumfang beobachtet, obwohl diese praktisch nicht relevant sind. Außerdem werden häufig keine signifikanten Unterschiede bei kleinem Stichprobenumfang beobachtet, obwohl gravierende Unterschiede vorhanden sind.\nDie visuelle Modelldiagnostik wird daher häufig als wichtiger angesehen als die p-Wert-basierten Tests auf Normalverteilung und Varianzhomogenität (Cochran, Bartlett und Levenes Test).\n\n\n\n\n\n\nTests auf Varianzhomogenität\n\n\n\n\n\n\nvar.test(md$Prot[md$Quali==\"E\"], md$Prot[md$Quali==\"B\"] )\n\n\n    F test to compare two variances\n\ndata:  md$Prot[md$Quali == \"E\"] and md$Prot[md$Quali == \"B\"]\nF = 0.6686, num df = 7, denom df = 7, p-value = 0.6085\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1338567 3.3396057\nsample estimates:\nratio of variances \n         0.6686019 \n\nbartlett.test(Prot ~ Quali, data=md)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  Prot by Quali\nBartlett's K-squared = 1.0564, df = 3, p-value = 0.7876\n\nlibrary(car)\nleveneTest(Prot ~ Quali, data=md) \n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  3  0.3349 0.8002\n      28               \n\nlibrary(outliers)\ncochran.test(Prot ~ Quali, data=md)\n\n\n    Cochran test for outlying variance\n\ndata:  Prot ~ Quali\nC = 0.36079, df = 8, k = 4, p-value = 0.6601\nalternative hypothesis: Group C has outlying variance\nsample estimates:\n       A        B        C        E \n1.805174 2.503336 3.376528 1.673735 \n\n\n\n\n\nIn unserem Beispiel ist alles ok. Sowohl visuell als auch nach Aussage der Tests.\n\nHier ein Beispiel für Varianzheterogenität mit veränderten Daten.\n\nmd$Prot2= md$Prot\nset.seed(1309)\nmd$Prot2[md$Quali==\"E\"] =rnorm(8, 14.5, 13)\nggplot(md, aes(x=Quali, y=Prot2)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n\n\n\n\n\n\n\n\n\nmod2&lt;-lm(Prot2 ~ Quali, data=md)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod2, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = md$Quali)\n\n\n\n\n\n\n\n\nDie Residuen weisen eine größere Streuung mit größer werdenden fitted values auf bzw. unterscheiden sich die Varianzen der Gruppen. Um dem entgegenzuwirken, könnten wir 1.) entweder die Analyse mit transformierten Daten vornehmen oder 2.) besser einen Funktion anwenden, die die unterschiedliche Varianz in den Gruppen berücksichtigt oder 3.) ein Generalisertes Lineares Modell anwenden, welches die Verteilungsannahme der abhängigen Variable berücksichtigt - denn häufig weisen bspw. Zähldaten eine größere Streuung mit größer werdenden fitted values auf. Siehe dazu Analysis of two-factorial experiments with generalised linear (mixed effect) models"
  },
  {
    "objectID": "Themen/04/04_Anova.html#modellinterpretation",
    "href": "Themen/04/04_Anova.html#modellinterpretation",
    "title": "ANOVA",
    "section": "Modellinterpretation",
    "text": "Modellinterpretation\nZurück zu unserem Modell, bei dem die Modelldiagnostik keine Auffälligkeiten zeigte.\n\nsummary(mod) \n\n\nCall:\nlm(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  13.2728     0.5408  24.543   &lt;2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,    Adjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198\n\n\n\nR² ist 35.3 %. Adjusted R² ist 28.3 %.\nHinter dem Intercept verbirgt sich das erste Level von Quali, i.e. A. A hat demnach einen geschätzten mittleren Proteingehalt von 13.3.\nUm den geschätzten mittleren Proteingehalt für B zu ermitteln, müssen wir Intercept + Estimate QualiB rechnen, d.h. 13.3 -1 = 12.2\nUm den geschätzten mittleren Proteingehalt für C zu ermitteln, müssen wir Intercept + Estimate QualiC rechnen, d.h. 13.3 -1.6 = 11.7\nund für E Intercept + Estimate QualiE: 13.3 + 1.2 = 14.5\n\n\nPost-hoc Test\nDie ANOVA hat einen signifikanten Effekt von Quali auf Prot gezeigt. Allerdings wissen wir nicht, welche Weizenqualitätsklassen sich voneinander unterscheiden. Bei Faktoren mit mehr als zwei Ausprägungen wird daher ein Post-hoc Test durchgeführt. Dieser korrigiert die Irrtumswahrscheinlichkeit um die Anzahl der Vergleiche, da bei beispielsweise 100 Ausprägungen schon rein zufällig fünf signifikante Unterschiede auftreten können.\n\n\nBespiel für multiples Testen ohne und mit Adjustierung des p-Wertes\n\npairwise.t.test(md$Prot, md$Quali, p.adj = \"none\") # p-Werte werden nicht korrigiert, nicht gut! \n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  md$Prot and md$Quali \n\n  A      B      C     \nB 0.1897 -      -     \nC 0.0510 0.4928 -     \nE 0.1268 0.0069 0.0012\n\nP value adjustment method: none \n\n# Bonferroni-Korrektur (Bonferroni multipliziert p mit der Anzahl Tests, sehr konservativ)\npairwise.t.test(md$Prot, md$Quali, p.adj = \"bonferroni\") # besser\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  md$Prot and md$Quali \n\n  A     B     C    \nB 1.000 -     -    \nC 0.306 1.000 -    \nE 0.761 0.041 0.007\n\nP value adjustment method: bonferroni \n\n\n\n\nPost-hoc Test: package emmeans\nDie library(emmeans) mit der Funktion emmeans() bietet eine Vielzahl an Möglichkeiten um einen Post-hoc Test am gefitteten Modell (hier die ANOVA) durchzuführen. Mit dem Argument method=\"pairwise\" kann man alle Behandlungen miteinander per Tukey-Test vergleichen, i.e. paarweise.\n\nlibrary(emmeans)\ncontrast(emmeans(mod, ~Quali), method=\"pairwise\")\n\n contrast estimate    SE df t.ratio p.value\n A - B       1.028 0.765 28   1.344  0.5437\n A - C       1.559 0.765 28   2.039  0.1982\n A - E      -1.204 0.765 28  -1.574  0.4093\n B - C       0.532 0.765 28   0.695  0.8981\n B - E      -2.231 0.765 28  -2.918  0.0328\n C - E      -2.763 0.765 28  -3.613  0.0061\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nMit method=\"trt.vs.ctrl\" wird ein Dunnett-Test durchgeführt, der alle Behandlungen gegen eine Kontrolle testet. Die p-Werte werden automatisch um die Anzahl der Tests korrigiert.\n\ncontrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\")\n\n contrast estimate    SE df t.ratio p.value\n B - A       -1.03 0.765 28  -1.344  0.4116\n C - A       -1.56 0.765 28  -2.039  0.1295\n E - A        1.20 0.765 28   1.574  0.2937\n\nP value adjustment: dunnettx method for 3 tests \n\n\nHier wird immer gegen die Qualität A geprüft, weil diese das erste Level der Variable Quali ist.\nMit dem Argument ref kann ich ein anderes Level wählen. Hier die E-Qualität.\n\ncontrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\", ref=4)\n\n contrast estimate    SE df t.ratio p.value\n A - E       -1.20 0.765 28  -1.574  0.2937\n B - E       -2.23 0.765 28  -2.918  0.0190\n C - E       -2.76 0.765 28  -3.613  0.0033\n\nP value adjustment: dunnettx method for 3 tests \n\n\nAlternativ kann ich bereits im data.frame die Faktorenlevels entsprechend meiner Interpretation ändern und damit das Modell anpassen. (siehe dazu Reihenfolge ändern in Kap. Grafik)\nInteressant sind auch die Konfidenzintervalle. Wenn Konfidenzintervalle sich nicht überlappen, geht man in der Regel von signifikanten Unterschieden aus. Es kann auch sein, dass Konfidenzintervalle leicht überlappen, und trotzdem signifikante Unterschiede vorliegen. https://core.ac.uk/download/pdf/82702323.pdf Hier sollte man immer auf die p-Werte des Tests schauen.\n\nsummary(emmeans(mod, ~Quali)) #Konfidenzintervalle\n\n Quali emmean    SE df lower.CL upper.CL\n A       13.3 0.541 28     12.2     14.4\n B       12.2 0.541 28     11.1     13.4\n C       11.7 0.541 28     10.6     12.8\n E       14.5 0.541 28     13.4     15.6\n\nConfidence level used: 0.95 \n\nplot(emmeans(mod, ~Quali))\n\n\n\n\n\n\n\n\nUm Gruppenunterschiede leicht verständlich anzugeben bzw. zu visualisieren, kann das compact letter display genutzt werden. Hierfür benötigen wir die library(multcompView) und library(multcomp).\n\nlibrary(multcompView)\nlibrary(multcomp)\ncld(emmeans(mod, ~Quali), adjust=\"sidak\", Letters=letters) # Compact letter display für Gruppenunterschiede \n\n Quali emmean    SE df lower.CL upper.CL .group\n C       11.7 0.541 28     10.3     13.2  a    \n B       12.2 0.541 28     10.8     13.7  a    \n A       13.3 0.541 28     11.8     14.7  ab   \n E       14.5 0.541 28     13.0     15.9   b   \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nGruppen, die keinen Buchstaben gemeinsam haben, sind im Mittelwert signifikant unterschiedlich. Qualitätsklasse E hat einen signifikant höheren Proteingehalt im Vergleich zu B und C, während E und A sich nicht signifikant unterscheiden."
  },
  {
    "objectID": "Themen/04/04_Anova.html#präsentation-der-ergebnisse",
    "href": "Themen/04/04_Anova.html#präsentation-der-ergebnisse",
    "title": "ANOVA",
    "section": "Präsentation der Ergebnisse",
    "text": "Präsentation der Ergebnisse\nSo könnte man die Daten und die Ergebnisse des Modells präsentieren. Ich speichere die geschätzten Mittelwerte und das Konfidenzintervall als Objekt CIs und plotte diese neben die jittered Boxplots der Gruppen. Das Einzeichnen der Buchstaben muss nicht sein. Der Vollständigkeit halber soll es hier aber gezeigt werden.\n\nCIs=cld(emmeans(mod, ~Quali), adjust=\"sidak\", sort = FALSE, Letters=letters)\nCIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert\n\n[1] \" ab\" \" a \" \" a \" \"  b\"\n\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen\nCIs$.group # besser\n\n[1] \"ab\" \"a\"  \"a\"  \"b\" \n\nstr(CIs)\n\nClasses 'summary_emm' and 'data.frame': 4 obs. of  7 variables:\n $ Quali   : Factor w/ 4 levels \"A\",\"B\",\"C\",\"E\": 1 2 3 4\n $ emmean  : num  13.3 12.2 11.7 14.5\n $ SE      : num  0.541 0.541 0.541 0.541\n $ df      : num  28 28 28 28\n $ lower.CL: num  11.8 10.8 10.3 13\n $ upper.CL: num  14.7 13.7 13.2 15.9\n $ .group  : chr  \"ab\" \"a\" \"a\" \"b\"\n - attr(*, \"estName\")= chr \"emmean\"\n - attr(*, \"clNames\")= chr [1:2] \"lower.CL\" \"upper.CL\"\n - attr(*, \"pri.vars\")= chr \"Quali\"\n - attr(*, \"adjust\")= chr \"sidak\"\n - attr(*, \"side\")= num 0\n - attr(*, \"delta\")= num 0\n - attr(*, \"type\")= chr \"link\"\n - attr(*, \"mesg\")= chr [1:5] \"Confidence level used: 0.95\" \"Conf-level adjustment: sidak method for 4 estimates\" \"P value adjustment: sidak method for 6 tests\" \"significance level used: alpha = 0.05\" ...\n\nggplot(md, aes(x=Quali, y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n             shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 17, label =.group))+\n  scale_y_continuous(labels=scales::number_format(accuracy = 0.01, \n                                                  decimal.mark =\",\"))+\n  theme_bw() +\n  ylab(\"Proteingehalt %\")+\n  xlab(\"Qualitätsklasse\")\n\n\n\n\n\n\n\n\nIm Text sollte man erwähnen, dass\n\nQuali einen signifikanten Einfluss auf Prot hat. Nutze die Funktion anova(mod) und gibt den p-Wert zusammen mit den degrees of freedom und F-Wert an.\nder Post-hoc Test gezeigt hat, dass E mit im Mittel 14.5 % einen signifikant höheren Proteingehalt hatte als B und C mit 12.2 % und 11.7 % , während E und A sich nicht unterscheiden. Die Proteingehalte von A, B und C unterscheiden sich nicht signifikant (p&gt;0.05). Hierzu nutzt du die Funktion contrast(emmeans(mod, c(\"Quali\")), method=\"pairwise\").\ndas R² des Modells 35.3 beträgt. summary(mod)$r.sq\ndie Modellannahmen für die ANOVA (Varianzhomogenität und annähernde Normalverteilung der Residuen) visuell mit dem Paket DHARMa überprüft wurden.\n\n\nadd on: Unterschiede zu einer Kontrolle darstellen (absolut)\nWie bereits erwähnt, können wir durch geeignete Modellinterpretation alle Behandlungen gegen eine bestimmte Kontrollgruppe testen. Nehmen wir an, die Qualität C sei unsere Standardqualität und wir möchten die Unterschiede der übrigen Qualitäten im Vergleich zu C quantifizieren. Dies lässt sich mit method=\"trt.vs.ctrl\" umsetzen, wobei wir über das Argument ref die gewünschte Kontrollgruppe – in diesem Fall die C-Qualität – festlegen. Mit dem Argument infer=c(T,T) wird das 95%-Konfidenzintervall für die Unterschiede zwischen den Gruppen berechnet.\n\ncontrast(emmeans(mod, ~Quali),  method=\"trt.vs.ctrl\", ref=\"C\", infer=c(T,T))\n\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - C       1.559 0.765 28   -0.351     3.47   2.039  0.1295\n B - C       0.532 0.765 28   -1.379     2.44   0.695  0.8021\n E - C       2.763 0.765 28    0.853     4.67   3.613  0.0033\n\nConfidence level used: 0.95 \nConf-level adjustment: dunnettx method for 3 estimates \nP value adjustment: dunnettx method for 3 tests \n\n\nDas Ergebnis wird als data.frame CI.con gespeichert.\n\nCI.con=data.frame(contrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\", ref=\"C\", infer=c(T,T)))\nCI.con\n\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n\n\nIm nächsten Schritt wird zur besseren Visualisierung die Information aus die Spalte contrast aufbereitet und in eine neue Spalte contrast2 geschrieben: Aus den Namen wie E - C oder A - C wird das - C entfernt. Gleichzeitig wird mit levels=c(\"E\",\"A\",\"B\") eine gewünschte Reihenfolge der Gruppen festgelegt.\n\nCI.con$contrast2=factor(str_replace_all(CI.con$contrast, \" - C\", \"\"), levels=c(\"E\", \"A\", \"B\"))\nCI.con\n\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2\n1         A\n2         B\n3         E\n\n\n\nggplot(data=CI.con, aes(y=estimate, x=contrast2))+\n  geom_hline(yintercept=0, linetype=\"dashed\")+\n  geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL), width=0.1)+\n  geom_point(size=3)+\n  coord_flip()+\n  theme_bw() +\n  ylab(\"Differenz im mittleren Proteingehalt und 95%-Konfidenzintervall \\n im Vergleich zur C-Qualität\")+\n  scale_x_discrete(limits=rev, name=\"Qualitätsklasse\")\n\n\n\n\n\n\n\n\nDie Grafik zeigt die geschätzten Differenzen im mittleren Proteingehalt der Qualitätsklassen E, A und B im Vergleich zur Referenz C, jeweils mit 95%-Konfidenzintervallen. Die gestrichelte Linie markiert den Referenzwert (kein Unterschied zu C).\n\n\nadd on: Unterschiede zu einer Kontrolle darstellen (Cohen’s d)\nUm die Größenordnung der Unterschiede zur C-Qualität unabhängig von der absoluten Skala der Messwerte zu veranschaulichen, können wir Cohen’s d-ähnliche Effektstärken berechnen. Cohen’s d ist eine standardisierte Effektgröße, die den Unterschied zweier Mittelwerte ins Verhältnis zur Streuung setzt. Mit der Funktion eff_size kann Cohen’s d aus dem Modell berechnet werden, d.h. aus den geschätzten Mittelwerten und der geschätzten Residual-Standardabweichung.\nMit sigma = sigma(mod) und edf = df.residual(mod) werden die Residual-Standardabweichung und die geschätzten Freiheitsgrade aus dem Modell übergeben.\n\neff_size(emmeans(mod, ~Quali), sigma = sigma(mod), edf = df.residual(mod), \n                        method = \"trt.vs.ctrl\", ref = \"C\")\n\n contrast effect.size    SE df lower.CL upper.CL\n A - C          1.019 0.518 28  -0.0421     2.08\n B - C          0.347 0.502 28  -0.6811     1.38\n E - C          1.806 0.555 28   0.6690     2.94\n\nsigma used for effect sizes: 1.53 \nConfidence level used: 0.95 \n\n\nPrinzipiell gilt für Cohen`s d:\n\nkleiner Effekt: d ≈ 0.2\nmittlerer Effekt: d ≈ 0.5\ngroßer Effekt: d ≈ 0.8\n\nFür obiges Beispiel bedeutet das:\n\nA zeigt einen großen, aber statistisch unsicheren Effekt (das Konfidenzintervall schließt die 0 mit ein).\nB zeigt nur einen kleinen, statistisch unsicheren Effekt.\nE unterscheidet sich klar und deutlich von C (großer, signifikanter Effekt, das Konfidenzintervall liegt vollständig über 0).\n\n\n\nadd on: Unterschiede zu einer Kontrolle darstellen (prozentual)\nUm die Unterschiede zu einer Referenzgruppe anschaulicher darzustellen, können die Mittelwertsdifferenzen prozentual zur C-Qualität angegeben werden. So wird sichtbar, um wie viel Prozent die anderen Qualitätsklassen vom Standard abweichen.\nProzentuale Unterschiede sind oft intuitiver verständlich als Rohwerte oder standardisierte Effektgrößen. Sie sind insbesondere für Präsentationen oder für praxisorientierte Zielgruppen (z. B. Landwirte, Praktiker) besser geeignet. Auch beim Vergleich unterschiedlicher Messgrößen (z. B. Proteingehalt, Gewicht, usw) in Relation zur Behandlung kann die Berechnung der prozentualen Unterschiede eine gute Grundlage für die Interpretation liefern.\nZu beachten ist jedoch, dass prozentuale Änderungen immer relativ zur Referenz zu interpretieren sind. Sind diese sehr klein, können die Prozentwerte stark verzerrt werden. Daher empfiehlt es sich, immer auch die geschätzten Werte (emmeans) oder Rohdifferenzen (wie oben) anzugeben.\n\nemm1=data.frame(emmeans(mod, ~Quali))\nemm1\n\n  Quali   emmean        SE df lower.CL upper.CL\n1     A 13.27277 0.5407972 28 12.16500 14.38055\n2     B 12.24490 0.5407972 28 11.13712 13.35267\n3     C 11.71337 0.5407972 28 10.60560 12.82114\n4     E 14.47638 0.5407972 28 13.36861 15.58416\n\nC.p=emm1$emmean[emm1$Quali==\"C\"]\nC.p\n\n[1] 11.71337\n\n\nHier werden die geschätzten Mittelwerte der Qualitätsklassen berechnet und der Mittelwert der C-Qualität (C.p) als Referenz gespeichert.\n\nCI.con\n\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2\n1         A\n2         B\n3         E\n\nCI.con$p.change=CI.con$estimate/C.p*100\nCI.con$p.change.low=CI.con$lower.CL/C.p*100\nCI.con$p.change.up=CI.con$upper.CL/C.p*100\nCI.con\n\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2  p.change p.change.low p.change.up\n1         A 13.313027    -2.994838    29.62089\n2         B  4.537768   -11.770097    20.84563\n3         E 23.588537     7.280673    39.89640\n\n\nDie absoluten Differenzen zu C werden in prozentuale Abweichungen umgerechnet. Neben dem Schätzwert (p.change) werden auch die unteren (p.change.low) und oberen (p.change.up) Konfidenzgrenzen in Prozent berechnet.\n\nggplot(data=CI.con, aes(y=p.change, x=contrast2))+\n  geom_hline(yintercept=0, linetype=\"dashed\")+\n  geom_errorbar(aes(ymin=p.change.low, ymax=p.change.up), width=0.1)+\n  geom_point(size=3)+\n  coord_flip()+\n  theme_bw() +\n  ylab(\"prozentualer Unterschied im mittleren Proteingehalt und 95%-Konfidenzintervall \\n im Vergleich zur C-Qualität\")+\n  scale_x_discrete(limits=rev, name=\"Qualitätsklasse\")#+  xlab()\n\n\n\n\n\n\n\n\n\n\nadd on: Faktorlevels in Grafik umsortieren\nZurück zu unseren emmeans und Originaldaten: Schön wäre es, die Qualitäten in absteigender Reihenfolge darzustellen. E steht für Elite und ist die beste Qualität.\n\nlibrary(forcats)\nmd %&gt;% \nggplot(aes(x=fct_relevel(Quali, \"E\"), y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n           shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 20, label =.group))+\n  theme_bw()\n\n\n\n\n\n\n\n\noder in aufsteigender Reihenfolge, basierend auf den Messwerten.\n\nCIs$Prot=CIs$emmean\nmd %&gt;% \nggplot(aes(x=fct_reorder(Quali, Prot), y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n           shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 20, label =.group))+\n  theme_bw()"
  },
  {
    "objectID": "Themen/04/04_Anova.html#übung-4",
    "href": "Themen/04/04_Anova.html#übung-4",
    "title": "ANOVA",
    "section": "Übung 4",
    "text": "Übung 4\nIn einem Gefäßversuch wurde die pflanzenliche Biomasse (BM) in den 4 Düngemittelvarianten (DM: Kontrolle, Düngemittel A, B und C) an jeweils 10 Proben gemessen.\n\nImportiere bitte die Daten Gefaessversuch.xlsx in R und mach Dich mit dem Datensatz vertraut.\n\n\n\n\n\n\n\nDaten einlesen und prüfen\n\n\n\n\n\n\nlibrary(openxlsx)\ng&lt;-read.xlsx(\"Gefaessversuch.xlsx\")\nstr(g)\n\n'data.frame':   40 obs. of  3 variables:\n $ ID: num  1 2 3 4 5 6 7 8 9 10 ...\n $ DM: chr  \"K\" \"K\" \"K\" \"K\" ...\n $ BM: num  118.3 122.4 96.7 86.9 119 ...\n\n\n\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n\n\n\n\n\n\n\n\nwir können die Kontrolle als erstes Level definieren.\n\ng$DM=fct_relevel(g$DM, \"K\")\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n\n\n\n\n\n\n\n\n\n\n\n\nUnterscheidet sich die Biomasse zwischen den Varianten?\n\n\n\n\n\n\n\nModell formulieren\n\n\n\n\n\n\nmod&lt;-lm(BM ~ DM, data=g)\nanova(mod)\n\nAnalysis of Variance Table\n\nResponse: BM\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nDM         3 431421  143807  67.744 7.084e-15 ***\nResiduals 36  76421    2123                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nJa, aber bevor wir das Modell interpretieren, müssen wir uns unbedingt die Residuen anschauen.\n\n\n\n\nSind die Voraussetzung für eine ANOVA gegeben? Prüfe die Residuen.\n\n\n\n\n\n\n\nModelldiagnostik\n\n\n\n\n\n\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n\n\n\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = g$DM)\n\n\n\n\n\n\n\n\nNein, das sieht nicht gut aus. Die Varianz wird mit jedem Level etwas größer. Hier könnte man nun die Abhängige Variable transformieren, um die Varianz zu stabilisieren.\nPlotten wir die Daten mit einer Wurzel-transformierten Y-Achse:\n\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") +\n  scale_y_sqrt()\n\n\n\n\n\n\n\n\nDas sieht besser aus. Die Boxen der Boxplots weisen eine ähnliche Höhe auf.\nNun können wir entweder\n\neine neue Variable in unseren data.frame definieren, die die wurzel-transformierten Werte enthält, z.B. g$BM.sq=sqrt(g$BM)\nund mit dieser Variable das Modell fitten mod&lt;-lm(BM.sq ~ DM, data=g)\nund später die emmeans und CIs zurücktransformieren CIs$emmean.2=CIs$emmean^2 (gleiches für die Konfidenzintervalle)\n\noder\n\ndie Transformation im Modell definieren. Das hat bei der späteren Nutzung von emmeans() den Vorteil, dass die Werte auf die Response Skala automatisch tranformiert werden können.\n\n\nmod1&lt;-lm(sqrt(BM) ~ DM, data=g)\nanova(mod1)\n\nAnalysis of Variance Table\n\nResponse: sqrt(BM)\n          Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nDM         3 495.26 165.086  69.415 4.885e-15 ***\nResiduals 36  85.62   2.378                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod1, plot = F)\nplot(simulationOutput)\n\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = g$DM)\n\n\n\n\n\n\n\n\nAuch wenn wir Warnmeldungen für die obigen Plots erhalten, so ist doch die Annahme der Varianzhomogenität und annähernede Normalverteilung der Residuen erfüllt. Wir können das Modell nun interpretieren.\n\nModellinterpretation\n\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(mod1, ~DM), adjust = \"sidak\", Letters=letters)\n\n DM emmean    SE df lower.CL upper.CL .group\n K     9.8 0.488 36     8.52     11.1  a    \n A    11.4 0.488 36    10.15     12.7  a    \n B    14.1 0.488 36    12.85     15.4   b   \n C    19.1 0.488 36    17.81     20.4    c  \n\nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nDie emmeans sind recht niedrig, was an der Wurzeltransformation liegt.\n\ncld(emmeans(mod1, ~DM, type=\"response\"), adjust = \"sidak\", Letters=letters)\n\n DM response    SE df lower.CL upper.CL .group\n K      96.1  9.56 36     72.6      123  a    \n A     130.6 11.10 36    103.0      161  a    \n B     199.5 13.80 36    165.0      237   b   \n C     364.3 18.60 36    317.1      415    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nMit dem Argument type=\"response\" werden die emmeans auf die Originalskala zurücktransformiert. Beachte, dass jetzt die Variable reponse heißt und der Code für die Grafik angepasst werden muss. Die p-Werte der paarweisen Vergleiche können wir über die contrast()-Funktion erhalten. Alternativ kann mit dem Argument method=\"trt.vs.ctrl\" ein Dunnett-Test durchgeführt werden, der die Düngemittel A, B und C gegen die Kontrolle testet.\n\ncontrast(emmeans(mod1, ~DM), method=\"pairwise\")\n\n contrast estimate   SE df t.ratio p.value\n K - A       -1.63 0.69 36  -2.361  0.1032\n K - B       -4.32 0.69 36  -6.270  &lt;.0001\n K - C       -9.29 0.69 36 -13.464  &lt;.0001\n A - B       -2.70 0.69 36  -3.909  0.0021\n A - C       -7.66 0.69 36 -11.103  &lt;.0001\n B - C       -4.96 0.69 36  -7.194  &lt;.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 4 estimates \n\ncontrast(emmeans(mod1, ~DM), method=\"trt.vs.ctrl\")\n\n contrast estimate   SE df t.ratio p.value\n A - K        1.63 0.69 36   2.361  0.0633\n B - K        4.32 0.69 36   6.270  &lt;.0001\n C - K        9.29 0.69 36  13.464  &lt;.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: dunnettx method for 3 tests \n\n\n\ncontrast(emmeans(mod1, ~DM), adjust = \"sidak\", method=\"pairwise\")\n\n contrast estimate   SE df t.ratio p.value\n K - A       -1.63 0.69 36  -2.361  0.1343\n K - B       -4.32 0.69 36  -6.270  &lt;.0001\n K - C       -9.29 0.69 36 -13.464  &lt;.0001\n A - B       -2.70 0.69 36  -3.909  0.0024\n A - C       -7.66 0.69 36 -11.103  &lt;.0001\n B - C       -4.96 0.69 36  -7.194  &lt;.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \n\ncontrast(emmeans(mod1, ~DM), adjust = \"sidak\", method=\"trt.vs.ctrl\")\n\n contrast estimate   SE df t.ratio p.value\n A - K        1.63 0.69 36   2.361  0.0696\n B - K        4.32 0.69 36   6.270  &lt;.0001\n C - K        9.29 0.69 36  13.464  &lt;.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 3 tests \n\n\n\nCIs=cld(emmeans(mod1, ~DM, type = \"response\" ), adjust = \"sidak\", sort = FALSE, Letters=letters)\nCIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert\n\n[1] \" a  \" \" a  \" \"  b \" \"   c\"\n\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen\nCIs$.group # besser\n\n[1] \"a\" \"a\" \"b\" \"c\"\n\nstr(CIs)\n\nClasses 'summary_emm' and 'data.frame': 4 obs. of  7 variables:\n $ DM      : Factor w/ 4 levels \"K\",\"A\",\"B\",\"C\": 1 2 3 4\n $ response: num  96.1 130.6 199.5 364.3\n $ SE      : num  9.56 11.15 13.78 18.62\n $ df      : num  36 36 36 36\n $ lower.CL: num  72.6 103 165 317.1\n $ upper.CL: num  123 161 237 415\n $ .group  : chr  \"a\" \"a\" \"b\" \"c\"\n - attr(*, \"estName\")= chr \"response\"\n - attr(*, \"clNames\")= chr [1:2] \"lower.CL\" \"upper.CL\"\n - attr(*, \"pri.vars\")= chr \"DM\"\n - attr(*, \"adjust\")= chr \"sidak\"\n - attr(*, \"side\")= num 0\n - attr(*, \"delta\")= num 0\n - attr(*, \"type\")= chr \"response\"\n - attr(*, \"mesg\")= chr [1:7] \"Confidence level used: 0.95\" \"Conf-level adjustment: sidak method for 4 estimates\" \"Intervals are back-transformed from the sqrt scale\" \"Note: contrasts are still on the sqrt scale. Consider using\\n      regrid() if you want contrasts of back-trans\"| __truncated__ ...\n - attr(*, \"linkname\")= chr \"sqrt\"\n\n\n\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=response), \n             shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=response, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 550, label =.group))+\n  theme_bw() +\n  scale_y_sqrt(breaks=c(50, 100,200,300,400,500))+\n  ylab(\"Biomasse (g)\")+\n  xlab(\"Düngemittel\")\n\n\n\n\n\n\n\n\n\n\n\n\nEnde Übung 4"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html",
    "href": "Themen/02/02_DeskriptiveStats.html",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "",
    "text": "Diese Daten sind die leicht modifizierten und erweiterten greenhouse-Daten aus dem R-Paket agricolae.\nIn einem Versuch wurden verschiedene Kartoffelsorten (variety) in verschiedenen Anbaumethoden (method) kultiviert und die Anzahl Knollen (tubers), deren Gewicht (weight), der Krankheitsbefall (infection 1=ja, 0=nein) und die mittlere Luftfeuchte (humidity) ermittelt.\nZunächst lesen wir den Datensatz potato.xlsx mit der Funktion read.xlsx aus der library(openxlsx) ein und benennen den data.frame mit pot und machen uns mit ihm vertraut.\n\nlibrary(openxlsx)\npot&lt;-read.xlsx(\"potato.xlsx\", sheet=1)\nstr(pot)\n\n'data.frame':   478 obs. of  7 variables:\n $ variety  : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method   : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n $ humidity : num  26.1 30.2 52.5 34 49.6 ...\n\n\nDer Datensatz hat 478 Zeilen (Beobachtungen) und 7 Spalten.\nvariety undmethod sind als character eingelesen.\n\nunique(pot$variety)\n\n[1] \"Unica\"     \"Mariva\"    \"Costanera\"\n\nunique(pot$method)\n\n[1] \"pot\"        \"bed\"        \"hydroponic\" \"aeroponic\" \n\n\nDiese können wir auch in Faktoren umwandeln (siehe Section 2.2.3.1). Alle anderen Variablen sind numerisch."
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#zeilen",
    "href": "Themen/02/02_DeskriptiveStats.html#zeilen",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Zeilen",
    "text": "Zeilen\nWir lernen nun Funtionen aus dem paket dplyr kennen, mit denen wir Beobachtungen, d.h. Zeilen unseres Datensatzes, auswählen oder umsortieren können.\n\nfilter\nMit der Funktion filter können wir ein Subset des Datensatzes erstellen. pot.M enthält mit folgendem Code nur noch Beobachtungen der Sorte Mariva.\n\npot.M&lt;- pot.sub %&gt;% filter(variety==\"Mariva\")\npot.M\n\n# A tibble: 8 × 7\n# Groups:   variety, method [4]\n  variety method     plant tubers weight infection humidity\n  &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Mariva  aeroponic      7      6  99.2          0     31.8\n2 Mariva  aeroponic      5      5  72.6          0     24.5\n3 Mariva  bed            7      5  59.9          0     56.3\n4 Mariva  bed            8      5  77.3          0     16.3\n5 Mariva  hydroponic     9      2  10.8          0     44.6\n6 Mariva  hydroponic     9      1   7.85         0     48.5\n7 Mariva  pot            5      7 104.           0     41.4\n8 Mariva  pot            8      5  64.8          0     27.3\n\n\npot.BM enthält mit folgendem Code nur noch Beobachtungen der Sorte Mariva und Methode bed.\n\npot.MB&lt;- pot.sub %&gt;% filter(variety==\"Mariva\", method==\"bed\")\npot.MB  \n\n# A tibble: 2 × 7\n# Groups:   variety, method [1]\n  variety method plant tubers weight infection humidity\n  &lt;chr&gt;   &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Mariva  bed        7      5   59.9         0     56.3\n2 Mariva  bed        8      5   77.3         0     16.3\n\n\nMehrere Ausprägungen einer Variable können mit %in% ausgewählt werden: pot.MU enthält mit folgendem Code nur noch Beobachtungen der Sorten Mariva und Unica.\n\npot.MU&lt;- pot.sub %&gt;% filter(variety%in%c(\"Mariva\", \"Unica\"))\npot.MU\n\n# A tibble: 16 × 7\n# Groups:   variety, method [8]\n   variety method     plant tubers weight infection humidity\n   &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Mariva  aeroponic      7      6  99.2          0     31.8\n 2 Mariva  aeroponic      5      5  72.6          0     24.5\n 3 Mariva  bed            7      5  59.9          0     56.3\n 4 Mariva  bed            8      5  77.3          0     16.3\n 5 Mariva  hydroponic     9      2  10.8          0     44.6\n 6 Mariva  hydroponic     9      1   7.85         0     48.5\n 7 Mariva  pot            5      7 104.           0     41.4\n 8 Mariva  pot            8      5  64.8          0     27.3\n 9 Unica   aeroponic      6      2 112.           0     27.5\n10 Unica   aeroponic      7      4  50.1          0     40.0\n11 Unica   bed            9      4 124.           0     41.8\n12 Unica   bed            9      3  38            0     56.8\n13 Unica   hydroponic     6      2  17.1          0     50.2\n14 Unica   hydroponic     4      2  21.8          0     14.3\n15 Unica   pot            7      4  50.4          0     36.0\n16 Unica   pot            9      5  97.7          1     58.7\n\n\nAlternativ können alle Beobachtungen bis auf Sorte Mariva selektiert werden.\n\npot.oM&lt;- pot.sub %&gt;% filter(variety!=(\"Mariva\"))\npot.oM \n\n# A tibble: 16 × 7\n# Groups:   variety, method [8]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic      1      5   24.1         0     33.9\n 2 Costanera aeroponic      5      7   42           0     26.0\n 3 Costanera bed            4      7  137.          1     41.6\n 4 Costanera bed            3      5   78           1     51.0\n 5 Costanera hydroponic     8      6   31.8         1     57.2\n 6 Costanera hydroponic     4      5   42           1     56.8\n 7 Costanera pot            5      3  110.          0     26.6\n 8 Costanera pot            6      7  139.          0     41.6\n 9 Unica     aeroponic      6      2  112.          0     27.5\n10 Unica     aeroponic      7      4   50.1         0     40.0\n11 Unica     bed            9      4  124.          0     41.8\n12 Unica     bed            9      3   38           0     56.8\n13 Unica     hydroponic     6      2   17.1         0     50.2\n14 Unica     hydroponic     4      2   21.8         0     14.3\n15 Unica     pot            7      4   50.4         0     36.0\n16 Unica     pot            9      5   97.7         1     58.7\n\n\nHier werden alle Beobachtungen mit größer gleich 5 Knollen selektiert.\n\npot.T5 &lt;-pot.sub %&gt;% filter(tubers&gt;=5)\npot.T5\n\n# A tibble: 14 × 7\n# Groups:   variety, method [8]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic      1      5   24.1         0     33.9\n 2 Costanera aeroponic      5      7   42           0     26.0\n 3 Costanera bed            4      7  137.          1     41.6\n 4 Costanera bed            3      5   78           1     51.0\n 5 Costanera hydroponic     8      6   31.8         1     57.2\n 6 Costanera hydroponic     4      5   42           1     56.8\n 7 Costanera pot            6      7  139.          0     41.6\n 8 Mariva    aeroponic      7      6   99.2         0     31.8\n 9 Mariva    aeroponic      5      5   72.6         0     24.5\n10 Mariva    bed            7      5   59.9         0     56.3\n11 Mariva    bed            8      5   77.3         0     16.3\n12 Mariva    pot            5      7  104.          0     41.4\n13 Mariva    pot            8      5   64.8         0     27.3\n14 Unica     pot            9      5   97.7         1     58.7\n\npot.T5$tubers\n\n [1] 5 7 7 5 6 5 7 6 5 5 5 7 5 5\n\n\nHier werden alle Beobachtungen mit mehr als 5 Knollen selektiert.\n\npot.T5 &lt;-pot.sub %&gt;% filter(tubers&gt;5)\npot.T5\n\n# A tibble: 6 × 7\n# Groups:   variety, method [6]\n  variety   method     plant tubers weight infection humidity\n  &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Costanera aeroponic      5      7   42           0     26.0\n2 Costanera bed            4      7  137.          1     41.6\n3 Costanera hydroponic     8      6   31.8         1     57.2\n4 Costanera pot            6      7  139.          0     41.6\n5 Mariva    aeroponic      7      6   99.2         0     31.8\n6 Mariva    pot            5      7  104.          0     41.4\n\npot.T5$tubers\n\n[1] 7 7 6 7 6 7\n\n\nzwei Bedingungen (Anzahl Knollen und Gewicht)\n\npot.sub %&gt;% filter(tubers&gt;=5, weight &gt; 80)\n\n# A tibble: 5 × 7\n# Groups:   variety, method [5]\n  variety   method    plant tubers weight infection humidity\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 Costanera bed           4      7  137.          1     41.6\n2 Costanera pot           6      7  139.          0     41.6\n3 Mariva    aeroponic     7      6   99.2         0     31.8\n4 Mariva    pot           5      7  104.          0     41.4\n5 Unica     pot           9      5   97.7         1     58.7\n\n\n\n\narrange\nMit der Funktion arrange sortieren wir die Daten. Hier nach Anzahl tubers in aufsteigender Reihenfolge.\n\npot.sub %&gt;% arrange(tubers)\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Mariva    hydroponic     9      1   7.85         0     48.5\n 2 Mariva    hydroponic     9      2  10.8          0     44.6\n 3 Unica     aeroponic      6      2 112.           0     27.5\n 4 Unica     hydroponic     6      2  17.1          0     50.2\n 5 Unica     hydroponic     4      2  21.8          0     14.3\n 6 Costanera pot            5      3 110.           0     26.6\n 7 Unica     bed            9      3  38            0     56.8\n 8 Unica     aeroponic      7      4  50.1          0     40.0\n 9 Unica     bed            9      4 124.           0     41.8\n10 Unica     pot            7      4  50.4          0     36.0\n# ℹ 14 more rows\n\n\nund hier in absteigender Reihenfolge durch Funktion desc():\n\npot.sub %&gt;% arrange(desc(tubers))\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic      5      7   42           0     26.0\n 2 Costanera bed            4      7  137.          1     41.6\n 3 Costanera pot            6      7  139.          0     41.6\n 4 Mariva    pot            5      7  104.          0     41.4\n 5 Costanera hydroponic     8      6   31.8         1     57.2\n 6 Mariva    aeroponic      7      6   99.2         0     31.8\n 7 Costanera aeroponic      1      5   24.1         0     33.9\n 8 Costanera bed            3      5   78           1     51.0\n 9 Costanera hydroponic     4      5   42           1     56.8\n10 Mariva    aeroponic      5      5   72.6         0     24.5\n# ℹ 14 more rows\n\n\nund hier für zwei Kriterien (wobei letzteres Kriterium nur bei gleichen Werten in erstem Kriterium sortiert wird)\n\npot.sub %&gt;% arrange(desc(tubers),desc(weight))\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera pot            6      7  139.          0     41.6\n 2 Costanera bed            4      7  137.          1     41.6\n 3 Mariva    pot            5      7  104.          0     41.4\n 4 Costanera aeroponic      5      7   42           0     26.0\n 5 Mariva    aeroponic      7      6   99.2         0     31.8\n 6 Costanera hydroponic     8      6   31.8         1     57.2\n 7 Unica     pot            9      5   97.7         1     58.7\n 8 Costanera bed            3      5   78           1     51.0\n 9 Mariva    bed            8      5   77.3         0     16.3\n10 Mariva    aeroponic      5      5   72.6         0     24.5\n# ℹ 14 more rows\n\n\n\n\nslice\nMit der Funktion slice selektieren wir die Zeilen. Hier Zeile 5 bis 10 im Datensatz pot.\n\npot %&gt;% slice(5:10)\n\n  variety method plant tubers weight infection humidity\n1   Unica    pot     5      2   11.3         1 49.62655\n2   Unica    pot     6      2   17.8         0 54.42449\n3   Unica    pot     7      3   28.1         0 38.82654\n4   Unica    pot     8      6   33.0         0 17.36043\n5   Unica    pot     9      9   81.5         0 24.55165\n6   Unica    pot    10      6   71.1         0 27.55136\n\n\nDie Funktion slice_head(n=3) zeigt die ersten drei Zeilen des Datensatzes an.\n\npot %&gt;% slice_head(n=3)\n\n  variety method plant tubers weight infection humidity\n1   Unica    pot     1      9  209.9         0 26.12342\n2   Unica    pot     2      3  248.4         0 30.23136\n3   Unica    pot     3      4   53.6         0 52.47987\n\n\nDie Funktion slice_tail(n=3) zeigt die letzten drei Zeilen des Datensatzes an.\n\npot %&gt;% slice_tail(n=3)\n\n    variety    method plant tubers weight infection humidity\n1 Costanera aeroponic     8      6   29.1         1 49.90505\n2 Costanera aeroponic     9      4   17.6         0 54.39016\n3 Costanera aeroponic    10      7   36.9         0 29.03782\n\n\nAlternativ könnte man auch die Funtionen head(pot) und tail(pot) nutzen.\nDie Funktion slice_sample(n=3) wählt zufällig drei Beobachtungen aus.\n\npot %&gt;% slice_sample(n=3)\n\n    variety     method plant tubers weight infection humidity\n1     Unica        bed     3      2   18.2         1 42.24794\n2 Costanera        bed     2      4  118.5         1 33.23794\n3     Unica hydroponic     3      2   58.7         0 13.54122\n\n\nWenn man immer das gleiche Set an Proben zufällig auswählen möchte, d.h. ein reproduzierbares Ergebnis erzielen möchte, dann setzt man vorher den seed. Die Zahl (hier 123) kann beliebig gewählt werden.\n\nset.seed(123)\npot %&gt;% slice_sample(n=3)\n\n    variety     method plant tubers weight infection humidity\n1    Mariva        bed     5      3   37.8         1 42.87366\n2 Costanera hydroponic     3      7   18.6         1 54.46725\n3    Mariva        bed     9      6   99.4         0 38.52317\n\n\nDie Funktion slice_max(n=3) wählt die drei Beobachtungen mit dem höchsten Gewicht aus.\n\npot %&gt;% slice_max(weight, n=3)\n\n  variety    method plant tubers weight infection humidity\n1  Mariva aeroponic     6     13  323.3         0 45.84920\n2   Unica aeroponic     9      5  265.4         0 17.41489\n3   Unica       pot     2      3  248.4         0 30.23136"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#spalten",
    "href": "Themen/02/02_DeskriptiveStats.html#spalten",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Spalten",
    "text": "Spalten\nHäufig arbeitet man mit großen Datensätzen und vielen Variablen.\n\nselect\nMit der Funktion select kann man Variablen auswählen, indem ich sie durch Komme getrennt aufliste:\n\npot.sub %&gt;% select(variety, method, tubers, weight)\n\n# A tibble: 24 × 4\n# Groups:   variety, method [12]\n   variety   method     tubers weight\n   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 Costanera aeroponic       5   24.1\n 2 Costanera aeroponic       7   42  \n 3 Costanera bed             7  137. \n 4 Costanera bed             5   78  \n 5 Costanera hydroponic      6   31.8\n 6 Costanera hydroponic      5   42  \n 7 Costanera pot             3  110. \n 8 Costanera pot             7  139. \n 9 Mariva    aeroponic       6   99.2\n10 Mariva    aeroponic       5   72.6\n# ℹ 14 more rows\n\n\noder von variety bis weight\n\npot.sub %&gt;% select(variety:weight)\n\n# A tibble: 24 × 5\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 Costanera aeroponic      1      5   24.1\n 2 Costanera aeroponic      5      7   42  \n 3 Costanera bed            4      7  137. \n 4 Costanera bed            3      5   78  \n 5 Costanera hydroponic     8      6   31.8\n 6 Costanera hydroponic     4      5   42  \n 7 Costanera pot            5      3  110. \n 8 Costanera pot            6      7  139. \n 9 Mariva    aeroponic      7      6   99.2\n10 Mariva    aeroponic      5      5   72.6\n# ℹ 14 more rows\n\n\nwie oben nur ohne plant\n\npot.sub %&gt;% \n  select(variety:weight)%&gt;% \n  select(-plant)\n\n# A tibble: 24 × 4\n# Groups:   variety, method [12]\n   variety   method     tubers weight\n   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 Costanera aeroponic       5   24.1\n 2 Costanera aeroponic       7   42  \n 3 Costanera bed             7  137. \n 4 Costanera bed             5   78  \n 5 Costanera hydroponic      6   31.8\n 6 Costanera hydroponic      5   42  \n 7 Costanera pot             3  110. \n 8 Costanera pot             7  139. \n 9 Mariva    aeroponic       6   99.2\n10 Mariva    aeroponic       5   72.6\n# ℹ 14 more rows\n\n# oder so\npot.sub %&gt;% \n  select(c(variety:weight,-plant))\n\n# A tibble: 24 × 4\n# Groups:   variety, method [12]\n   variety   method     tubers weight\n   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 Costanera aeroponic       5   24.1\n 2 Costanera aeroponic       7   42  \n 3 Costanera bed             7  137. \n 4 Costanera bed             5   78  \n 5 Costanera hydroponic      6   31.8\n 6 Costanera hydroponic      5   42  \n 7 Costanera pot             3  110. \n 8 Costanera pot             7  139. \n 9 Mariva    aeroponic       6   99.2\n10 Mariva    aeroponic       5   72.6\n# ℹ 14 more rows\n\n# aber nicht so\npot.sub %&gt;% \n  select(c(-plant, variety:weight))\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     tubers weight infection humidity plant\n   &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 Costanera aeroponic       5   24.1         0     33.9     1\n 2 Costanera aeroponic       7   42           0     26.0     5\n 3 Costanera bed             7  137.          1     41.6     4\n 4 Costanera bed             5   78           1     51.0     3\n 5 Costanera hydroponic      6   31.8         1     57.2     8\n 6 Costanera hydroponic      5   42           1     56.8     4\n 7 Costanera pot             3  110.          0     26.6     5\n 8 Costanera pot             7  139.          0     41.6     6\n 9 Mariva    aeroponic       6   99.2         0     31.8     7\n10 Mariva    aeroponic       5   72.6         0     24.5     5\n# ℹ 14 more rows\n\n\n\npot.sub %&gt;% \n  select(ends_with(\"t\")) \n\nAdding missing grouping variables: `variety`, `method`\n\n\n# A tibble: 24 × 4\n# Groups:   variety, method [12]\n   variety   method     plant weight\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;\n 1 Costanera aeroponic      1   24.1\n 2 Costanera aeroponic      5   42  \n 3 Costanera bed            4  137. \n 4 Costanera bed            3   78  \n 5 Costanera hydroponic     8   31.8\n 6 Costanera hydroponic     4   42  \n 7 Costanera pot            5  110. \n 8 Costanera pot            6  139. \n 9 Mariva    aeroponic      7   99.2\n10 Mariva    aeroponic      5   72.6\n# ℹ 14 more rows\n\n\n\npot %&gt;% \n  select(ends_with(\"t\")) %&gt;% \n  slice_sample(n=8)\n\n  plant weight\n1     4  65.60\n2     5  78.30\n3     6  10.35\n4     6  14.15\n5     8  43.30\n6     9  34.10\n7     9  16.70\n8     4 142.80\n\n\n\n\nrename\nVariablen können umbenannt werden durch die Funktion rename().\n\npot.sub %&gt;% rename(plant_ID=plant)\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant_ID tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic         1      5   24.1         0     33.9\n 2 Costanera aeroponic         5      7   42           0     26.0\n 3 Costanera bed               4      7  137.          1     41.6\n 4 Costanera bed               3      5   78           1     51.0\n 5 Costanera hydroponic        8      6   31.8         1     57.2\n 6 Costanera hydroponic        4      5   42           1     56.8\n 7 Costanera pot               5      3  110.          0     26.6\n 8 Costanera pot               6      7  139.          0     41.6\n 9 Mariva    aeroponic         7      6   99.2         0     31.8\n10 Mariva    aeroponic         5      5   72.6         0     24.5\n# ℹ 14 more rows\n\n\n\npot.sub\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic      1      5   24.1         0     33.9\n 2 Costanera aeroponic      5      7   42           0     26.0\n 3 Costanera bed            4      7  137.          1     41.6\n 4 Costanera bed            3      5   78           1     51.0\n 5 Costanera hydroponic     8      6   31.8         1     57.2\n 6 Costanera hydroponic     4      5   42           1     56.8\n 7 Costanera pot            5      3  110.          0     26.6\n 8 Costanera pot            6      7  139.          0     41.6\n 9 Mariva    aeroponic      7      6   99.2         0     31.8\n10 Mariva    aeroponic      5      5   72.6         0     24.5\n# ℹ 14 more rows\n\n\nAuch hier müssen wir die Daten in einem neuen data.frame pot.sub1 speichern oder überschreiben (pot.sub=pot.sub %&gt;% rename(plant_ID=plant)), um auf die neue Variable zugreifen zu können.\n\npot.sub1=pot.sub %&gt;% rename(plant_ID=plant)\npot.sub1\n\n# A tibble: 24 × 7\n# Groups:   variety, method [12]\n   variety   method     plant_ID tubers weight infection humidity\n   &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 Costanera aeroponic         1      5   24.1         0     33.9\n 2 Costanera aeroponic         5      7   42           0     26.0\n 3 Costanera bed               4      7  137.          1     41.6\n 4 Costanera bed               3      5   78           1     51.0\n 5 Costanera hydroponic        8      6   31.8         1     57.2\n 6 Costanera hydroponic        4      5   42           1     56.8\n 7 Costanera pot               5      3  110.          0     26.6\n 8 Costanera pot               6      7  139.          0     41.6\n 9 Mariva    aeroponic         7      6   99.2         0     31.8\n10 Mariva    aeroponic         5      5   72.6         0     24.5\n# ℹ 14 more rows\n\n\n\n\nmutate\nEine neue Variable kann durch die Funktion mutate berechnet und eingefügt werden.\nBeispielsweise könnten wir das Gewicht in kg statt g angeben. Es wird eine neue Variable erzeugt weight_kg indem weight durch 1000 geteilt wird.\n\npot.sub %&gt;% \n  mutate(weight_kg=weight/1000)\n\n# A tibble: 24 × 8\n# Groups:   variety, method [12]\n   variety   method     plant tubers weight infection humidity weight_kg\n   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Costanera aeroponic      1      5   24.1         0     33.9    0.0241\n 2 Costanera aeroponic      5      7   42           0     26.0    0.042 \n 3 Costanera bed            4      7  137.          1     41.6    0.137 \n 4 Costanera bed            3      5   78           1     51.0    0.078 \n 5 Costanera hydroponic     8      6   31.8         1     57.2    0.0318\n 6 Costanera hydroponic     4      5   42           1     56.8    0.042 \n 7 Costanera pot            5      3  110.          0     26.6    0.110 \n 8 Costanera pot            6      7  139.          0     41.6    0.139 \n 9 Mariva    aeroponic      7      6   99.2         0     31.8    0.0992\n10 Mariva    aeroponic      5      5   72.6         0     24.5    0.0726\n# ℹ 14 more rows\n\n\nDamit diese neue Variable im Datensatz nicht nur erscheint, sondern auch zugreifbar ist, speichere ich den Datensatz unter einem neuen Namen ab. Man könnte ihn auch überschreiben. Ausserdem noch zwei Beispiele für eine log- und Wurzel-Transformation.\n\npot.sub1=pot.sub %&gt;% \n  mutate(weight_kg=weight/1000,\n         weight.sqrt=sqrt(weight),\n         weight.l=log(weight),\n         tubers.l=log(tubers))\npot.sub1\n\n# A tibble: 24 × 11\n# Groups:   variety, method [12]\n   variety   method plant tubers weight infection humidity weight_kg weight.sqrt\n   &lt;chr&gt;     &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n 1 Costanera aerop…     1      5   24.1         0     33.9    0.0241        4.91\n 2 Costanera aerop…     5      7   42           0     26.0    0.042         6.48\n 3 Costanera bed        4      7  137.          1     41.6    0.137        11.7 \n 4 Costanera bed        3      5   78           1     51.0    0.078         8.83\n 5 Costanera hydro…     8      6   31.8         1     57.2    0.0318        5.64\n 6 Costanera hydro…     4      5   42           1     56.8    0.042         6.48\n 7 Costanera pot        5      3  110.          0     26.6    0.110        10.5 \n 8 Costanera pot        6      7  139.          0     41.6    0.139        11.8 \n 9 Mariva    aerop…     7      6   99.2         0     31.8    0.0992        9.96\n10 Mariva    aerop…     5      5   72.6         0     24.5    0.0726        8.52\n# ℹ 14 more rows\n# ℹ 2 more variables: weight.l &lt;dbl&gt;, tubers.l &lt;dbl&gt;\n\n\n\nVariable in Faktor umwandeln\nBeim Importieren von Daten werden Variablen häufig als character eingelesen (oder als numeric), die für die spätere Analyse aber als Faktor benötigt werden. Wir können diese Variablen in Faktoren umwandeln, können diese überschreiben oder (wie unten gezeigt) geben ihnen einen neuen Namen mit dem Appendix “.f”.\n\npot=pot %&gt;% \n    mutate(variety.f=as.factor(variety),\n           method.f=as.factor(method),\n           infection.f=as.factor(infection))\n\nalternativer Code zu oben:\n\npot$variety.f=as.factor(pot$variety)\npot$method.f=as.factor(pot$method)\npot$infection.f=as.factor(pot$infection)\nstr(pot)\n\nMit across(where(is.character),as.factor) werden alle Variablen, die als Charakter eingelesen sind, in einen Faktor umgewandelt.\n\npot2&lt;-read.xlsx(\"potato.xlsx\", sheet=1)\nstr(pot2)\n\n'data.frame':   478 obs. of  7 variables:\n $ variety  : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method   : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n $ humidity : num  26.1 30.2 52.5 34 49.6 ...\n\npot3&lt;- pot2 %&gt;% mutate(across(where(is.character),as.factor))\nstr(pot3)\n\n'data.frame':   478 obs. of  7 variables:\n $ variety  : Factor w/ 3 levels \"Costanera\",\"Mariva\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ method   : Factor w/ 4 levels \"aeroponic\",\"bed\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n $ humidity : num  26.1 30.2 52.5 34 49.6 ...\n\n\nBitte beachten, dass infection damit nicht als Faktor umgewandelt wird, da es als numerische Variable eingelesen wurde. Wir müssen also immer nochmal die Struktur überprüfen und ggfls. nachjustieren.\n\npot4&lt;- pot2 %&gt;% mutate(across(where(is.character),as.factor),\n                       infection=as.factor(infection))\nstr(pot4)\n\n'data.frame':   478 obs. of  7 variables:\n $ variety  : Factor w/ 3 levels \"Costanera\",\"Mariva\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ method   : Factor w/ 4 levels \"aeroponic\",\"bed\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 1 1 1 ...\n $ humidity : num  26.1 30.2 52.5 34 49.6 ...\n\n\nDer große Vorteil von dplyr ist, dass ihr alle Schritte in einen Code schreiben und ihn damit gut nachvollziehen könnt.\n\npot1=pot%&gt;% \n  filter(variety==c(\"Mariva\", \"Costanera\"), tubers&gt;7) %&gt;% \n  mutate(weight_kg=weight/1000, \n         variety.f=as.factor(variety),\n         method.f=as.factor(method),\n         infection.f=as.factor(infection)) %&gt;% \n  select(!c(plant,infection, weight))\npot1\n\n     variety     method tubers humidity variety.f   method.f infection.f\n1     Mariva        bed      9 36.24464    Mariva        bed           0\n2     Mariva        bed     10 13.83214    Mariva        bed           0\n3     Mariva        bed      8 34.63448    Mariva        bed           0\n4  Costanera        pot      8 62.30639 Costanera        pot           1\n5  Costanera hydroponic      8 51.21347 Costanera hydroponic           1\n6  Costanera  aeroponic      9 40.65539 Costanera  aeroponic           0\n7     Mariva        pot     10 27.90961    Mariva        pot           0\n8     Mariva  aeroponic      8 55.48964    Mariva  aeroponic           1\n9  Costanera        pot      8 27.17098 Costanera        pot           0\n10 Costanera        pot      9 25.69880 Costanera        pot           0\n11    Mariva        bed     11 47.62537    Mariva        bed           0\n12    Mariva        bed      8 62.26231    Mariva        bed           1\n13    Mariva  aeroponic     10 28.71567    Mariva  aeroponic           0\n14    Mariva  aeroponic      8 54.04355    Mariva  aeroponic           0\n15    Mariva        pot     10 26.39289    Mariva        pot           0\n16    Mariva        bed     10 54.14047    Mariva        bed           1\n17    Mariva        bed      8 56.14320    Mariva        bed           1\n18    Mariva        bed     10 39.75289    Mariva        bed           0\n19    Mariva  aeroponic      9 30.72462    Mariva  aeroponic           0\n20    Mariva  aeroponic      8 36.82570    Mariva  aeroponic           0\n21 Costanera        pot      8 44.07980 Costanera        pot           0\n22 Costanera        bed      8 61.03558 Costanera        bed           1\n23 Costanera hydroponic      8 69.46336 Costanera hydroponic           1\n   weight_kg\n1     0.2274\n2     0.0338\n3     0.0948\n4     0.1624\n5     0.0486\n6     0.0781\n7     0.0773\n8     0.1205\n9     0.1449\n10    0.1391\n11    0.1182\n12    0.1250\n13    0.1883\n14    0.1656\n15    0.0644\n16    0.1069\n17    0.1332\n18    0.1183\n19    0.0759\n20    0.1684\n21    0.1531\n22    0.0494\n23    0.0253"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#übung-2.1.",
    "href": "Themen/02/02_DeskriptiveStats.html#übung-2.1.",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Übung 2.1.",
    "text": "Übung 2.1.\nDie Körpergröße, Schuhgröße, Geschlecht und Augenfarbe von Kursteilnehmer wurde ermittelt. Importiere bitte die Daten Kursteilnehmer.xlsx in R und benenne den data.frame mit md.\n\n\n\n\n\n\nDaten einlesen und prüfen\n\n\n\n\n\nDer Datensatz hat in der ersten Zeile eine detaillierte und in der zweiter Zeile die kurze Variablenbezeichnung. Daher lese ich die Daten mit dem Argument startRow = 2 erst ab der zweiten Zeile ein.\n\nlibrary(openxlsx)\nmd&lt;-read.xlsx(\"Kursteilnehmer.xlsx\", sheet=1, startRow = 2)\nstr(md)\n\n'data.frame':   72 obs. of  5 variables:\n $ Name: chr  \"Colton\" \"Kyle\" \"Brandon\" \"Cory\" ...\n $ KG  : num  181 183 186 184 172 186 183 197 180 184 ...\n $ SG  : num  42 44 42 45 43 43 42 45 43 43 ...\n $ AF  : chr  \"braun\" \"braun\" \"braun\" \"blau\" ...\n $ G   : chr  \"m\" \"m\" \"m\" \"m\" ...\n\n\n\n\n\nErstelle einen neuen Datensatz mit Beobachtungen von Kursteilnehmern mit jeweils:\n\nblauen Augen (md1)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlibrary(dplyr)\nmd1 = md %&gt;% filter(AF==\"blau\")\nmd1\n\n         Name  KG SG   AF G\n1        Cory 184 45 blau m\n2       Heath 172 43 blau m\n3       Jesse 186 43 blau m\n4       David 180 43 blau m\n5     Brandon 189 48 blau m\n6        Luke 177 44 blau m\n7        Cole 180 43 blau m\n8       Lance 173 40 blau m\n9     Braxton 180 44 blau m\n10       Noah 200 45 blau m\n11       Mark 183 43 blau m\n12     George 178 44 blau m\n13     Camron 183 44 blau m\n14   Benjamin 192 43 blau m\n15       Drew 178 41 blau m\n16       Kyle 173 42 blau m\n17    Janelle 167 39 blau w\n18    Kathryn 170 37 blau w\n19     Jordan 150 36 blau w\n20      Kiana 152 35 blau w\n21  Kimberlyn 164 40 blau w\n22      Janie 167 39 blau w\n23     Kelsey 164 38 blau w\n24    Kellcie 180 39 blau w\n25     Maggie 168 38 blau w\n26    Cassidy 157 38 blau w\n27 Mattielien 154 38 blau w\n28    Carissa 170 40 blau w\n\n\n\n\n\n\nKörpergröße größer 1,70 m (md2)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd2 = md %&gt;% filter(KG&gt;170)\nmd2\n\n            Name  KG SG    AF G\n1         Colton 181 42 braun m\n2           Kyle 183 44 braun m\n3        Brandon 186 42 braun m\n4           Cory 184 45  blau m\n5          Heath 172 43  blau m\n6          Jesse 186 43  blau m\n7         Daniel 183 42 braun m\n8         Bradin 197 45 braun m\n9          David 180 43  blau m\n10          Kyle 184 43 braun m\n11       Brandon 189 48  blau m\n12          Luke 177 44  blau m\n13       Cameron 181 43 braun m\n14 Jackson Payne 176 42 braun m\n15          Cole 180 43  blau m\n16         Riley 184 44 gruen m\n17         Lance 173 40  blau m\n18         Nakai 178 43 braun m\n19       Garrett 182 43 braun m\n20       Braxton 180 44  blau m\n21          Noah 200 45  blau m\n22        Brolon 178 44 braun m\n23          Mark 183 43  blau m\n24        George 178 44  blau m\n25        Camron 183 44  blau m\n26        Bryson 180 41 braun m\n27      Benjamin 192 43  blau m\n28          Drew 178 41  blau m\n29          Kyle 173 42  blau m\n30         Jacob 178 42 gruen m\n31         Paige 177 40 braun w\n32        Morgan 173 41 gruen w\n33       Kaitlyn 172 38 gruen w\n34       Kellcie 180 39  blau w\n35         Hanna 172 41 braun w\n36         Traci 175 41 braun w\n37        Hannah 176 39 braun w\n38       Felicia 172 40 braun w\n39      Kaytlynn 186 42 braun w\n\n\n\n\n\n\nblauen und grünen Augen (md3)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd3 = md %&gt;% filter(AF%in%c(\"blau\", \"gruen\"))\nmd3\n\n         Name  KG SG    AF G\n1        Cory 184 45  blau m\n2       Heath 172 43  blau m\n3       Jesse 186 43  blau m\n4       David 180 43  blau m\n5     Brandon 189 48  blau m\n6        Luke 177 44  blau m\n7      Justin 160 38 gruen m\n8        Cole 180 43  blau m\n9       Riley 184 44 gruen m\n10      Lance 173 40  blau m\n11    Braxton 180 44  blau m\n12       Noah 200 45  blau m\n13       Mark 183 43  blau m\n14     George 178 44  blau m\n15     Camron 183 44  blau m\n16   Benjamin 192 43  blau m\n17       Drew 178 41  blau m\n18      Brian 163 42 gruen m\n19       Kyle 173 42  blau m\n20      Jacob 178 42 gruen m\n21    Allison 170 41 gruen w\n22    Janelle 167 39  blau w\n23    Kathryn 170 37  blau w\n24     Jordan 150 36  blau w\n25      Kiana 152 35  blau w\n26  Kimberlyn 164 40  blau w\n27     Morgan 173 41 gruen w\n28      Janie 167 39  blau w\n29     Soraya 170 39 gruen w\n30    Kaitlyn 172 38 gruen w\n31     Kelsey 164 38  blau w\n32   Brynelle 165 37 gruen w\n33    Kellcie 180 39  blau w\n34     Maggie 168 38  blau w\n35    Cassidy 157 38  blau w\n36    Mallory 160 38 gruen w\n37       Erin 160 38 gruen w\n38 Mattielien 154 38  blau w\n39    Carissa 170 40  blau w\n40   Danielle 164 37 gruen w\n\n\n\n\n\n\nohne Schuhgröße (md4)\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd4 = md %&gt;% select(-SG)\nmd4\n\n            Name  KG    AF G\n1         Colton 181 braun m\n2           Kyle 183 braun m\n3        Brandon 186 braun m\n4           Cory 184  blau m\n5          Heath 172  blau m\n6          Jesse 186  blau m\n7         Daniel 183 braun m\n8         Bradin 197 braun m\n9          David 180  blau m\n10          Kyle 184 braun m\n11       Brandon 189  blau m\n12          Luke 177  blau m\n13       Cameron 181 braun m\n14        Justin 160 gruen m\n15 Jackson Payne 176 braun m\n16          Cole 180  blau m\n17         Riley 184 gruen m\n18         Lance 173  blau m\n19         Nakai 178 braun m\n20       Garrett 182 braun m\n21       Braxton 180  blau m\n22          Noah 200  blau m\n23        Brolon 178 braun m\n24          Mark 183  blau m\n25        George 178  blau m\n26        Camron 183  blau m\n27        Bryson 180 braun m\n28      Benjamin 192  blau m\n29          Drew 178  blau m\n30         Brian 163 gruen m\n31          Kyle 173  blau m\n32         Jacob 178 gruen m\n33         Paige 177 braun w\n34       Allison 170 gruen w\n35       Janelle 167  blau w\n36        Ashlie 163 braun w\n37       Kathryn 170  blau w\n38        Jordan 150  blau w\n39         Kiana 152  blau w\n40     Kimberlyn 164  blau w\n41         Sydne 165 braun w\n42       Jessica 170 braun w\n43        Morgan 173 gruen w\n44         Janie 167  blau w\n45        Soraya 170 gruen w\n46         Grace 168 braun w\n47      Danielle 167 braun w\n48     Elizabeth 163 braun w\n49       Kaitlyn 172 gruen w\n50      Bethanie 167 braun w\n51        Kelsey 164  blau w\n52         Dixie 170 braun w\n53      Brynelle 165 gruen w\n54       Andreah 162 braun w\n55      Ashleigh 170 braun w\n56       Kellcie 180  blau w\n57        Maggie 168  blau w\n58       Cassidy 157  blau w\n59       Mallory 160 gruen w\n60       Lindsay 168 braun w\n61          Erin 162 braun w\n62          Erin 160 gruen w\n63         Hanna 172 braun w\n64         Traci 175 braun w\n65        Hannah 176 braun w\n66    Mattielien 154  blau w\n67       Felicia 172 braun w\n68       Carissa 170  blau w\n69      Danielle 164 gruen w\n70      Kaytlynn 186 braun w\n71        Lauren 168 braun w\n72        Jenine 168 braun w\n\n\n\n\n\nEnde Übung 2.1."
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#qualitative-daten",
    "href": "Themen/02/02_DeskriptiveStats.html#qualitative-daten",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Qualitative Daten",
    "text": "Qualitative Daten\nQualitative Variablen sind in unserem Beispiel die Sorte, der Krankheitsbefall und die Methode. Diese Daten beschreiben wir durch Häufigkeitstabellen (Kontingenztabellen), die angeben, wie häufig eine Merkmalsausprägung bzw. -kombination in unserem Datensatz vorkommt. Wir nutzen die Funktion count()aus dem Package dplyr\n\npot %&gt;% count(variety)\n\n    variety   n\n1 Costanera 158\n2    Mariva 160\n3     Unica 160\n\n\noder die Funktion table().\n\ntable(pot$variety) \n\n\nCostanera    Mariva     Unica \n      158       160       160 \n\n\nDie Funktion prop.table() berechnet uns die relativen Anteile jeder Merkmalsausprägung bzw. -kombination.\n\npot %&gt;% count(variety) %&gt;% \n  mutate(prop = prop.table(n))\n\n    variety   n      prop\n1 Costanera 158 0.3305439\n2    Mariva 160 0.3347280\n3     Unica 160 0.3347280\n\n\n\nprop.table(table(pot$variety)) # relativ, i.e. Anteil der Beobachtungen an der Gesamtzahl der Beobachtungen \n\n\nCostanera    Mariva     Unica \n0.3305439 0.3347280 0.3347280 \n\n\nHäufigkeitstabellen können für 2 Kombinationen (Merkmale) erstellt werden, indem man beide Variablen in der Funktion count() oder table() angibt.\n\npot %&gt;% count(variety, infection) %&gt;% \n  mutate(prop = prop.table(n))\n\n    variety infection   n       prop\n1 Costanera         0  77 0.16108787\n2 Costanera         1  81 0.16945607\n3    Mariva         0 119 0.24895397\n4    Mariva         1  41 0.08577406\n5     Unica         0 122 0.25523013\n6     Unica         1  38 0.07949791\n\n\n\ntable(pot$variety, pot$infection)\n\n           \n              0   1\n  Costanera  77  81\n  Mariva    119  41\n  Unica     122  38\n\nprop.table(table(pot$variety, pot$infection)) # relative Häufigkeit\n\n           \n                     0          1\n  Costanera 0.16108787 0.16945607\n  Mariva    0.24895397 0.08577406\n  Unica     0.25523013 0.07949791\n\n\nHäufigkeitstabelle für 3 Kombinationen\n\npot %&gt;% count(variety, method, infection) %&gt;% \n  mutate(prop = prop.table(n))\n\n     variety     method infection  n       prop\n1  Costanera  aeroponic         0 28 0.05857741\n2  Costanera  aeroponic         1 12 0.02510460\n3  Costanera        bed         0  9 0.01882845\n4  Costanera        bed         1 31 0.06485356\n5  Costanera hydroponic         0 11 0.02301255\n6  Costanera hydroponic         1 27 0.05648536\n7  Costanera        pot         0 29 0.06066946\n8  Costanera        pot         1 11 0.02301255\n9     Mariva  aeroponic         0 27 0.05648536\n10    Mariva  aeroponic         1 13 0.02719665\n11    Mariva        bed         0 29 0.06066946\n12    Mariva        bed         1 11 0.02301255\n13    Mariva hydroponic         0 31 0.06485356\n14    Mariva hydroponic         1  9 0.01882845\n15    Mariva        pot         0 32 0.06694561\n16    Mariva        pot         1  8 0.01673640\n17     Unica  aeroponic         0 30 0.06276151\n18     Unica  aeroponic         1 10 0.02092050\n19     Unica        bed         0 31 0.06485356\n20     Unica        bed         1  9 0.01882845\n21     Unica hydroponic         0 32 0.06694561\n22     Unica hydroponic         1  8 0.01673640\n23     Unica        pot         0 29 0.06066946\n24     Unica        pot         1 11 0.02301255\n\n\n\ntable(pot$variety, pot$method, pot$infection)\n\n, ,  = 0\n\n           \n            aeroponic bed hydroponic pot\n  Costanera        28   9         11  29\n  Mariva           27  29         31  32\n  Unica            30  31         32  29\n\n, ,  = 1\n\n           \n            aeroponic bed hydroponic pot\n  Costanera        12  31         27  11\n  Mariva           13  11          9   8\n  Unica            10   9          8  11\n\nftable(pot$variety, pot$method, pot$infection)\n\n                       0  1\n                           \nCostanera aeroponic   28 12\n          bed          9 31\n          hydroponic  11 27\n          pot         29 11\nMariva    aeroponic   27 13\n          bed         29 11\n          hydroponic  31  9\n          pot         32  8\nUnica     aeroponic   30 10\n          bed         31  9\n          hydroponic  32  8\n          pot         29 11"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#quantitative-daten",
    "href": "Themen/02/02_DeskriptiveStats.html#quantitative-daten",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Quantitative Daten",
    "text": "Quantitative Daten\n\nMittelwert und Median\n\nArithmetischer Mittelwert mean()\nMedian median(): Wert, der an der mittleren (zentralen) Stelle steht, wenn man die Werte der Größe nach sortiert\nMedian besser als arithmetischer Mittelwert bei:\n\nordinalskalierten Beobachtungen\ngeringem Stichprobenumfang\nasymmetrischen Verteilungen\nVerdacht auf Ausreißer\n\n\n\npot %&gt;% \n  summarise(tubers_avg=mean(tubers))\n\n  tubers_avg\n1   4.721757\n\n\n\npot %&gt;% \n  summarise(tubers_avg=mean(tubers),\n            tubers_med=median(tubers))\n\n  tubers_avg tubers_med\n1   4.721757          4\n\n\n\nmean(pot$tubers)\n\n[1] 4.721757\n\nmedian(pot$tubers)\n\n[1] 4\n\n\n\n\nVarianz und Standardabweichung\nsind Maße, die die Streuung der Daten beschreiben.\n\nVarianz var()\nStandardabweichung sd()\nStandardabweichung in gleicher Einheit wie Mittelwert\nWenn Mittelwert und Standardabweichung einer normalverteilten Grundgesamtheit bekannt ist, kann die Wahrscheinlichkeit berechnet werden, mit der ein Wert auftritt.\n\n\npot %&gt;% \n  summarise(tubers_avg=mean(tubers),\n            tubers_med=median(tubers),\n            tubers_var=var(tubers),\n            tubers_sd=sd(tubers))\n\n  tubers_avg tubers_med tubers_var tubers_sd\n1   4.721757          4   5.190763  2.278324\n\n\n\nvar(pot$tubers)\n\n[1] 5.190763\n\nsd(pot$tubers)\n\n[1] 2.278324\n\n\n\n\nStandardfehler des Mittelwertes (sem)\nbeschreibt die Genauigkeit der Berechnung des Stichproben-Mittelwertes.\n\nsem = sd/sqrt(n)\nstd &lt;- function(x) {sd(x, na.rm=TRUE)/sqrt(length(na.omit(x)))}\nkein Streuungsmaß der Stichprobe\nje mehr Datenpunkte, desto genauer die Schätzung des Mittelwertes\nMittelwert ± 1 sem beschreibt den Wertebereich, in dem wir mit 68%iger Wahrscheinlichkeit den wahren Mittelwert erwarten\nMittelwert ± 1,96 sem 95% Wahrscheinlichkeit i.e. Konfidenzintervall\nMittelwert ± 2 sem 95,5%\nMittelwert ± 3 sem 99,7%\n\n\n# Funktion für den Standardfehler\nstd &lt;- function(x) {sd(x, na.rm=TRUE)/sqrt(length(na.omit(x)))} #muss nur einmal definiert werden\nstd(pot$tubers)\n\n[1] 0.1042081\n\n\n\n\nweitere Maße zur beschreibenden Statistik:\n\nMinimum min()\nMaximum max()\nWertebereich range()\nQuantile quantile()\nVarianzkoeffizient: CV = sd/mean\n\n\nmin(pot$tubers)\n\n[1] 0\n\nmax(pot$tubers)\n\n[1] 13\n\nrange(pot$tubers)\n\n[1]  0 13\n\nquantile(pot$tubers)\n\n  0%  25%  50%  75% 100% \n   0    3    4    6   13 \n\nquantile(pot$tubers, p=c(0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 0.90, 0.95, 0.99))\n\n 1%  5% 10% 25% 50% 75% 90% 95% 99% \n  0   2   2   3   4   6   8   9  11 \n\n#Funktion für Variationskoeffizienten\nCV &lt;- function(x) {sd(x, na.rm=TRUE)/mean(x, na.rm=TRUE)} \n\n\npot %&gt;% \n  summarise(tubers_avg=mean(tubers),\n            tubers_med=median(tubers),\n            tubers_var=var(tubers),\n            tubers_sd=sd(tubers),\n            tubers_std=std(tubers),\n            tubers_min=min(tubers),\n            tubers_max=max(tubers),\n            tubers_q25=quantile(tubers, 0.25),\n            tubers_q75=quantile(tubers, 0.75),\n            tubers_CV=CV(tubers))\n\n  tubers_avg tubers_med tubers_var tubers_sd tubers_std tubers_min tubers_max\n1   4.721757          4   5.190763  2.278324  0.1042081          0         13\n  tubers_q25 tubers_q75 tubers_CV\n1          3          6 0.4825162"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#anwendungsbeispiele",
    "href": "Themen/02/02_DeskriptiveStats.html#anwendungsbeispiele",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Anwendungsbeispiele",
    "text": "Anwendungsbeispiele\nEine erste einfache Beschreibung der Daten kann mit der Funktion summary() erfolgen. Hier sieht man jetzt den Unterschied im Output zwischen variety (als character) und variety.f (als factor).\n\nsummary(pot)\n\n   variety             method              plant           tubers      \n Length:478         Length:478         Min.   : 1.00   Min.   : 0.000  \n Class :character   Class :character   1st Qu.: 3.00   1st Qu.: 3.000  \n Mode  :character   Mode  :character   Median : 5.00   Median : 4.000  \n                                       Mean   : 5.49   Mean   : 4.722  \n                                       3rd Qu.: 8.00   3rd Qu.: 6.000  \n                                       Max.   :10.00   Max.   :13.000  \n     weight         infection         humidity         variety.f  \n Min.   :  0.00   Min.   :0.0000   Min.   : 0.00   Costanera:158  \n 1st Qu.: 26.07   1st Qu.:0.0000   1st Qu.:28.53   Mariva   :160  \n Median : 61.00   Median :0.0000   Median :38.14   Unica    :160  \n Mean   : 72.77   Mean   :0.3347   Mean   :38.40                  \n 3rd Qu.:109.25   3rd Qu.:1.0000   3rd Qu.:48.47                  \n Max.   :323.30   Max.   :1.0000   Max.   :80.00                  \n       method.f   infection.f\n aeroponic :120   0:318      \n bed       :120   1:160      \n hydroponic:118              \n pot       :120              \n                             \n                             \n\n\nMöchte man eine beschreibende Statistik für jede numerische Variable berechnen, kann die Funktion summarise_if(is.numeric, mean, na.rm = TRUE) genutzt werden. Im Beispiel berechnen wir den Mittelwert für alle Variablen im data.frame pot.\n\npot %&gt;%\n  summarise_if(is.numeric, mean, na.rm = TRUE)\n\n    plant   tubers   weight infection humidity\n1 5.48954 4.721757 72.77259  0.334728 38.39556\n\n\nHäufig möchte man die beschreibende Statistik für ein oder mehrere Gruppierungslevel berechnen. Bspw. das mittleres Gewicht je Sorte. Wir nutzen hierfür die Funktion group_by():\n\npot %&gt;% group_by(variety) %&gt;% \n  summarise(weight_avg=mean(weight, na.rm = TRUE))\n\n# A tibble: 3 × 2\n  variety   weight_avg\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Costanera       74.1\n2 Mariva          74.7\n3 Unica           69.6\n\n\nBsp.: mittleres Gewicht je Sorte und Methode\n\npot %&gt;% group_by(variety, method) %&gt;% \n  summarise(weight_avg=mean(weight, na.rm = TRUE))\n\n`summarise()` has grouped output by 'variety'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 3\n# Groups:   variety [3]\n   variety   method     weight_avg\n   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;\n 1 Costanera aeroponic        40.2\n 2 Costanera bed              87.5\n 3 Costanera hydroponic       25.1\n 4 Costanera pot             141. \n 5 Mariva    aeroponic        95.4\n 6 Mariva    bed              96.8\n 7 Mariva    hydroponic       14.3\n 8 Mariva    pot              92.2\n 9 Unica     aeroponic        88.5\n10 Unica     bed              69.1\n11 Unica     hydroponic       26.3\n12 Unica     pot              94.6\n\n\nBsp.: Mittelwert und Standardabweichung von Gewicht je Sorte und Methode\n\npot %&gt;% group_by(variety, method) %&gt;% \n  summarise(weight_avg=mean(weight, na.rm = TRUE),\n            weight_sd=sd(weight, na.rm = TRUE))\n\n`summarise()` has grouped output by 'variety'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 12 × 4\n# Groups:   variety [3]\n   variety   method     weight_avg weight_sd\n   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n 1 Costanera aeroponic        40.2     16.6 \n 2 Costanera bed              87.5     32.6 \n 3 Costanera hydroponic       25.1      8.17\n 4 Costanera pot             141.      22.2 \n 5 Mariva    aeroponic        95.4     54.8 \n 6 Mariva    bed              96.8     54.8 \n 7 Mariva    hydroponic       14.3      9.34\n 8 Mariva    pot              92.2     27.4 \n 9 Unica     aeroponic        88.5     70.8 \n10 Unica     bed              69.1     36.4 \n11 Unica     hydroponic       26.3     14.1 \n12 Unica     pot              94.6     60.3 \n\n\nHier ein Code für eine Übersichtstabelle zur Beschreibung der Daten:\n\nlibrary(tidyr)\npot %&gt;% summarise(across(where(is.numeric), .fns = \n                     list(min = min,\n                          median = median,\n                          mean = mean,\n                          stdev = sd,\n                          q25 = ~quantile(., 0.25),\n                          q75 = ~quantile(., 0.75),\n                          max = max, \n                          n=length))) %&gt;%\n  pivot_longer(everything(), names_sep='_', names_to=c('variable', '.value'))\n\n# A tibble: 5 × 9\n  variable    min median   mean  stdev   q25   q75   max     n\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 plant         1    5    5.49   2.87    3     8     10    478\n2 tubers        0    4    4.72   2.28    3     6     13    478\n3 weight        0   61   72.8   53.6    26.1 109.   323.   478\n4 infection     0    0    0.335  0.472   0     1      1    478\n5 humidity      0   38.1 38.4   14.2    28.5  48.5   80    478\n\n\nund hier nur für tubers und weight:\n\npot %&gt;% summarise(across(c(\"tubers\", \"weight\"), .fns = \n                     list(min = min,\n                          median = median,\n                          mean = mean,\n                          stdev = sd,\n                          q25 = ~quantile(., 0.25),\n                          q75 = ~quantile(., 0.75),\n                          max = max, \n                          n=length))) %&gt;%\n  pivot_longer(everything(), names_sep='_', names_to=c('variable', '.value'))\n\n# A tibble: 2 × 9\n  variable   min median  mean stdev   q25   q75   max     n\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 tubers       0      4  4.72  2.28   3      6    13    478\n2 weight       0     61 72.8  53.6   26.1  109.  323.   478\n\n\nbzw. ohne plant\n\npot %&gt;% \n  select(!plant)%&gt;% \n  summarise(across(where(is.numeric), .fns = \n                     list(min = min,\n                          median = median,\n                          mean = mean,\n                          stdev = sd,\n                          q25 = ~quantile(., 0.25),\n                          q75 = ~quantile(., 0.75),\n                          max = max, \n                          n=length))) %&gt;%\n  pivot_longer(everything(), names_sep='_', names_to=c('variable', '.value'))\n\n# A tibble: 4 × 9\n  variable    min median   mean  stdev   q25   q75   max     n\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 tubers        0    4    4.72   2.28    3     6     13    478\n2 weight        0   61   72.8   53.6    26.1 109.   323.   478\n3 infection     0    0    0.335  0.472   0     1      1    478\n4 humidity      0   38.1 38.4   14.2    28.5  48.5   80    478\n\n\nfür unterschiedliche Methoden:\n\npot %&gt;%  group_by(method) %&gt;%\n  summarise(across(c(\"tubers\", \"weight\"), .fns = \n                     list(min = min,\n                          median = median,\n                          mean = mean,\n                          stdev = sd,\n                          q25 = ~quantile(., 0.25),\n                          q75 = ~quantile(., 0.75),\n                          max = max, \n                          n=length))) %&gt;%\n  pivot_longer(cols = -method,  names_sep='_', names_to=c('variable', '.value')) %&gt;% \n  arrange(variable)%&gt;% \n  relocate(variable)\n\n# A tibble: 8 × 10\n  variable method       min median   mean stdev   q25   q75   max     n\n  &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 tubers   aeroponic   0       5     4.76  2.29  3.75   6    13     120\n2 tubers   bed         1       5     5.55  2.37  4      7    13     120\n3 tubers   hydroponic  1       3     3.15  1.67  2      4     8     118\n4 tubers   pot         2       5     5.4   1.89  4      7    10     120\n5 weight   aeroponic   0      62.1  74.7  57.7  36.2   99.2 323.    120\n6 weight   bed        13.2    79.6  84.5  43.6  50.3  118.  227.    120\n7 weight   hydroponic  2.95   20.0  21.8  12.1  14.1   25.4  58.7   118\n8 weight   pot        11.3   111.  109.   45.9  72.7  143.  248.    120"
  },
  {
    "objectID": "Themen/02/02_DeskriptiveStats.html#übung-2.2.",
    "href": "Themen/02/02_DeskriptiveStats.html#übung-2.2.",
    "title": "Datenmanagement und deskriptive Statistik",
    "section": "Übung 2.2.",
    "text": "Übung 2.2.\nDie Körpergröße, Schuhgröße, Geschlecht und Augenfarbe von Kursteilnehmer wurde ermittelt. Importiere bitte die Daten Kursteilnehmer.xlsx in R und benenne den data.frame mit md.\n\n\n\n\n\n\nDaten einlesen und prüfen\n\n\n\n\n\nDer Datensatz hat in der ersten Zeile eine detaillierte und in der zweiter Zeile die kurze Variablenbezeichnung. Daher lese ich die Daten mit dem Argument startRow = 2 erst ab der zweiten Zeile ein.\n\nlibrary(openxlsx)\nmd&lt;-read.xlsx(\"Kursteilnehmer.xlsx\", sheet=1, startRow = 2)\nstr(md)\n\n'data.frame':   72 obs. of  5 variables:\n $ Name: chr  \"Colton\" \"Kyle\" \"Brandon\" \"Cory\" ...\n $ KG  : num  181 183 186 184 172 186 183 197 180 184 ...\n $ SG  : num  42 44 42 45 43 43 42 45 43 43 ...\n $ AF  : chr  \"braun\" \"braun\" \"braun\" \"blau\" ...\n $ G   : chr  \"m\" \"m\" \"m\" \"m\" ...\n\n\n\n\n\n\nNutze die Funktion summary(md), um die Daten zu beschreiben.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsummary(md)\n\n     Name                 KG              SG             AF           \n Length:72          Min.   :150.0   Min.   :35.00   Length:72         \n Class :character   1st Qu.:167.0   1st Qu.:38.00   Class :character  \n Mode  :character   Median :172.0   Median :40.00   Mode  :character  \n                    Mean   :173.2   Mean   :40.61                     \n                    3rd Qu.:180.0   3rd Qu.:43.00                     \n                    Max.   :200.0   Max.   :48.00                     \n      G            \n Length:72         \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\n\n\nErmittele die Anzahl Frauen und Männer für jede Augenfarbe.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd %&gt;% count(AF, G) %&gt;% \n  mutate(prop = prop.table(n))\n\n     AF G  n       prop\n1  blau m 16 0.22222222\n2  blau w 12 0.16666667\n3 braun m 12 0.16666667\n4 braun w 20 0.27777778\n5 gruen m  4 0.05555556\n6 gruen w  8 0.11111111\n\n\n\n\n\n\nBerechne die mittlere Körpergröße für Männer und Frauen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd %&gt;% group_by(G) %&gt;% \n  summarise(KG_avg=mean(KG, na.rm = TRUE))\n\n# A tibble: 2 × 2\n  G     KG_avg\n  &lt;chr&gt;  &lt;dbl&gt;\n1 m       181.\n2 w       167.\n\n\n\n\n\n\nBerechne den Quotienten aus Körpergröße und Schuhgröße für jeden Teilnehmer und füge diesen in den data.frame ein.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd1=md %&gt;% \n  mutate(Q=KG/SG)\nmd1\n\n            Name  KG SG    AF G        Q\n1         Colton 181 42 braun m 4.309524\n2           Kyle 183 44 braun m 4.159091\n3        Brandon 186 42 braun m 4.428571\n4           Cory 184 45  blau m 4.088889\n5          Heath 172 43  blau m 4.000000\n6          Jesse 186 43  blau m 4.325581\n7         Daniel 183 42 braun m 4.357143\n8         Bradin 197 45 braun m 4.377778\n9          David 180 43  blau m 4.186047\n10          Kyle 184 43 braun m 4.279070\n11       Brandon 189 48  blau m 3.937500\n12          Luke 177 44  blau m 4.022727\n13       Cameron 181 43 braun m 4.209302\n14        Justin 160 38 gruen m 4.210526\n15 Jackson Payne 176 42 braun m 4.190476\n16          Cole 180 43  blau m 4.186047\n17         Riley 184 44 gruen m 4.181818\n18         Lance 173 40  blau m 4.325000\n19         Nakai 178 43 braun m 4.139535\n20       Garrett 182 43 braun m 4.232558\n21       Braxton 180 44  blau m 4.090909\n22          Noah 200 45  blau m 4.444444\n23        Brolon 178 44 braun m 4.045455\n24          Mark 183 43  blau m 4.255814\n25        George 178 44  blau m 4.045455\n26        Camron 183 44  blau m 4.159091\n27        Bryson 180 41 braun m 4.390244\n28      Benjamin 192 43  blau m 4.465116\n29          Drew 178 41  blau m 4.341463\n30         Brian 163 42 gruen m 3.880952\n31          Kyle 173 42  blau m 4.119048\n32         Jacob 178 42 gruen m 4.238095\n33         Paige 177 40 braun w 4.425000\n34       Allison 170 41 gruen w 4.146341\n35       Janelle 167 39  blau w 4.282051\n36        Ashlie 163 39 braun w 4.179487\n37       Kathryn 170 37  blau w 4.594595\n38        Jordan 150 36  blau w 4.166667\n39         Kiana 152 35  blau w 4.342857\n40     Kimberlyn 164 40  blau w 4.100000\n41         Sydne 165 38 braun w 4.342105\n42       Jessica 170 38 braun w 4.473684\n43        Morgan 173 41 gruen w 4.219512\n44         Janie 167 39  blau w 4.282051\n45        Soraya 170 39 gruen w 4.358974\n46         Grace 168 39 braun w 4.307692\n47      Danielle 167 39 braun w 4.282051\n48     Elizabeth 163 37 braun w 4.405405\n49       Kaitlyn 172 38 gruen w 4.526316\n50      Bethanie 167 39 braun w 4.282051\n51        Kelsey 164 38  blau w 4.315789\n52         Dixie 170 39 braun w 4.358974\n53      Brynelle 165 37 gruen w 4.459459\n54       Andreah 162 38 braun w 4.263158\n55      Ashleigh 170 40 braun w 4.250000\n56       Kellcie 180 39  blau w 4.615385\n57        Maggie 168 38  blau w 4.421053\n58       Cassidy 157 38  blau w 4.131579\n59       Mallory 160 38 gruen w 4.210526\n60       Lindsay 168 38 braun w 4.421053\n61          Erin 162 39 braun w 4.153846\n62          Erin 160 38 gruen w 4.210526\n63         Hanna 172 41 braun w 4.195122\n64         Traci 175 41 braun w 4.268293\n65        Hannah 176 39 braun w 4.512821\n66    Mattielien 154 38  blau w 4.052632\n67       Felicia 172 40 braun w 4.300000\n68       Carissa 170 40  blau w 4.250000\n69      Danielle 164 37 gruen w 4.432432\n70      Kaytlynn 186 42 braun w 4.428571\n71        Lauren 168 40 braun w 4.200000\n72        Jenine 168 37 braun w 4.540541\n\n\n\n\n\n\nExportiere die Daten z.B. mit write.xlsx().\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nwrite.xlsx(md1, \"KT_export.xlsx\", overwrite = TRUE)\n\n\n\n\nZusatzaufgabe\n\nExportiere sowohl die Daten als auch eine Summary Statistics der Daten in einem xlsx-file mit zwei Tabellenblätter.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmd.sum=md %&gt;%  group_by(G) %&gt;%\n  summarise(across(c(\"KG\", \"SG\"), .fns = \n                     list(min = min,\n                          median = median,\n                          mean = mean,\n                          stdev = sd,\n                          q25 = ~quantile(., 0.25),\n                          q75 = ~quantile(., 0.75),\n                          max = max, \n                          n=length))) %&gt;%\n  pivot_longer(cols = -G,  names_sep='_', names_to=c('X', '.value')) %&gt;% \n  arrange(X)%&gt;% \n  relocate(X)\nmd.sum\n\n# A tibble: 4 × 10\n  X     G       min median  mean stdev   q25   q75   max     n\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 KG    m       160   180. 181.   7.95  178    184   200    32\n2 KG    w       150   168  167.   7.07  164.   170   186    40\n3 SG    m        38    43   43.0  1.73   42     44    48    32\n4 SG    w        35    39   38.7  1.47   38     40    42    40\n\n\n\nwb &lt;- createWorkbook()\naddWorksheet(wb, sheetName = \"KT\")\nwriteData(wb, \"KT\", md1) \naddWorksheet(wb, sheetName = \"summary statistics\")\nwriteData(wb, \"summary statistics\", md.sum) \nsaveWorkbook(wb, file = \"KT_export1.xlsx\", overwrite = TRUE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Über diese Webseite",
    "section": "",
    "text": "Diese Webseite ist die Grundlage für meine Kurse, die ich für Wissenschaftler*innen am JKI gebe. Sie soll den Einstieg in die Arbeit mit R erleichtern und anhand von Beispielen Lösungswege und -möglichkeiten für häufig auftretende statistische Fragestellungen aufzeigen. Sie ist als eine Art Kochbuch zu verstehen. Man kann die Rezepte verwenden und selbst kreativ werden.\nDie Inhalte dieser Webseite dienen ausschließlich informatorischen Zwecken. Diese werden kontinuierlich aktualisiert und erweitert. Eine Garantie für die Aktualität, Richtigkeit und Vollständigkeit der zur Verfügung gestellten Informationen ist jedoch ausgeschlossen.\nBei Fragen und Anmerkungen kontaktiert mich bitte: doreen.gabriel@julius-kuehn.de"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html",
    "href": "Themen/01/01_Allgemeines.html",
    "title": "Allgemeines",
    "section": "",
    "text": "Diese Bücher sind teilweise etwas älter (was die R-Codes anbetrifft). Sie geben aber trotzdem einen guten Einblick in die Statistik und Anwendung von R.\nCrawley 2013: The R Book. 2nd Edition, E-Book unter http://onlinelibrary.wiley.com/book/10.1002/9781118448908\nCrawley 2013: Statistik mit R.\nDormann 2013: Parametrische Statistik.\nBurnham und Anderson 2002: Model Selection and Multimodel Inference.\nJames, Witten, Hastie & Tibshirani 2023: An Introduction to Statistical Learning with Applications in R. https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf.download.html Hastie, Tibshirani & Friedman 2017: The Elements of Statistical Learning - Data Mining, Inference and Prediction https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#literatur",
    "href": "Themen/01/01_Allgemeines.html#literatur",
    "title": "Allgemeines",
    "section": "",
    "text": "Diese Bücher sind teilweise etwas älter (was die R-Codes anbetrifft). Sie geben aber trotzdem einen guten Einblick in die Statistik und Anwendung von R.\nCrawley 2013: The R Book. 2nd Edition, E-Book unter http://onlinelibrary.wiley.com/book/10.1002/9781118448908\nCrawley 2013: Statistik mit R.\nDormann 2013: Parametrische Statistik.\nBurnham und Anderson 2002: Model Selection and Multimodel Inference.\nJames, Witten, Hastie & Tibshirani 2023: An Introduction to Statistical Learning with Applications in R. https://hastie.su.domains/ISLR2/ISLRv2_corrected_June_2023.pdf.download.html Hastie, Tibshirani & Friedman 2017: The Elements of Statistical Learning - Data Mining, Inference and Prediction https://hastie.su.domains/ElemStatLearn/printings/ESLII_print12_toc.pdf"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#webseiten",
    "href": "Themen/01/01_Allgemeines.html#webseiten",
    "title": "Allgemeines",
    "section": "Webseiten",
    "text": "Webseiten\n\nKursskripte der vorangegangenen Inhouse-Schulungen sowie der zentralen Biometriekurse des BMEL findet ihr im Intranet unter Forschung Biometrie\nviele Tutorien im Netz und auf YouTube\nR Cookbook https://rc2e.com/\nDSFAIR von Paul Schmidt https://schmidtpaul.github.io/dsfair_quarto/\nMailing lists und archives auf http://www.r-project.org/\nhttp://de.wikibooks.org/wiki/GNU_R"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#hilfe-in-r",
    "href": "Themen/01/01_Allgemeines.html#hilfe-in-r",
    "title": "Allgemeines",
    "section": "Hilfe in R",
    "text": "Hilfe in R\n\nhelp.start()\nHilfeseite öffnet sich durch ?Funktion z.B. ?mean\nVergleiche ?mean vs. ??mean"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#pakete-installieren-und-laden",
    "href": "Themen/01/01_Allgemeines.html#pakete-installieren-und-laden",
    "title": "Allgemeines",
    "section": "Pakete installieren und laden",
    "text": "Pakete installieren und laden\n\nentweder im Editor install.packages(\"Paketname\") z.B. install.packages(\"nlme\")\noder über das Fenster Packages/Install und dann Name des Package z.B. nlme eintragen und Install klicken\nLaden der Pakete einmal pro Session durch die Funktion library(\"Paketname\") z.B. library(\"nlme\")"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#grundlagen-programmiersprache-r",
    "href": "Themen/01/01_Allgemeines.html#grundlagen-programmiersprache-r",
    "title": "Allgemeines",
    "section": "Grundlagen Programmiersprache R",
    "text": "Grundlagen Programmiersprache R\n\nR unterscheidet zwischen Groß- und Kleinschreibung\nLeerzeichen werden normalerweise ignoriert, d.h. kein Unterschied 2+5 vs. 2 + 5\nKommentare werden mit # markiert und dadurch nicht als Befehl von R erkannt, sondern als Text\nZeilenumbruch bei langen Befehlen ist kein Problem (ein + erscheint in der nächsten Zeile)\nNormale Rechenoperationen + - * /\nAchtung ein : bedeutet nicht “geteilt durch”! Probier es aus 10:5\nlog(), log10(), exp(), sqrt(), 2^2, 2^0.5"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#r-ist-objektorientiert",
    "href": "Themen/01/01_Allgemeines.html#r-ist-objektorientiert",
    "title": "Allgemeines",
    "section": "R ist objektorientiert",
    "text": "R ist objektorientiert\n\na &lt;- 5\n\nDie 5 wird dem Objekt a zugewiesen\n\nb &lt;- 3\n\nDie 3 wird dem Objekt b zugewiesen\n\nc &lt;- a + b\n\nc ist die Summe aus a und b.\n\nc\n\n[1] 8"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#datentypen",
    "href": "Themen/01/01_Allgemeines.html#datentypen",
    "title": "Allgemeines",
    "section": "Datentypen",
    "text": "Datentypen\nObjekte können verschieden Datentypen zugehören.\n\nNumeric (Zahl)\nCharacter (Zeichenketten, z.B. “Messeweg”)\nLogical (TRUE, FALSE)\nFactor (Kategoriale Daten mit verschiedenen Levels, z.B. hoch, mittel, niedrig oder rot, blau, gelb)"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#datenstrukturen",
    "href": "Themen/01/01_Allgemeines.html#datenstrukturen",
    "title": "Allgemeines",
    "section": "Datenstrukturen",
    "text": "Datenstrukturen\n\nvector (eindimensionale Vektoren)\nmatrix (zweidimensionale Matrizen)\narray (verallgemeinerte Matrizen mit auch mehr als zwei Dimensionen)\nlist (Listen)\ndata.frame (Datensätze i.e. Tabelle mit unterschiedlichen Datentypen je Spalte)\nfunction (Funktionen)"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#funktionen",
    "href": "Themen/01/01_Allgemeines.html#funktionen",
    "title": "Allgemeines",
    "section": "Funktionen",
    "text": "Funktionen\nBeim Aufruf von Funktionen sind die Werte, die der Funktion als Berechnungsgrundlage dienen, in runde Klammern einzuschließen: z.B.\n\nround(1.358) # runden einer Zahl\n\n[1] 1\n\n\nDie Argumentliste besteht aus Zuweisungen an Argumenten in der Form Argumentname=Wert, die der Funktion die notwendigen Eingangsinformationen liefern.\n\nround(1.358, digits=1)\n\n[1] 1.4\n\nround(1.358, 1)# nur eine Kommastelle\n\n[1] 1.4\n\n\nEs können je nach Funktion ein oder mehrere durch Komma getrennte Argumente angegeben werden, die ihrerseits obligatorisch oder nur optional sein können. Funktionen können ineinander verschachtelt werden z.B.\n\nround(mean(c(3,6,2,8)), digits=1)\n\n[1] 4.8\n\n\nAuf eine Kommastelle gerundeter Mittelwert aus den Zahlen 3, 6, 2 und 8.\nDie Hilfeseite für eine Funktion öffnet sich durch ?round.\n\nBeispiel Funktion seq und rep\n\nseq(from = 2, to = 8, by = 2)\n\n[1] 2 4 6 8\n\nseq(from = 2, to = 8, by= 0.5)\n\n [1] 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0 6.5 7.0 7.5 8.0\n\nseq(from = 0, to = 9, length = 4)\n\n[1] 0 3 6 9\n\nrep(1:5, times = 2)\n\n [1] 1 2 3 4 5 1 2 3 4 5\n\nrep(1:5, each = 2)\n\n [1] 1 1 2 2 3 3 4 4 5 5\n\nrep(c(\"A\",\"B\"), times = 2)\n\n[1] \"A\" \"B\" \"A\" \"B\""
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#daten-einlesen",
    "href": "Themen/01/01_Allgemeines.html#daten-einlesen",
    "title": "Allgemeines",
    "section": "Daten einlesen",
    "text": "Daten einlesen\n\nSpaltenbenennung (Variablen) ohne Leerzeichen, keine Zahlen am Anfang, kein + - / % besser _\nkurze, prägnante Variablennamen (Stickstoffduengermenge besser ND), Objektnamen (z.B. für den data.frame Stickstoffversuchsdaten besser ndat) und Pfadnamen (ohne ä, ö & ü)\nMissing Values in Excel leer lassen oder als NA in csv\n\n\nDaten direkt aus Excel einlesen\nDiesen Datensatz potato.xlsx können wir direkt mit der library(openxlsx) aus Excel einlesen.\n\n\nlibrary(openxlsx)\nmd&lt;-read.xlsx(\"potato.xlsx\", sheet=1)\nstr(md)\n\n'data.frame':   478 obs. of  7 variables:\n $ variety  : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method   : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n $ humidity : num  26.1 30.2 52.5 34 49.6 ...\n\n# oder\nmd&lt;-read.xlsx(\"potato.xlsx\", sheet=\"Tabelle1\")\n\nSolltet ihr mit RMarkdown arbeiten, dann werden die Daten (ohne Pfadangabe) aus dem Ordner in dem auch das .Rmd gespeichert ist eingelesen.\n\nalternativ könnt ihr den Pfad angeben:\n\n\n# entweder\nmd&lt;-read.xlsx(\"D:/R/Kartoffelversuch/potato.xlsx\", sheet=1)\n# oder\nmd&lt;-read.xlsx(\"D:\\\\R\\\\Kartoffelversuch\\\\potato.xlsx\", sheet=1)\n\noder\n\nihr setzt das working directory\n\nund lest dann die Daten ohne Angabe des Pfades ein\n\n\nsetwd(\"D:/R/Kartoffelversuch\") \nmd&lt;-read.xlsx(\"potato.xlsx\", sheet=1)\n\nÜber das Argument startRow können Zeilen übersprungen werden. Wenn bspw. die erste Zeile die ausführliche Beschreibung der Spalteninformation enthält und erst in der zweiten Zeile die kurzen prägnanten Variablennamen stehen, dann kann mit startRow=2 der Datensatz ab Zeile 2 eingelesen werden.\n\n\nmd&lt;-read.xlsx(\"potato_Zeile_2.xlsx\", sheet=1, startRow=2)\nstr(md)\n\n'data.frame':   478 obs. of  6 variables:\n $ variety  : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method   : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n\n\nMissing values in Excel leer lassen. R zeigt diese missing values als NA an. \n\nmd2&lt;-read.xlsx(\"potato_NA.xlsx\", sheet=1)\nhead(md2)# zeigt die ersten 6 Zeilen an\n\n  variety method plant tubers weight infection\n1   Unica    pot     1      9  209.9         0\n2   Unica    pot     2      3  248.4         0\n3   Unica    pot     3      4     NA         0\n4   Unica    pot     4      4   77.2         0\n5   Unica    pot     5      2   11.3         1\n6   Unica    pot     6      2   17.8         0\n\n\n\n\nals .csv\n\nin Excel ein Tabellenblatt als .csv oder .txt speichern\nfunktion read.table für .txt oder read.csv für .csv mit den Argumenten:\n\nheader=TRUE bedeutet, dass in der ersten Zeile die Variablenbezeichnungen stehen\nsep ist der Separator, kann Komma, Semikolon oder Tab sein\ndec ist das Dezimalzeichen, kann Komma oder Punkt sein\nread.csv() für englische Excel-Einstellungen\nread.csv2() für deutsche Excel-Einstellungen.\n\n\n\nmd&lt;-read.csv2(\"potato.csv\", header=TRUE)\n# wenn csv unter englischen Excel-Einstellungen gespeichert wurde\nmd&lt;- read.csv(\"potato.csv\", header = TRUE, sep = \",\", dec = \".\")  \n# wenn csv unter deutschen Excel-Einstellungen gespeichert wurde\nmd&lt;- read.csv2(\"potato.csv\", header = TRUE, sep = \";\", dec = \",\") \n\n\n\nals .txt\n\nmd&lt;- read.table(\"potato.txt\", header = TRUE, sep = \"\", dec = \".\")\n\n\n\nDateneinlesen in R-Studio per Klick\nEine weitere Alternative bietet R-Studio auf Environment/Import Dataset. Hier kann man sich durchklicken, um Daten zu importieren. Man sollte aber unbedingt den R-Code nach erfolgtem Import ins Skript kopieren, damit man ihn in der nächsten Sitzung ausführen kann. So behält man den Überblick, welche Daten zur Analyse genutzt wurden. Außerdem können nur so auch Dritte den Import der Daten nachvollziehen. Stichwort reproducible research.\nDer Datenimport aus anderen Statistikprogrammen (SPSS, Stata, SAS) ist mit dem Package foreign oder aus Datenbanken mit dem Package RODBC möglich."
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#datenstruktur-prüfen",
    "href": "Themen/01/01_Allgemeines.html#datenstruktur-prüfen",
    "title": "Allgemeines",
    "section": "Datenstruktur prüfen",
    "text": "Datenstruktur prüfen\nNach erfolgtem Import sollte immer die Struktur der Daten durch die Funktion str() z.B. str(md) überprüft werden.\n\nstr(md)\n\n'data.frame':   478 obs. of  6 variables:\n $ variety  : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method   : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant    : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers   : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight   : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection: num  0 0 0 0 1 0 0 0 0 0 ...\n\n\nWir sehen hier, dass die Sorte und Methode als Character eingelesen wurde und alle anderen Spalten numerisch sind. Schaut bitte zum Kapitel [Beispieldatensatz potato.xlsx], wie Character in Faktoren umgewandelt werden.\nMit den Funktionen head()und tail() lässt man sich die ersten und letzten 6 Zeilen des Datensatzes anzeigen.\n\nhead(md)\n\n  variety method plant tubers weight infection\n1   Unica    pot     1      9  209.9         0\n2   Unica    pot     2      3  248.4         0\n3   Unica    pot     3      4   53.6         0\n4   Unica    pot     4      4   77.2         0\n5   Unica    pot     5      2   11.3         1\n6   Unica    pot     6      2   17.8         0\n\ntail(md)\n\n      variety    method plant tubers weight infection\n473 Costanera aeroponic     5      7   22.7         0\n474 Costanera aeroponic     6      5   38.4         1\n475 Costanera aeroponic     7      3   28.4         0\n476 Costanera aeroponic     8      6   29.1         1\n477 Costanera aeroponic     9      4   17.6         0\n478 Costanera aeroponic    10      7   36.9         0"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#datenexport",
    "href": "Themen/01/01_Allgemeines.html#datenexport",
    "title": "Allgemeines",
    "section": "Datenexport",
    "text": "Datenexport\nWir können die Daten exportieren.\n\nmit dem Package openxlsx:\n\n\nlibrary(openxlsx)\nwrite.xlsx(md, \"potato.export2.xlsx\")\n\nDas Package openxlsx bietet die Möglichkeit, unterschiedliche Datensätze in mehreren Tabellenblättern in einer xlsx-Datei zu speichern. Hier mal exemplarisch, indem wir den potato-Datensatz mit einer summary statistics (siehe Kapitel Deskriptive Statistik) in zwei Tabellenblättern in einer Datei speichern.\n\nlibrary(dplyr)\nmd.sum=md %&gt;% group_by(variety, method) %&gt;% \n  summarise(weight_avg=mean(weight, na.rm = TRUE),\n            weight_sd=sd(weight, na.rm = TRUE))\nmd.sum\n\n# A tibble: 12 × 4\n# Groups:   variety [3]\n   variety   method     weight_avg weight_sd\n   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;\n 1 Costanera aeroponic        40.2     16.6 \n 2 Costanera bed              87.5     32.6 \n 3 Costanera hydroponic       25.1      8.17\n 4 Costanera pot             141.      22.2 \n 5 Mariva    aeroponic        95.4     54.8 \n 6 Mariva    bed              96.8     54.8 \n 7 Mariva    hydroponic       14.3      9.34\n 8 Mariva    pot              92.2     27.4 \n 9 Unica     aeroponic        88.5     70.8 \n10 Unica     bed              69.1     36.4 \n11 Unica     hydroponic       26.3     14.1 \n12 Unica     pot              94.6     60.3 \n\n\n\nwb &lt;- createWorkbook()\naddWorksheet(wb, sheetName = \"Kartoffeldaten\")\nwriteData(wb, \"Kartoffeldaten\", md) \naddWorksheet(wb, sheetName = \"summary statistics\")\nwriteData(wb, \"summary statistics\", md.sum) \nsaveWorkbook(wb, file = \"potato.export3.xlsx\", overwrite = TRUE)"
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#datenformat",
    "href": "Themen/01/01_Allgemeines.html#datenformat",
    "title": "Allgemeines",
    "section": "Datenformat",
    "text": "Datenformat\nDas flat format ist gegenüber dem wide format zu bevorzugen.\nBsp. flat format\n\n\n\nBehandl\nErtrag\n\n\n\n\nN0\n3.5\n\n\nN0\n1.5\n\n\nN0\n2.8\n\n\nN0\n3.1\n\n\nN100\n6.4\n\n\nN100\n7.4\n\n\nN100\n5.8\n\n\nN100\n5.4\n\n\nN200\n5.9\n\n\nN200\n8.4\n\n\nN200\n7.7\n\n\nN200\n6.7\n\n\n\nBsp. wide format\n\n\n\nKontrolle\nN-Level 100\nN-Level 200\n\n\n\n\n3.5\n6.4\n5.9\n\n\n1.5\n7.4\n8.4\n\n\n2.8\n5.8\n7.7\n\n\n3.1\n5.4\n6.7\n\n\n\nR kann vom wide zum flat format (und zurück) konvertieren, z.B. mit der Funktion melt aus der library(reshape2). Siehe auch http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/."
  },
  {
    "objectID": "Themen/01/01_Allgemeines.html#übung-1",
    "href": "Themen/01/01_Allgemeines.html#übung-1",
    "title": "Allgemeines",
    "section": "Übung 1",
    "text": "Übung 1\nDie Körpergröße, Schuhgröße, Geschlecht und Augenfarbe von Kursteilnehmer wurde ermittelt. Importiere bitte die Daten Kursteilnehmer.xlsx in R und benenne den data.frame mit md.\n\n\n\n\n\n\nDaten einlesen und prüfen\n\n\n\n\n\nDer Datensatz hat in der ersten Zeile eine detaillierte und in der zweiter Zeile die kurze Variablenbezeichnung. Daher lese ich die Daten mit dem Argument startRow = 2 erst ab der zweiten Zeile ein.\n\nlibrary(openxlsx)\nmd&lt;-read.xlsx(\"Kursteilnehmer.xlsx\", sheet=1, startRow = 2)\nstr(md)\n\n'data.frame':   72 obs. of  5 variables:\n $ Name: chr  \"Colton\" \"Kyle\" \"Brandon\" \"Cory\" ...\n $ KG  : num  181 183 186 184 172 186 183 197 180 184 ...\n $ SG  : num  42 44 42 45 43 43 42 45 43 43 ...\n $ AF  : chr  \"braun\" \"braun\" \"braun\" \"blau\" ...\n $ G   : chr  \"m\" \"m\" \"m\" \"m\" ...\n\n\n\n\n\nLerne die Daten und folgende Funktionen kennen:\n\nstr(md)\nnames(md)\nhead(md)\ntail(md)\nmd[,]\nmd[1,]\nmd[,3]\nmd[,-3]\nmd[1:3,]\nmd[,1:3]\n\nmd[2,2:4]\nmd[,c(2,4)]\n\n\n\n\n\n\n\nFunktionen\n\n\n\n\n\n\nstr(md) \n\n'data.frame':   72 obs. of  5 variables:\n $ Name: chr  \"Colton\" \"Kyle\" \"Brandon\" \"Cory\" ...\n $ KG  : num  181 183 186 184 172 186 183 197 180 184 ...\n $ SG  : num  42 44 42 45 43 43 42 45 43 43 ...\n $ AF  : chr  \"braun\" \"braun\" \"braun\" \"blau\" ...\n $ G   : chr  \"m\" \"m\" \"m\" \"m\" ...\n\nnames(md)\n\n[1] \"Name\" \"KG\"   \"SG\"   \"AF\"   \"G\"   \n\nhead(md)\n\n     Name  KG SG    AF G\n1  Colton 181 42 braun m\n2    Kyle 183 44 braun m\n3 Brandon 186 42 braun m\n4    Cory 184 45  blau m\n5   Heath 172 43  blau m\n6   Jesse 186 43  blau m\n\ntail(md)\n\n       Name  KG SG    AF G\n67  Felicia 172 40 braun w\n68  Carissa 170 40  blau w\n69 Danielle 164 37 gruen w\n70 Kaytlynn 186 42 braun w\n71   Lauren 168 40 braun w\n72   Jenine 168 37 braun w\n\nmd[,]\n\n            Name  KG SG    AF G\n1         Colton 181 42 braun m\n2           Kyle 183 44 braun m\n3        Brandon 186 42 braun m\n4           Cory 184 45  blau m\n5          Heath 172 43  blau m\n6          Jesse 186 43  blau m\n7         Daniel 183 42 braun m\n8         Bradin 197 45 braun m\n9          David 180 43  blau m\n10          Kyle 184 43 braun m\n11       Brandon 189 48  blau m\n12          Luke 177 44  blau m\n13       Cameron 181 43 braun m\n14        Justin 160 38 gruen m\n15 Jackson Payne 176 42 braun m\n16          Cole 180 43  blau m\n17         Riley 184 44 gruen m\n18         Lance 173 40  blau m\n19         Nakai 178 43 braun m\n20       Garrett 182 43 braun m\n21       Braxton 180 44  blau m\n22          Noah 200 45  blau m\n23        Brolon 178 44 braun m\n24          Mark 183 43  blau m\n25        George 178 44  blau m\n26        Camron 183 44  blau m\n27        Bryson 180 41 braun m\n28      Benjamin 192 43  blau m\n29          Drew 178 41  blau m\n30         Brian 163 42 gruen m\n31          Kyle 173 42  blau m\n32         Jacob 178 42 gruen m\n33         Paige 177 40 braun w\n34       Allison 170 41 gruen w\n35       Janelle 167 39  blau w\n36        Ashlie 163 39 braun w\n37       Kathryn 170 37  blau w\n38        Jordan 150 36  blau w\n39         Kiana 152 35  blau w\n40     Kimberlyn 164 40  blau w\n41         Sydne 165 38 braun w\n42       Jessica 170 38 braun w\n43        Morgan 173 41 gruen w\n44         Janie 167 39  blau w\n45        Soraya 170 39 gruen w\n46         Grace 168 39 braun w\n47      Danielle 167 39 braun w\n48     Elizabeth 163 37 braun w\n49       Kaitlyn 172 38 gruen w\n50      Bethanie 167 39 braun w\n51        Kelsey 164 38  blau w\n52         Dixie 170 39 braun w\n53      Brynelle 165 37 gruen w\n54       Andreah 162 38 braun w\n55      Ashleigh 170 40 braun w\n56       Kellcie 180 39  blau w\n57        Maggie 168 38  blau w\n58       Cassidy 157 38  blau w\n59       Mallory 160 38 gruen w\n60       Lindsay 168 38 braun w\n61          Erin 162 39 braun w\n62          Erin 160 38 gruen w\n63         Hanna 172 41 braun w\n64         Traci 175 41 braun w\n65        Hannah 176 39 braun w\n66    Mattielien 154 38  blau w\n67       Felicia 172 40 braun w\n68       Carissa 170 40  blau w\n69      Danielle 164 37 gruen w\n70      Kaytlynn 186 42 braun w\n71        Lauren 168 40 braun w\n72        Jenine 168 37 braun w\n\nmd[,3]\n\n [1] 42 44 42 45 43 43 42 45 43 43 48 44 43 38 42 43 44 40 43 43 44 45 44 43 44\n[26] 44 41 43 41 42 42 42 40 41 39 39 37 36 35 40 38 38 41 39 39 39 39 37 38 39\n[51] 38 39 37 38 40 39 38 38 38 38 39 38 41 41 39 38 40 40 37 42 40 37\n\nmd[1,]\n\n    Name  KG SG    AF G\n1 Colton 181 42 braun m\n\nmd[,-3]\n\n            Name  KG    AF G\n1         Colton 181 braun m\n2           Kyle 183 braun m\n3        Brandon 186 braun m\n4           Cory 184  blau m\n5          Heath 172  blau m\n6          Jesse 186  blau m\n7         Daniel 183 braun m\n8         Bradin 197 braun m\n9          David 180  blau m\n10          Kyle 184 braun m\n11       Brandon 189  blau m\n12          Luke 177  blau m\n13       Cameron 181 braun m\n14        Justin 160 gruen m\n15 Jackson Payne 176 braun m\n16          Cole 180  blau m\n17         Riley 184 gruen m\n18         Lance 173  blau m\n19         Nakai 178 braun m\n20       Garrett 182 braun m\n21       Braxton 180  blau m\n22          Noah 200  blau m\n23        Brolon 178 braun m\n24          Mark 183  blau m\n25        George 178  blau m\n26        Camron 183  blau m\n27        Bryson 180 braun m\n28      Benjamin 192  blau m\n29          Drew 178  blau m\n30         Brian 163 gruen m\n31          Kyle 173  blau m\n32         Jacob 178 gruen m\n33         Paige 177 braun w\n34       Allison 170 gruen w\n35       Janelle 167  blau w\n36        Ashlie 163 braun w\n37       Kathryn 170  blau w\n38        Jordan 150  blau w\n39         Kiana 152  blau w\n40     Kimberlyn 164  blau w\n41         Sydne 165 braun w\n42       Jessica 170 braun w\n43        Morgan 173 gruen w\n44         Janie 167  blau w\n45        Soraya 170 gruen w\n46         Grace 168 braun w\n47      Danielle 167 braun w\n48     Elizabeth 163 braun w\n49       Kaitlyn 172 gruen w\n50      Bethanie 167 braun w\n51        Kelsey 164  blau w\n52         Dixie 170 braun w\n53      Brynelle 165 gruen w\n54       Andreah 162 braun w\n55      Ashleigh 170 braun w\n56       Kellcie 180  blau w\n57        Maggie 168  blau w\n58       Cassidy 157  blau w\n59       Mallory 160 gruen w\n60       Lindsay 168 braun w\n61          Erin 162 braun w\n62          Erin 160 gruen w\n63         Hanna 172 braun w\n64         Traci 175 braun w\n65        Hannah 176 braun w\n66    Mattielien 154  blau w\n67       Felicia 172 braun w\n68       Carissa 170  blau w\n69      Danielle 164 gruen w\n70      Kaytlynn 186 braun w\n71        Lauren 168 braun w\n72        Jenine 168 braun w\n\nmd[1:3,]\n\n     Name  KG SG    AF G\n1  Colton 181 42 braun m\n2    Kyle 183 44 braun m\n3 Brandon 186 42 braun m\n\nmd[,1:3]\n\n            Name  KG SG\n1         Colton 181 42\n2           Kyle 183 44\n3        Brandon 186 42\n4           Cory 184 45\n5          Heath 172 43\n6          Jesse 186 43\n7         Daniel 183 42\n8         Bradin 197 45\n9          David 180 43\n10          Kyle 184 43\n11       Brandon 189 48\n12          Luke 177 44\n13       Cameron 181 43\n14        Justin 160 38\n15 Jackson Payne 176 42\n16          Cole 180 43\n17         Riley 184 44\n18         Lance 173 40\n19         Nakai 178 43\n20       Garrett 182 43\n21       Braxton 180 44\n22          Noah 200 45\n23        Brolon 178 44\n24          Mark 183 43\n25        George 178 44\n26        Camron 183 44\n27        Bryson 180 41\n28      Benjamin 192 43\n29          Drew 178 41\n30         Brian 163 42\n31          Kyle 173 42\n32         Jacob 178 42\n33         Paige 177 40\n34       Allison 170 41\n35       Janelle 167 39\n36        Ashlie 163 39\n37       Kathryn 170 37\n38        Jordan 150 36\n39         Kiana 152 35\n40     Kimberlyn 164 40\n41         Sydne 165 38\n42       Jessica 170 38\n43        Morgan 173 41\n44         Janie 167 39\n45        Soraya 170 39\n46         Grace 168 39\n47      Danielle 167 39\n48     Elizabeth 163 37\n49       Kaitlyn 172 38\n50      Bethanie 167 39\n51        Kelsey 164 38\n52         Dixie 170 39\n53      Brynelle 165 37\n54       Andreah 162 38\n55      Ashleigh 170 40\n56       Kellcie 180 39\n57        Maggie 168 38\n58       Cassidy 157 38\n59       Mallory 160 38\n60       Lindsay 168 38\n61          Erin 162 39\n62          Erin 160 38\n63         Hanna 172 41\n64         Traci 175 41\n65        Hannah 176 39\n66    Mattielien 154 38\n67       Felicia 172 40\n68       Carissa 170 40\n69      Danielle 164 37\n70      Kaytlynn 186 42\n71        Lauren 168 40\n72        Jenine 168 37\n\nmd[2,2:4]\n\n   KG SG    AF\n2 183 44 braun\n\nmd[,c(2,4)]\n\n    KG    AF\n1  181 braun\n2  183 braun\n3  186 braun\n4  184  blau\n5  172  blau\n6  186  blau\n7  183 braun\n8  197 braun\n9  180  blau\n10 184 braun\n11 189  blau\n12 177  blau\n13 181 braun\n14 160 gruen\n15 176 braun\n16 180  blau\n17 184 gruen\n18 173  blau\n19 178 braun\n20 182 braun\n21 180  blau\n22 200  blau\n23 178 braun\n24 183  blau\n25 178  blau\n26 183  blau\n27 180 braun\n28 192  blau\n29 178  blau\n30 163 gruen\n31 173  blau\n32 178 gruen\n33 177 braun\n34 170 gruen\n35 167  blau\n36 163 braun\n37 170  blau\n38 150  blau\n39 152  blau\n40 164  blau\n41 165 braun\n42 170 braun\n43 173 gruen\n44 167  blau\n45 170 gruen\n46 168 braun\n47 167 braun\n48 163 braun\n49 172 gruen\n50 167 braun\n51 164  blau\n52 170 braun\n53 165 gruen\n54 162 braun\n55 170 braun\n56 180  blau\n57 168  blau\n58 157  blau\n59 160 gruen\n60 168 braun\n61 162 braun\n62 160 gruen\n63 172 braun\n64 175 braun\n65 176 braun\n66 154  blau\n67 172 braun\n68 170  blau\n69 164 gruen\n70 186 braun\n71 168 braun\n72 168 braun\n\n\n\n\n\nEnde Übung 1"
  },
  {
    "objectID": "Themen/03/03_Graph.html",
    "href": "Themen/03/03_Graph.html",
    "title": "Grafische Darstellungen",
    "section": "",
    "text": "Bevor Daten statistisch analysiert werden, sollten sie grafisch dargestellt werden, um mögliche Fehler, Ausreißer oder Muster zu erkennen. Darüber hinaus ist die grafische Darstellung der Daten für die Präsentation und Interpretation statistischer Modelle unerlässlich. Wir nutzen hierfür den Datensatz potato.xlsx, wie schon in der vorherigen Kapiteln. Ich füge zusätzlich für die als character eingelesenen Spalten, Variablen als Faktoren ein (variety.f, method.f, infection.f) und ändere für variety.f2 die Reihenfolge der Faktorlevels, i.e. Unica ist nun das erste Level.\nlibrary(openxlsx)\nlibrary(dplyr)\npot&lt;-read.xlsx(\"potato.xlsx\", sheet=1)\npot=pot %&gt;% \n    mutate(variety.f=as.factor(variety),\n           method.f=as.factor(method),\n           infection.f=as.factor(infection),\n           variety.f2=factor(variety, levels=c(\"Unica\" , \"Costanera\", \"Mariva\")))\nstr(pot)\n\n'data.frame':   478 obs. of  11 variables:\n $ variety    : chr  \"Unica\" \"Unica\" \"Unica\" \"Unica\" ...\n $ method     : chr  \"pot\" \"pot\" \"pot\" \"pot\" ...\n $ plant      : num  1 2 3 4 5 6 7 8 9 10 ...\n $ tubers     : num  9 3 4 4 2 2 3 6 9 6 ...\n $ weight     : num  209.9 248.4 53.6 77.2 11.3 ...\n $ infection  : num  0 0 0 0 1 0 0 0 0 0 ...\n $ humidity   : num  26.1 30.2 52.5 34 49.6 ...\n $ variety.f  : Factor w/ 3 levels \"Costanera\",\"Mariva\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ method.f   : Factor w/ 4 levels \"aeroponic\",\"bed\",..: 4 4 4 4 4 4 4 4 4 4 ...\n $ infection.f: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 1 1 1 1 1 ...\n $ variety.f2 : Factor w/ 3 levels \"Unica\",\"Costanera\",..: 1 1 1 1 1 1 1 1 1 1 ..."
  },
  {
    "objectID": "Themen/03/03_Graph.html#achsenbeschriftung-labs",
    "href": "Themen/03/03_Graph.html#achsenbeschriftung-labs",
    "title": "Grafische Darstellungen",
    "section": "Achsenbeschriftung labs()",
    "text": "Achsenbeschriftung labs()\nMit der Funktion + labs(title=\" \", x=\" \", y=\" \") werden in die ” ” die Beschriftungen eingefügt.\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  labs(x=\"Gewicht in g\", y=\"Anzahl Kartoffelknollen\")"
  },
  {
    "objectID": "Themen/03/03_Graph.html#achsenlimitierung-coord_cartesian",
    "href": "Themen/03/03_Graph.html#achsenlimitierung-coord_cartesian",
    "title": "Grafische Darstellungen",
    "section": "Achsenlimitierung coord_cartesian()",
    "text": "Achsenlimitierung coord_cartesian()\nMit der Funktion coord_cartesian(xlim=c(,), ylim=c(,)) ändert man das Minimum und Maximum der x- und y-Achse.\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  coord_cartesian(ylim=c(0,15), xlim = c(0,350))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#alle-layer-über-verbinden",
    "href": "Themen/03/03_Graph.html#alle-layer-über-verbinden",
    "title": "Grafische Darstellungen",
    "section": "alle Layer über + verbinden",
    "text": "alle Layer über + verbinden\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  labs(x=\"Gewicht in g\", y=\"Anzahl Kartoffelknollen pro Pflanze\")+\n  coord_cartesian(ylim=c(0,15), xlim = c(0,350))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#plotsymbol-shape",
    "href": "Themen/03/03_Graph.html#plotsymbol-shape",
    "title": "Grafische Darstellungen",
    "section": "Plotsymbol shape",
    "text": "Plotsymbol shape\nDurch das Argument shape= in der Funktion geom_point() können die Plotsymbole geändert werden. Folgende Symbole werden durch die Zahlen 0 bis 24 abgebildet.\n\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point(shape=1)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#plotsymbol-entsprechend-variety",
    "href": "Themen/03/03_Graph.html#plotsymbol-entsprechend-variety",
    "title": "Grafische Darstellungen",
    "section": "Plotsymbol entsprechend variety",
    "text": "Plotsymbol entsprechend variety\n\nggplot(data=pot, aes(x=weight, y=tubers, shape=variety)) +\n  geom_point()"
  },
  {
    "objectID": "Themen/03/03_Graph.html#plotsymbole-manuel-festlegen",
    "href": "Themen/03/03_Graph.html#plotsymbole-manuel-festlegen",
    "title": "Grafische Darstellungen",
    "section": "Plotsymbole manuel festlegen",
    "text": "Plotsymbole manuel festlegen\nMit scale_shape_manual(values=c(1,2,3)) kann man manuell die Plotsymbole verändern, wobei die Werte 1, 2 und 3 dann für die 3 Sorten stehen. Hier kann man ganze Zahlen von 0 bis 24 wählen (siehe Abbildung zu den Plotsymbolen weiter oben). Wichtig ist nur, dass die Anzahl der Zahlen mit der Anzahl der unterschiedlichen Sorten übereinstimmt.\n\nggplot(data=pot, aes(x=weight, y=tubers, shape=variety)) +\n  geom_point()+\n  scale_shape_manual(values=c(1,2,3))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#größe-des-plotsymbols-size",
    "href": "Themen/03/03_Graph.html#größe-des-plotsymbols-size",
    "title": "Grafische Darstellungen",
    "section": "Größe des Plotsymbols size",
    "text": "Größe des Plotsymbols size\nsize=3 je höher die Zahl, desto größer die Symbole\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point(shape=2, size=3)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#farbe-des-plotsymbols-col",
    "href": "Themen/03/03_Graph.html#farbe-des-plotsymbols-col",
    "title": "Grafische Darstellungen",
    "section": "Farbe des Plotsymbols col",
    "text": "Farbe des Plotsymbols col\n\n\n\n\n\n\n\n\n\nMit col=3 werden die Symbole grün dargestellt. Farben kann man durch die Zahlen 1 bis 7 wählen oder benennen z.B. “green”, “darkgreen”, “red”. Alle möglichen Farben findet ihr mit der Funktion colors()oder auf http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf\n\nlibrary(scales)\nshow_col(colors()[1:100], ncol=10)\n\n\n\n\n\n\n\nshow_col(colors()[152:253], ncol=10)\n\n\n\n\n\n\n\nshow_col(pal_hue()(49))\n\n\n\n\n\n\n\nshow_col(pal_viridis()(49))\n\n\n\n\n\n\n\nshow_col(topo.colors(49))\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point(shape=20, size=3, col=\"#287C8EFF\")\n\n\n\n\n\n\n\n\nAuch RGB-Farben können gewählt werden. Hier ein Beispiel für das JKI blau:\n\nR: 35\nG: 80\nB: 150\n\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point(shape=20, size=3, col=rgb(35,80,150, max = 255))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#die-farbe-des-plotsymbols-ensprechend-der-faktorausprägung-variety",
    "href": "Themen/03/03_Graph.html#die-farbe-des-plotsymbols-ensprechend-der-faktorausprägung-variety",
    "title": "Grafische Darstellungen",
    "section": "Die Farbe des Plotsymbols ensprechend der Faktorausprägung variety",
    "text": "Die Farbe des Plotsymbols ensprechend der Faktorausprägung variety\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  scale_color_manual(values=c(\"royalblue\", \"orange\", \"olivedrab\"))\n\n\n\n\n\n\n\n\nDie Sorten entsprechend JKI-Farbwelt.\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  scale_color_manual(values=c(rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255), \n                              rgb(240,215,35, max = 255)))\n\n\n\n\n\n\n\n\nWenn keine Zuordnung der Werte zu den Farben erfolgt, dann werden die Farben entsprechend der Reihenfolge der Faktorlevels abgebildet (alphanumerisch).\nHier ein Beispiel mit Zuordnung.\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  scale_color_manual(values=c(\"Mariva\"=rgb(190,210,35, max = 255), \n                              \"Unica\"=rgb(35,80,150, max = 255), \n                              \"Costanera\"=rgb(240,215,35, max = 255)))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#ein-plot-für-jede-sorte-facet_grid-und-facet_wrap",
    "href": "Themen/03/03_Graph.html#ein-plot-für-jede-sorte-facet_grid-und-facet_wrap",
    "title": "Grafische Darstellungen",
    "section": "ein Plot für jede Sorte facet_grid() und facet_wrap()",
    "text": "ein Plot für jede Sorte facet_grid() und facet_wrap()\nMit der Funktion + facet_grid(~ variety) oder + facet_wrap(~ variety) wird ein separater Plot für jedes Gruppierungslevel der variety erzeugt.\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  facet_grid(~variety)\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  facet_wrap(~variety)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#ein-plot-für-jede-sorte-und-mit-und-ohne-befall-infection",
    "href": "Themen/03/03_Graph.html#ein-plot-für-jede-sorte-und-mit-und-ohne-befall-infection",
    "title": "Grafische Darstellungen",
    "section": "Ein Plot für jede Sorte und mit und ohne Befall (Infection)",
    "text": "Ein Plot für jede Sorte und mit und ohne Befall (Infection)\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  facet_grid(infection~variety)\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  facet_wrap(infection~variety, labeller = labeller(.multi_line = FALSE))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#regressionslinien-einzeichnen",
    "href": "Themen/03/03_Graph.html#regressionslinien-einzeichnen",
    "title": "Grafische Darstellungen",
    "section": "Regressionslinien einzeichnen",
    "text": "Regressionslinien einzeichnen\nIm Folgenden sehen wir Beispiele für unterschiedliche Modellfits. Diese dienen nur der Veranschaulichung und ersetzen nicht die statistischen Analysen mit Modelldiagnostik.\n\nLM fit (lineare Regression)\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nLM fit ohne Konfidenzintervall\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=lm, se=FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nPolynomial zweiten Grades y= x + x²\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=lm, formula=y ~ poly(x, 2)) # formula=y ~ x+I(x^2)\n\n\n\n\n\n\n\n\n\n\nPolynomial dritten Grades y= x + x² + x³\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=lm, formula=y ~ poly(x, 3)) # formula=y ~ x+I(x^2)+I(x^3)\n\n\n\n\n\n\n\n\n\n\nGLM fit\nWer sich über Generalsierte Lineare Modelle informieren möchte, kann im Intranet unter http://intranet.julius-kuehn.de/forschungservice/biometrie das Skript Generalisierte Lineare Modelle in R finden.\n\nZähldaten: Poisson\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=glm, method.args = list(family = \"poisson\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nZähldaten: Quasipoisson\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=glm, method.args = list(family = \"quasipoisson\"))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\nZähldaten: Negativbinomial\n\nlibrary(MASS)\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  geom_smooth(method=\"glm.nb\")\n\n\n\n\n\n\n\n\n\n\nStreng positive kontinuierliche Daten: Gamma\n\npot1=pot[pot$weight&gt;0,]\nggplot(data=pot1, aes(x=tubers, y=weight)) +\n  geom_point()+\n  geom_smooth(method=\"glm\", method.args = list(family = Gamma(link = log)))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\npresence/absence: binomial\nWir plotten die Beziehung zwischen Infektion und Luftfeuchtigkeit (humidity).\nBeispiele mit unterschiedlichen Links (logit, probit und cloglog)\n\n#logit\nggplot(data=pot, aes(x=humidity, y=infection)) +\n  geom_point()+\n  geom_smooth(method=\"glm\", method.args = list(family = binomial))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#probit\nggplot(data=pot, aes(x=humidity, y=infection)) +\n  geom_point()+\n  geom_smooth(method=\"glm\", method.args = list(family = binomial(link = probit)))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#cloglog\nggplot(data=pot, aes(x=humidity, y=infection)) +\n  geom_point()+\n  geom_smooth(method=\"glm\", method.args = list(family = binomial(link = cloglog)))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\nModellfit für verschiedene Sorten\n\nggplot(data=pot, aes(x=weight, y=tubers, colour=variety)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nund hier ein Modelfit ohne Berücksichtigung der farblich unterschiedlichen Sorten\n\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point(aes(colour=variety))+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=weight, y=tubers, colour=variety)) +\n  geom_point()+\n  geom_smooth(method=lm)+\n  facet_grid(~variety)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Themen/03/03_Graph.html#mögliche-abbildung-der-daten",
    "href": "Themen/03/03_Graph.html#mögliche-abbildung-der-daten",
    "title": "Grafische Darstellungen",
    "section": "mögliche Abbildung der Daten",
    "text": "mögliche Abbildung der Daten\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  geom_smooth(method=lm)+\n  scale_color_manual(values=c(rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255), \n                              rgb(240,215,35, max = 255)))+\n  labs(x=\"Gewicht in g\", y=\"Anzahl Kartoffelknollen\")+\n  coord_cartesian(ylim=c(0,15), xlim = c(0,350))+\n  facet_grid(method~variety)+\n  theme(legend.position=\"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Themen/03/03_Graph.html#jittered-boxplot",
    "href": "Themen/03/03_Graph.html#jittered-boxplot",
    "title": "Grafische Darstellungen",
    "section": "jittered Boxplot",
    "text": "jittered Boxplot\nBei einem jittered Boxplot werden die Messwerte zusätzlich über den Boxplot geplottet. Das gibt dem Betrachter ein umfangreicheres Verständnis über die Daten. Um eine überlappung der Daten zu verhindern, wird für jeden Messwert eine kleine Zufallszahl in x-Richtung (width=0.25) gezogen. Natürlich werden die Werte nicht in der y-Richtung verändert (height=0). Um mögliche Ausreißer nicht doppelt abzubilden, muss das Argument outlier.shape=NA in der Funktion geom_boxplot() gesetzt werden.\nPallmann & Hothorn 2015: Boxplots for grouped and clustered data in toxicology. Archives of Toxicology. DOI 10.1007/s00204-015-1608-4\n\nggplot(data=pot, aes(x=method, y=weight)) +\n   stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#zusätzliche-stats",
    "href": "Themen/03/03_Graph.html#zusätzliche-stats",
    "title": "Grafische Darstellungen",
    "section": "zusätzliche Stats",
    "text": "zusätzliche Stats\n\nMittelwert\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") # Mittelwert\n\n\n\n\n\n\n\n\n\n\nbootstrapped Konfidenzintervall\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun.data = \"mean_cl_boot\", colour = \"red\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\nStichprobenumfang bzw. Anzahl Wiederholungen je Gruppe\nhttps://stackoverflow.com/questions/42822273/adding-sample-size-to-a-box-plot-at-the-min-or-max-of-the-facet-in-ggplot\n\ngive.n&lt;-function(x)\n  {\n  return(c(y = 300, label = length(x))) # y ggfls. anpassen \n  }\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\")+ # Mittelwert\n  stat_summary(fun.data = give.n, geom=\"text\", colour=\"gray10\")"
  },
  {
    "objectID": "Themen/03/03_Graph.html#weight-method-und-variety",
    "href": "Themen/03/03_Graph.html#weight-method-und-variety",
    "title": "Grafische Darstellungen",
    "section": "weight ~ method und variety",
    "text": "weight ~ method und variety\n\n# 1)\nggplot(data=pot, aes(x=method, y=weight, colour=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() \n\n\n\n\n\n\n\n# 2) \nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() \n\n\n\n\n\n\n\n\n\n# 3) \nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot() +\n  facet_grid(~variety)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#x-achsenlevels",
    "href": "Themen/03/03_Graph.html#x-achsenlevels",
    "title": "Grafische Darstellungen",
    "section": "x-Achsenlevels",
    "text": "x-Achsenlevels\nIn diesem Beispiel ist die Beschriftung der x-Achsenlevels sehr lang. Mit \\n können wir einen Zeilenumbruch erzeugen:\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot() +\n  facet_grid(~variety)+\n  scale_x_discrete(labels =c(\"aero-\\nponic\", \"bed\", \"hydro-\\nponic\", \"pot\"))\n\n\n\n\n\n\n\n\noder wir drehen die X-Achsenbeschriftungslevels um 45 Grad.\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot() +\n  facet_grid(~variety)+\n  scale_x_discrete(labels =c(\"aeronponic\", \"bed\", \"hydronponic\", \"pot\"))+\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#jittered-boxplot-für-weight-method-und-variety",
    "href": "Themen/03/03_Graph.html#jittered-boxplot-für-weight-method-und-variety",
    "title": "Grafische Darstellungen",
    "section": "jittered boxplot für weight ~ method und variety",
    "text": "jittered boxplot für weight ~ method und variety\n\nggplot(data=pot, aes(x=method, y=weight, colour=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(shape=1, size=1)\n\n\n\n\n\n\n\n\nNoch nicht ganz richtig. Die Punkte haben zwar unterschiedliche Farben, sind aber nicht den Boxen der Sorten zugeordnet.\nMit dem Argument position=position_jitterdodge() können wir das ändern:\n\nggplot(data=pot, aes(x=method, y=weight, colour=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0, \n                                            dodge.width=0.75), \n              shape=1, size=1)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#transformation-der-achsenabstände-scale_._",
    "href": "Themen/03/03_Graph.html#transformation-der-achsenabstände-scale_._",
    "title": "Grafische Darstellungen",
    "section": "Transformation der Achsenabstände scale_._()",
    "text": "Transformation der Achsenabstände scale_._()\nHäufig weisen Daten eine (Rechts-) Schiefe auf, d.h. es gibt viele kleine und wenige große Werte. Dies ist bei Zähldaten häufig der Fall, die poisson oder negative binomial verteilt sein können oder bei streng positiven diskreten Daten, wie z.B. Biomasse, die gamma-verteilt sein kann. Dabei nimmt die Varianz (die Streuung) häufig mit steigendem Mittelwert zu.\nFür die Abbildung solcher Daten eignet sich eine Wurzel- oder Log-Transformation der Achsenabstände durch die die Funktion scale_y_sqrt() und scale_y_log10().\nFür die Wurzel-Transformation müssen die Werte &gt;= 0 sein:\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_sqrt()\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=method, y=weight)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  scale_y_sqrt(limits=c(0,400))\n\n\n\n\n\n\n\n\nFür die logarithmische Skala müssen die Werte &gt; 0 sein.\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_log10()\n\nWarning in scale_y_log10(): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n\n\nWarning: Removed 8 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\nRemoved 8 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nIn diesem Datensatz sind Nullen enthalten und wir bekommen eine Warnmeldung, dass diese Werte nicht abgebildet werden. Hier hilft folgender Trick:\n\nwir addieren eine kleine Konstante y+1\nlabeln die Skala bei y+1 mit den Werten von y\nbenennen die Y-Achse name=\"weight\"\n\n\nggplot(data=pot, aes(x=method, y=weight+1))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_log10(breaks=c(0,3, 10,25, 50, 100,250, 500)+1,\n                label=c(0,3, 10, 25, 50, 100,250, 500),\n                lim=c(0,500)+1, name=\"weight\")\n\n\n\n\n\n\n\n\nAuch für die wurzeltransformierte Y-Achse können wir die Beschriftung der Achsenticks festlegen. Da wir keine Konstante addiert haben, werden die gleichen Informationen beim Argument breaks und label eingegeben:\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_sqrt(breaks=c(0,20, 50, 100, 200, 400), \n               label=c(0,20, 50, 100, 200, 400), \n               lim=c(0,400))\n\n\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_sqrt(breaks=seq(0,20, by=5)^2, \n               label=seq(0,20, by=5)^2,\n               lim=c(0,400))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#komma-statt-punkte-in-y-achse",
    "href": "Themen/03/03_Graph.html#komma-statt-punkte-in-y-achse",
    "title": "Grafische Darstellungen",
    "section": "Komma statt Punkte in Y-Achse",
    "text": "Komma statt Punkte in Y-Achse\nWenn wir Abbildungen in Deutsch verfassen, sollten die Dezimalstellen als Komma dargestellt werden.\n\nggplot(data=pot, aes(x=method, y=weight/1000))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_continuous()\n\n\n\n\n\n\n\n\nHierfür gibt es die Möglichkeit über das Argument labels und die Funktion number_format() der library(scales) das Dezimalzeichen als Kommas anzeigen zu lassen.\n\nggplot(data=pot, aes(x=method, y=weight/1000))+ \n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot()+\n  scale_y_continuous(labels=scales::number_format(accuracy = 0.01, \n                                                  decimal.mark =\",\"))+\n  ylab(\"Gewicht in kg\")+\n  xlab(\"Methode\")"
  },
  {
    "objectID": "Themen/03/03_Graph.html#facet_grid-und-facet_wrap",
    "href": "Themen/03/03_Graph.html#facet_grid-und-facet_wrap",
    "title": "Grafische Darstellungen",
    "section": "facet_grid() und facet_wrap()",
    "text": "facet_grid() und facet_wrap()\n\nReihenfolge ändern\nDie Reihenfolge der facets (oder auch der Levels im Boxplot) könnt ihr am einfachsten ändern, indem ihr die Reihenfolge der Faktorlevels definiert. Diese werden per default alphanumerisch sortiert. Ich habe nun nach dem Einlesen der Daten den Faktor variety.f2 mit dem Code variety.f2=factor(variety, levels=c(\"Unica\" , \"Costanera\", \"Mariva\")) in der Funktion mutate() eingepflegt und die Levelreihenfolge geändert. Alternativer Code ohne mutate() pot$variety.f2=factor(pot$variety, levels=c(\"Unica\" , \"Costanera\", \"Mariva\")) Weitere tolle Möglichkeiten, um Fakoren zu manipulieren, bietet die library(forcats) https://forcats.tidyverse.org/.\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  facet_grid(~variety.f2)+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\nalternativer Code mit der library(forcats) und der Funktion fct_relevel().\n\nlibrary(forcats)\npot %&gt;% \n  ggplot(aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  facet_grid(~fct_relevel(variety, \"Unica\", \"Mariva\"))+# hier neue Reihenfolge eingeben\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\n\nlabeller = label_both\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  facet_grid(~variety, labeller = label_both)+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\n\nlabeller = labeller(variety = Sorten.labs)\n\nSorten.labs &lt;- c(\"a) Costanera\", \"b) Mariva\", \"c) Unica\")\nnames(Sorten.labs) &lt;- c(\"Costanera\", \"Mariva\" ,   \"Unica\" )\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  facet_grid(~variety, labeller = labeller(variety = Sorten.labs))+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\n\n\nBeschriftung im Plot\ndabei bilden x und y die Koordinaten im Plot\n\nabc=data.frame(label=c(\"a)\", \"b)\", \"c)\"), \n               x=c(20,20,20), y=c(13,13, 13),\n               variety=c(levels(pot$variety.f)))\nabc\n\n  label  x  y   variety\n1    a) 20 13 Costanera\n2    b) 20 13    Mariva\n3    c) 20 13     Unica\n\n\ndie Beschrifftung erfolgt dann über die Funktion geom_text()\n\nggplot(data=pot, aes(x=weight, y=tubers, color=variety)) +\n  geom_point()+\n  facet_grid(~variety)+\n  geom_text(data  = abc,\n            aes(x = x, y = y, label = label), col=1)+\n  theme(legend.position=\"bottom\")"
  },
  {
    "objectID": "Themen/03/03_Graph.html#theme",
    "href": "Themen/03/03_Graph.html#theme",
    "title": "Grafische Darstellungen",
    "section": "Theme",
    "text": "Theme\nMit der Funktion `theme()´ können Gitterlinien, Beschriftungen, Legenden und vieles mehr angepasst werden. https://ggplot2.tidyverse.org/reference/theme.html\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  theme(panel.border = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank(),\n        axis.text = element_text(colour = \"red\", size = rel(1.5)),\n        legend.position=\"top\",\n        legend.title = element_text(colour=\"blue\", size=10, \n                                      face=\"bold\"))\n\n\n\n\n\n\n\n\nEs gibt eine Reihe von abgestimmten themes():\n\ntheme_bw\nwhite background - weißer Hintergrund und schwarze Gitterlinien\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\ntheme_classic\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\ntheme_pubr\n\nlibrary(ggpubr)\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  theme_pubr(base_size = 12, border = TRUE)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#farbwahl-für-fill-argument",
    "href": "Themen/03/03_Graph.html#farbwahl-für-fill-argument",
    "title": "Grafische Darstellungen",
    "section": "Farbwahl für fill-Argument",
    "text": "Farbwahl für fill-Argument\n\ngrey\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  scale_fill_grey() \n\n\n\n\n\n\n\n\n\n\nbrewer blau\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.75))+\n  geom_boxplot() +\n  scale_fill_brewer(palette=\"Blues\")\n\n\n\n\n\n\n\n\nweitere Beispiele https://ggplot2.tidyverse.org/reference/scale_brewer.html"
  },
  {
    "objectID": "Themen/03/03_Graph.html#abstand-zwischen-den-boxen",
    "href": "Themen/03/03_Graph.html#abstand-zwischen-den-boxen",
    "title": "Grafische Darstellungen",
    "section": "Abstand zwischen den Boxen",
    "text": "Abstand zwischen den Boxen\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n   stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.6))+\n  geom_boxplot(position=position_dodge(0.6))\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n   stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=0.8))+\n  geom_boxplot(position=position_dodge(0.8)) \n\n\n\n\n\n\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n   stat_boxplot(geom =\"errorbar\", width = 0.5, position = position_dodge(width=1))+\n  geom_boxplot(position=position_dodge(1))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#dotplot",
    "href": "Themen/03/03_Graph.html#dotplot",
    "title": "Grafische Darstellungen",
    "section": "Dotplot",
    "text": "Dotplot\n\nggplot(data=pot, aes(x=method, y=weight, fill=variety)) +\n  geom_dotplot(binaxis=\"y\", stackdir=\"center\", binwidth = 5)+\n  facet_grid(~variety)+\n  theme(legend.position=\"none\", \n        axis.text.x=element_text(angle = 45, hjust = 1))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#violinplot",
    "href": "Themen/03/03_Graph.html#violinplot",
    "title": "Grafische Darstellungen",
    "section": "Violinplot",
    "text": "Violinplot\nhttp://www.sthda.com/english/wiki/ggplot2-violin-plot-quick-start-guide-r-software-and-data-visualization\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  geom_violin()\n\n\n\n\n\n\n\nggplot(data=pot, aes(x=method, y=weight))+ \n  geom_violin(trim=F)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#mit-bins-und-binwidth-die-anzahl-der-balken-klassen-ändern",
    "href": "Themen/03/03_Graph.html#mit-bins-und-binwidth-die-anzahl-der-balken-klassen-ändern",
    "title": "Grafische Darstellungen",
    "section": "mit bins und binwidth die Anzahl der Balken (Klassen) ändern",
    "text": "mit bins und binwidth die Anzahl der Balken (Klassen) ändern\nWir können nun die Anzahl der Klassen mit dem Argument bins = 15 ändern, oder die Klassenbreite mit binwidth = 25 wählen.\n\nggplot(data=pot, aes(weight)) + \n  geom_histogram(bins = 15)\n\n\n\n\n\n\n\nggplot(data=pot, aes(weight)) + \n  geom_histogram(binwidth = 25)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#ein-histogramm-von-weight-für-die-sorten",
    "href": "Themen/03/03_Graph.html#ein-histogramm-von-weight-für-die-sorten",
    "title": "Grafische Darstellungen",
    "section": "ein Histogramm von weight für die Sorten",
    "text": "ein Histogramm von weight für die Sorten\nMit der Funktion + facet_wrap(~ variety) oder + facet_grid(~ variety) wird ein separater Plot (hier Histogramm) für jedes Gruppierungslevel der variety erzeugt.\n\nggplot(data=pot, aes(weight)) + \n  geom_histogram(binwidth = 25, col=1)+\n  facet_wrap(~ variety)"
  },
  {
    "objectID": "Themen/03/03_Graph.html#vier-plots-in-einer-grafik",
    "href": "Themen/03/03_Graph.html#vier-plots-in-einer-grafik",
    "title": "Grafische Darstellungen",
    "section": "Vier Plots in einer Grafik",
    "text": "Vier Plots in einer Grafik\nUm mehrere Plots in einer Grafik abzubilden, müssen die Plots zunächst einzeln in Objekten gespeichert werden (z.B. p1 bis p4), um dann mit der Funktion grid.arrange(p1,p2,p3,p4, ncol=2) der library(gridExtra) geplottet zu werden. Mit dem Argument ncol kann die Anzahl der Spalten bestimmt werden.\n\nlibrary(gridExtra)\n\n\nAttache Paket: 'gridExtra'\n\n\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    combine\n\np1=ggplot(data=pot, aes(weight, colour=method, fill=method)) + \n  geom_density(adjust=.75, alpha=.2)\n\np2=ggplot(data=pot, aes(x=method, y=weight, colour=method)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\n\np3=ggplot(data=pot, aes(tubers, colour=method, fill=method)) + \n  geom_density(adjust=.75, alpha=.2)\n\np4=ggplot(data=pot, aes(x=method, y=tubers, colour=method)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\n\ngrid.arrange(p1,p2,p3,p4, ncol=2)\n\n\n\n\n\n\n\n\nDas ist noch nicht wirklich schön. Die Legenden nehmen zu viel Platz ein. Alle Plots haben zudem die gleiche Legende. Diese Redundanz können wir entfernen, indem wir nur im ersten Plot eine Legende zeichnen und dabei diese durch das Argument theme(legend.position=c(0.8,0.7)) in den Plot zeichnen. Bei den anderen Plots unterdrücken wir durch theme(legend.position=\"none\") die Legende.\n\np1=ggplot(data=pot, aes(weight, colour=method, fill=method)) + \n  geom_density(adjust=.75, alpha=.2)+ \n  theme(legend.position=c(0.8,0.7)) #Legende innerhalb der Plotoberfläche\n\nWarning: A numeric `legend.position` argument in `theme()` was deprecated in ggplot2\n3.5.0.\nℹ Please use the `legend.position.inside` argument of `theme()` instead.\n\np2=ggplot(data=pot, aes(x=method, y=weight, colour=method)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)+ \n  theme(legend.position=\"none\") #ohne Legende\n\np3=ggplot(data=pot, aes(tubers, colour=method, fill=method)) + \n  geom_density(adjust=.75, alpha=.2)+ \n  theme(legend.position=\"none\")\n\np4=ggplot(data=pot, aes(x=method, y=tubers, colour=method)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)+ \n  theme(legend.position=\"none\")\n\ngrid.arrange(p1,p2,p3,p4, ncol=2)\n\n\n\n\n\n\n\n\nSchon besser."
  },
  {
    "objectID": "Themen/03/03_Graph.html#vier-plots-in-einer-grafik-mit-einer-legende-mit-libraryggpubr",
    "href": "Themen/03/03_Graph.html#vier-plots-in-einer-grafik-mit-einer-legende-mit-libraryggpubr",
    "title": "Grafische Darstellungen",
    "section": "Vier Plots in einer Grafik mit einer Legende mit library(ggpubr)",
    "text": "Vier Plots in einer Grafik mit einer Legende mit library(ggpubr)\nEine weitere Möglichkeit bietet die library(ggpubr) mit der Funktion ggarrange(). Hier können auch die einzelnen Plots z.B. mit a), b), c) und d) beschriftet werden.\n\nlibrary(ggpubr)\nggarrange(p1, p2, p3, p4, labels = c(\"a)\", \"b)\", \"c)\", \"d)\"), font.label = list(face=\"plain\"),\n          common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\n\n\n\nDas Argument align=\"hv\" richtet die Plots horizontal und vertikal aus (vgl. a) und c) oben mit dieser Grafik unten).\n\nggarrange(p1, p2, p3, p4, labels = c(\"a)\", \"b)\", \"c)\", \"d)\"), font.label = list(face=\"plain\"),\n          common.legend = TRUE, legend = \"bottom\", align=\"hv\")\n\n\n\n\n\n\n\n\nAusserdem kann auch die relative Breite der Plots geändert werden.\n\nggarrange(p1, p2, p3, p4, labels = c(\"a)\", \"b)\", \"c)\", \"d)\"), font.label = list(face=\"plain\"),\n          common.legend = TRUE, legend = \"bottom\", align=\"hv\", widths = c(0.6,0.4))"
  },
  {
    "objectID": "Themen/03/03_Graph.html#r-logo-im-plot",
    "href": "Themen/03/03_Graph.html#r-logo-im-plot",
    "title": "Grafische Darstellungen",
    "section": "R-Logo im Plot",
    "text": "R-Logo im Plot\n\nR_png &lt;- png::readPNG(\"R_logo.png\", native = TRUE)\nggplot(data=pot, aes(x=weight, y=tubers)) +\n  geom_point()+\n  patchwork::inset_element(p = R_png,\n                left = 0.01,\n                bottom = 0.8,\n                right = 0.15,\n                top = 0.99)"
  },
  {
    "objectID": "Themen/05/05_Regression.html",
    "href": "Themen/05/05_Regression.html",
    "title": "Regression",
    "section": "",
    "text": "library(ggplot2)\nlibrary(dplyr)\nlibrary(gridExtra)\nlibrary(ggpubr)\nlibrary(ggfortify)\nlibrary(DHARMa)\nLineare Regression\nAnnahmen:\nmod.Bsp1=lm(yn~x)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod.Bsp1, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nmod.Bsp2=lm(yh~x)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod.Bsp2, plot = F)\nplot(simulationOutput)\nNur für das erste Beispiel treffen die Annahmen für eine Regression zu. Im zweiten Beispiel tritt der Trompeteneffekt auf (Heteroskedastizität)."
  },
  {
    "objectID": "Themen/05/05_Regression.html#beispiel-trade-off-zwischen-ertrag-und-proteingehalt",
    "href": "Themen/05/05_Regression.html#beispiel-trade-off-zwischen-ertrag-und-proteingehalt",
    "title": "Regression",
    "section": "Beispiel Trade-off zwischen Ertrag und Proteingehalt",
    "text": "Beispiel Trade-off zwischen Ertrag und Proteingehalt\nBei gleicher N-Düngung beobachtet man im Weizen aufgrund unterschiedlicher Sorteneigenschaften häufig einen Trade-off zwischen Ertrag und Proteingehalt.\nFrage: Wie stark reduziert sich der Proteingehalt mit steigendem Ertrag?"
  },
  {
    "objectID": "Themen/05/05_Regression.html#daten-einlesen-kennenlernen-und-plotten",
    "href": "Themen/05/05_Regression.html#daten-einlesen-kennenlernen-und-plotten",
    "title": "Regression",
    "section": "Daten einlesen, kennenlernen und plotten",
    "text": "Daten einlesen, kennenlernen und plotten\n\nlibrary(openxlsx)\nreg&lt;-read.xlsx(\"Trade-off.xlsx\")\nstr(reg)\n\n'data.frame':   10 obs. of  2 variables:\n $ Ert : num  90.5 101.3 93.3 102 72 ...\n $ Prot: num  10.9 12.5 12.3 11.6 13.3 ...\n\nsummary(reg)\n\n      Ert              Prot      \n Min.   : 51.65   Min.   :10.51  \n 1st Qu.: 72.88   1st Qu.:11.73  \n Median : 90.70   Median :12.89  \n Mean   : 84.93   Mean   :13.12  \n 3rd Qu.: 99.30   3rd Qu.:14.07  \n Max.   :109.28   Max.   :16.80  \n\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()"
  },
  {
    "objectID": "Themen/05/05_Regression.html#modell-formulieren",
    "href": "Themen/05/05_Regression.html#modell-formulieren",
    "title": "Regression",
    "section": "Modell formulieren",
    "text": "Modell formulieren\n\nmod&lt;-lm(Prot~Ert, data=reg)\nsummary(mod)\n\n\nCall:\nlm(formula = Prot ~ Ert, data = reg)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.64733 -0.49234  0.00472  0.60021  1.54734 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 21.26794    1.55972  13.636 8.05e-07 ***\nErt         -0.09590    0.01798  -5.335 0.000699 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.008 on 8 degrees of freedom\nMultiple R-squared:  0.7806,    Adjusted R-squared:  0.7531 \nF-statistic: 28.46 on 1 and 8 DF,  p-value: 0.0006987\n\n\nMit jedem Anstieg des Ertrag (je dt/ha) sinkt der Proteingehalt um -0.1 %. Das R² des Modells beträgt 78.1."
  },
  {
    "objectID": "Themen/05/05_Regression.html#signifikanztest-der-modellparameter",
    "href": "Themen/05/05_Regression.html#signifikanztest-der-modellparameter",
    "title": "Regression",
    "section": "Signifikanztest der Modellparameter",
    "text": "Signifikanztest der Modellparameter\n\ndrop1(mod, test=\"F\")\n\nSingle term deletions\n\nModel:\nProt ~ Ert\n       Df Sum of Sq    RSS     AIC F value    Pr(&gt;F)    \n&lt;none&gt;               8.128  1.9277                      \nErt     1    28.914 37.043 15.0948  28.458 0.0006987 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSignifikanter Zusammenhang zwischen Ertrag und Proteingehalt."
  },
  {
    "objectID": "Themen/05/05_Regression.html#modelldiagnostik",
    "href": "Themen/05/05_Regression.html#modelldiagnostik",
    "title": "Regression",
    "section": "Modelldiagnostik",
    "text": "Modelldiagnostik\n\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\nAuch wenn es bei diesem kleinen Stichprobenumfang schwierig ist, diese Plots sicher zu interpretieren, scheint alles in Ordnung zu sein.\n\nDie Residuen sind annähernd normalverteilt (Plot oben links).\nDie Residuen weisen keinen Trompeteneffekt (Varianzheterogenität) auf (Plot oben rechts).\nEs gibt keine erkennbare Muster in den Residuen.\nEs gibt keine einflussreiche Punkte (keine roten Sternchen im Plot oben rechts).\n\n\nplotResiduals(simulationOutput, form = reg$Ert)\n\n\n\n\n\n\n\n\nAuch der Plot gegen die Erklärungsvariable zeigt keine auffälligen Muster.\nDas Paket ggfortify gibt noch zwei weitere Plots zur Cook’s Distance und Leverage aus. Hat eine Stichprobe eine hohe Leverage (i.e. Hebelwirkung, extremer Wert in x) und gleichzeitig ein großes Residuum (große Differenz zwischen beobachtetem und erwartetem Wert), dann spricht man von einem einflussreichem Punkt, der evtl. ein Ausreißer ist und durch eine hohe Cook’s Distance (&gt; 1 oder 0,5) gekennzeichnet ist.\nEntsprechend kann man auf diese Werte nochmal genauer schauen (i.e. den Wert auf Eingabefehler überprüfen) und ggfls. das Modell ohne Ausreißer rechnen und die “neuen” Modellparameter mit den “alten” vergleichen und damit die Robustheit der Ergebnisse überprüfen.\n\nlibrary(ggfortify)\nautoplot(mod, which =c(4,6), ncol = 2, label.size = 3)"
  },
  {
    "objectID": "Themen/05/05_Regression.html#modellinterpretation",
    "href": "Themen/05/05_Regression.html#modellinterpretation",
    "title": "Regression",
    "section": "Modellinterpretation",
    "text": "Modellinterpretation\nDie predict-Funktion rechnet uns die Erwartungswerte basierend auf den Modellkoeffizienten aus. Gibt man kein weiteres Argument in die predict-Funktion, dann werden die Originaldaten zur Vorhersage genutzt.\n\npredict(mod) \n\n       1        2        3        4        5        6        7        8 \n12.59231 11.55265 12.32326 11.48316 14.36743 16.31497 15.24944 14.01335 \n       9       10 \n12.54665 10.78760 \n\nreg$Ert\n\n [1]  90.46327 101.30412  93.26876 102.02872  71.95367  51.64602  62.75668\n [8]  75.64570  90.93937 109.28159\n\n\nBei einem Ertrag von 90.4 dt/ha schätzt unser Modell einen Proteingehalt von 12.59 %, bei einem Ertrag von 101.3 dt/ha schätzt es einen Proteingehalt von 11.6 %.\nWir können uns nun fragen, wie hoch der Proteingehalt bei einem Ertrag von 80 dt/ha ist. Hierzu müssen wir die geschätzten Koeffizienten (rcoef(mod)) in die Modellgleichung (y = a + b*x) einsetzen, wobei a der Intercept, b der Koeffizient fürErt` und x der Ertrag ist:\n\npredict(mod, newdata=data.frame(Ert=80))\n\n       1 \n13.59576 \n\n\nJetzt fehlt nur noch eine Abbildung zum Zusammenhang zwischen Wachstum und Ertrag.\nGanz schnell und einfach geht es mit dem Package effects.\n\nlibrary(effects)\nplot(allEffects(mod))\n\n\n\n\n\n\n\nplot(Effect(c(\"Ert\"), mod, partial.residuals=TRUE))\n\n\n\n\n\n\n\n\nDie blaue Linie zeigt uns den fit (also die Regressionslinie) an, während die orangefarbene Linie ist ein fit durch die Residuen und sollte entlang der blauen Linie laufen und keine Kurvatur aufweisen.\nEine weitere Alternative für die Abbildung der Originalwerte zusammen mit den Vorhersagewerten und Konfidenzintervalle des Modells bietet die library(effects).\n\nef=allEffects(mod, xlevels=100)\nef1=as.data.frame(ef[[1]])\nhead(ef1)\n\n    Ert      fit        se    lower    upper\n1 51.65 16.31459 0.6778851 14.75139 17.87780\n2 52.23 16.25897 0.6687008 14.71694 17.80100\n3 52.81 16.20335 0.6595535 14.68241 17.72428\n4 53.39 16.14772 0.6504446 14.64779 17.64765\n5 53.97 16.09210 0.6413759 14.61308 17.57111\n6 54.56 16.03552 0.6321938 14.57767 17.49336\n\ntail(ef1)\n\n      Ert      fit        se    lower    upper\n95  106.4 11.06395 0.5005978 9.909565 12.21833\n96  107.0 11.00640 0.5089613 9.832737 12.18007\n97  107.5 10.95845 0.5159996 9.768556 12.14835\n98  108.1 10.90091 0.5245242 9.691357 12.11047\n99  108.7 10.84337 0.5331307 9.613969 12.07277\n100 109.3 10.78583 0.5418153 9.536401 12.03526\n\n\nDurch das Argument xlevels=100 werden 100 Einträge für die Erklärungsvariablen im beobachteten Werteberich erzeugt. Die Spalte fit zeigt die fitted values (Vorhersagewerte) und in lower und upper sind die Grenzen des Konfidenzintervalls aufgeführt.\nNun plotten wir die Originalwerte und zeichnen dann die Daten aus ef1 mit den Funktionen geom_line() und geom_ribbon() ein.\n\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()+\n  geom_line(data = ef1, aes(x = Ert, y = fit))+\n  geom_ribbon(data = ef1, aes(x = Ert, y = NULL, ymin =lower, ymax = upper), alpha = 0.4)\n\n\n\n\n\n\n\n\nBei einer einfachen Regression kann man die Regressionslinie mit der Funktion geom_smooth(method=lm) einzeichnen.\n\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\noder geom_abline(intercept = 21.26794, slope = -0.09590221)\n\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()+\n  geom_abline(intercept= 21.26794, slope=-0.09590221)\n\n\n\n\n\n\n\n# oder so\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()+\n  geom_abline(intercept=coef(mod)[1], slope=coef(mod)[2])\n\n\n\n\n\n\n\n\nAlternativ, aber etwas komplizierter, geht es auch so:\nUm die Regressionslinie des Modells in einen Plot “per Hand” einzuzeichnen, erstellen wir einen Testdatensatz, der alle Erklärungsvariablen des Modells in einem realistischen Wertebereich (Minimum bis Maximum) enthält. In diesem Beispiel ist das sehr einfach, da Ert die einzige Erklärungsvariable ist.\nWir benennen den Testdatensatz td und nutzen die predict-Funktion mit dem Argument newdata=td um die Erwartungswerte td$p zu berechnen.\n\nrange(reg$Ert)\n\n[1]  51.64602 109.28159\n\n#Testdatensatz mit Erklärungsvariablen (Wertebereich und Variablenname) erstellen \ntd&lt;-data.frame(Ert=seq(from = 50, to =110, by = 5))\n\ntd\n\n   Ert\n1   50\n2   55\n3   60\n4   65\n5   70\n6   75\n7   80\n8   85\n9   90\n10  95\n11 100\n12 105\n13 110\n\n#Predict-Funktion für neu erstellten Datensatz nutzen\ntd$p&lt;-predict(mod, newdata=td)\ntd\n\n   Ert        p\n1   50 16.47283\n2   55 15.99332\n3   60 15.51381\n4   65 15.03430\n5   70 14.55479\n6   75 14.07528\n7   80 13.59576\n8   85 13.11625\n9   90 12.63674\n10  95 12.15723\n11 100 11.67772\n12 105 11.19821\n13 110 10.71870\n\ntd&lt;-data.frame(td, predict(mod, newdata=td, interval = \"confidence\"))\ntd\n\n   Ert        p      fit       lwr      upr\n1   50 16.47283 16.47283 14.848937 18.09672\n2   55 15.99332 15.99332 14.551201 17.43544\n3   60 15.51381 15.51381 14.245615 16.78200\n4   65 15.03430 15.03430 13.928471 16.14012\n5   70 14.55479 14.55479 13.593891 15.51568\n6   75 14.07528 14.07528 13.232828 14.91772\n7   80 13.59576 13.59576 12.832845 14.35868\n8   85 13.11625 13.11625 12.381199 13.85131\n9   90 12.63674 12.63674 11.872220 13.40126\n10  95 12.15723 12.15723 11.311883 13.00258\n11 100 11.67772 11.67772 10.713011 12.64243\n12 105 11.19821 11.19821 10.087965 12.30845\n13 110 10.71870 10.71870  9.445689 11.99171\n\nstr(td)\n\n'data.frame':   13 obs. of  5 variables:\n $ Ert: num  50 55 60 65 70 75 80 85 90 95 ...\n $ p  : num  16.5 16 15.5 15 14.6 ...\n $ fit: num  16.5 16 15.5 15 14.6 ...\n $ lwr: num  14.8 14.6 14.2 13.9 13.6 ...\n $ upr: num  18.1 17.4 16.8 16.1 15.5 ...\n\n\nJetzt plotten wir die Originaldaten und zeichnen\n\ndie Regressionslinie durch die geom_line()-Funktion der vorhergesagten Werte td$fit und\ndas Konfidenzintervall durch die geom_ribbon-Funktion der vorhergesagten Werte td$lwr und td$upr ein.\n\n\nggplot(reg, aes(x=Ert, y=Prot)) +\n  geom_point()+\n  geom_line(data = td, aes(x = Ert, y = fit))+\n  geom_ribbon(data = td, aes(x = Ert, y = NULL, ymin = lwr, ymax = upr), alpha = 0.4)"
  },
  {
    "objectID": "Themen/05/05_Regression.html#polynomiale-regression-quadratischer-term",
    "href": "Themen/05/05_Regression.html#polynomiale-regression-quadratischer-term",
    "title": "Regression",
    "section": "Polynomiale Regression: Quadratischer Term",
    "text": "Polynomiale Regression: Quadratischer Term\nMit einer linearen Regression können auch “nicht-lineare” Zusammenhänge modelliert werden.\n\n\n\n\n\n\n\n\n\nWenn die Daten einen nicht-linearen Trend aufweisen, wir aber nur einen linearen Term modellieren, zeigen die Residuen ein Muster, i.e. eine Kurvatur.\n\nset.seed(123)\ndf=data.frame(y3=y3+runif(length(y3),0,4), x)\nmod=lm(y3~x, df)\nggplot(data=df, aes(y=y3, x=x))+\n  geom_point()+geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\n\nWir können diesen Zusammenhang modellieren, indem wir einen quadratischen Term in das lineare Modell nehmen.\nmod&lt;-lm(Abhängige~poly(Erklärungsvariable, 2), data=md)\noder\nmod&lt;-lm(Abhängige~Erklärungsvariable+I(Erklärungsvariable^2), data=md)\nDas I (Großbuchstabe i) steht für “as is”.\n\nmod2=lm(y3~x+I(x^2), df)\nggplot(data=df, aes(y=y3, x=x))+\n  geom_point()+\n  geom_smooth(method = lm, formula=y ~ poly(x, 2))\n\n\n\n\n\n\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod2, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$x)"
  },
  {
    "objectID": "Themen/05/05_Regression.html#übung-5",
    "href": "Themen/05/05_Regression.html#übung-5",
    "title": "Regression",
    "section": "Übung 5",
    "text": "Übung 5\n\nImportiere die Daten NDuenger.xlsx und mach dich mit den Daten vertraut.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlibrary(openxlsx)\ndat=read.xlsx(\"NDuenger.xlsx\")\nstr(dat)\n\n'data.frame':   20 obs. of  2 variables:\n $ ERT: num  70 73.1 75.5 79.8 81.1 79.7 84.5 82.9 83.6 86.4 ...\n $ ND : num  100 103 107 108 108 ...\n\n\n\nlibrary(ggplot2)\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nFühre eine Regression durch, um den Einfluss der N-Düngung auf den Ertrag zu modellieren. Was ist die Abhängige (y), was die Erklärungsvariable (x)?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nmod&lt;-lm(ERT~ND, data=dat)\ndrop1(mod, test=\"F\")\n\nSingle term deletions\n\nModel:\nERT ~ ND\n       Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;               66.94 28.162                      \nND      1    911.81 978.75 79.811  245.17 6.271e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(mod)\n\n\nCall:\nlm(formula = ERT ~ ND, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6108 -1.2027 -0.0947  1.6025  2.8800 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.66007    4.64358   2.726   0.0139 *  \nND           0.60648    0.03873  15.658 6.27e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.928 on 18 degrees of freedom\nMultiple R-squared:  0.9316,    Adjusted R-squared:  0.9278 \nF-statistic: 245.2 on 1 and 18 DF,  p-value: 6.271e-12\n\n\n\n\n\n\nStimmen die Annahmen für eine lineare Regression?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form=dat$ND)\n\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n\n\n\n\n\n\n\n\n\nNein, eine deutliche Kurve in dem Residuen vs. fitted values Plot.\nIch fitte nun ein polynomiales Modell mit quadratischem Term. Man könnte auch die Abhängige und/oder die Erklärungsvariablen transformieren (z.B. Wurzel oder log) und dann Modelle fitten und die Residuen überprüfen. Ich denke aber, dass ein polynomiales Modell den Zusammenhang ganz gut widerspigeln könnte.\n\nmod2&lt;-lm(ERT~ND+I(ND^2), data=dat)\n\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = mod2, plot = F)\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form=dat$ND)\n\n\n\n\n\n\n\n\nBesser. Die Residuen weisen kein auffälliges Muster auf.\n\ndrop1(mod2, test=\"F\")\n\nSingle term deletions\n\nModel:\nERT ~ ND + I(ND^2)\n        Df Sum of Sq    RSS    AIC F value    Pr(&gt;F)    \n&lt;none&gt;               42.324 20.992                      \nND       1    41.552 83.876 32.672 16.6897 0.0007708 ***\nI(ND^2)  1    24.619 66.943 28.162  9.8884 0.0059113 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBeide Terme sind signifikannt.\n\nsummary(mod2)\n\n\nCall:\nlm(formula = ERT ~ ND + I(ND^2), data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.4642 -1.2745  0.1751  1.0468  3.1174 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -1.078e+02  3.849e+01  -2.800 0.012297 *  \nND           2.623e+00  6.421e-01   4.085 0.000771 ***\nI(ND^2)     -8.368e-03  2.661e-03  -3.145 0.005911 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.578 on 17 degrees of freedom\nMultiple R-squared:  0.9568,    Adjusted R-squared:  0.9517 \nF-statistic: 188.1 on 2 and 17 DF,  p-value: 2.543e-12\n\n\nDas Modell hat ein R² von 95,7%.\nWir können auch beide Modelle mit der anova()-Funktion (F-test) vergleichen und sehne hier, dass mod2 signifikant besser fitted.\n\nanova(mod, mod2)\n\nAnalysis of Variance Table\n\nModel 1: ERT ~ ND\nModel 2: ERT ~ ND + I(ND^2)\n  Res.Df    RSS Df Sum of Sq      F   Pr(&gt;F)   \n1     18 66.943                                \n2     17 42.324  1    24.619 9.8884 0.005911 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAuch ein Vergleich der AIC-Werte zeigt, dass mod2 einen niedrigeren AIC im Vergleich zu mod hat und entsprechend damit einen besseren fit aufweist. Mehr Informationen zum AIC und Modellvergleich findest du im Kapitel Statistische Modellierung.\n\nAIC(mod, mod2)\n\n     df      AIC\nmod   3 86.91963\nmod2  4 79.74999\n\n\n\n\n\n\nWie hoch ist laut Modell der zu erwartende Ertrag bei 120 kg N?\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nUm diese Frage zu beantworten, sollten wir das polynomiale Modell nutzen. Wir können entweder die 120 kg N in die Modellgleichung einsetzten\n\ncoef(mod2)\n\n  (Intercept)            ND       I(ND^2) \n-1.077851e+02  2.623078e+00 -8.368154e-03 \n\n\n\ncoef(mod2)[1]+120*coef(mod2)[2]+120^2*coef(mod2)[3]\n\n(Intercept) \n   86.48283 \n\n\noder die Funktion predict()nutzen:\n\npredict(mod2, newdata=data.frame(ND=120))\n\n       1 \n86.48283 \n\n\nWir sollten nicht das lineare Modell interpretieren, da dies keinen guten fit aufweist (trotz hohem R²).\n\npredict(mod, newdata=data.frame(ND=120))\n\n       1 \n85.43708 \n\n\n\n\n\n\nPlotte die Regressionslinie des Modells/der Modelle.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nschnelle Interpretation:\n\nlibrary(effects)    \nplot(allEffects(mod2))  \n\n\n\n\n\n\n\nplot(Effect(c(\"ND\"), mod2, partial.residuals=TRUE))\n\n\n\n\n\n\n\n\ndas “falsche Model”\n\nplot(allEffects(mod))   \n\n\n\n\n\n\n\nplot(Effect(c(\"ND\"), mod, partial.residuals=TRUE))  \n\n\n\n\n\n\n\n\nIm Plot sehen wir nocheinmal, dass das euinfache lineare Modell (mod) im niedrigen und hohen N-Düngerbereich den Ertrag überschätzt.\nZu Interpretation dieses einfachen Modell (ohne weitere Kovariablen) könnten wir auch geom_smooth() nutzen, um die Regressionsline einzuzeichnen.\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+ \n  geom_smooth(method=lm, formula=y ~ poly(x, 2), col=\"green\") # quadr\n\n\n\n\n\n\n\n\nnur zum Vergleich beider Modelle:\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+ \n  geom_smooth(method=lm)+#linear\n  geom_smooth(method=lm, formula=y ~ poly(x, 2), col=\"green\") # quadr\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nhier aber noch der Code, bei dem das Modell interpretiert wird, wenn auch andere Effekte im Modell wären:\n\nef=allEffects(mod2, xlevels=100)    \nef1=as.data.frame(ef[[1]])  \nhead(ef1)   \n\n     ND      fit        se    lower    upper\n1 100.5 71.31378 1.0078085 69.18749 73.44007\n2 100.9 71.68888 0.9699969 69.64236 73.73539\n3 101.3 72.06129 0.9333186 70.09216 74.03042\n4 101.7 72.43103 0.8977950 70.53685 74.32521\n5 102.2 72.88943 0.8550494 71.08544 74.69343\n6 102.6 73.25315 0.8222100 71.51843 74.98786\n\ntail(ef1)\n\n       ND      fit        se    lower    upper\n95  139.3 95.22989 0.9450695 93.23596 97.22381\n96  139.7 95.34523 0.9798871 93.27785 97.41261\n97  140.2 95.48565 1.0250315 93.32302 97.64827\n98  140.6 95.59497 1.0624230 93.35345 97.83648\n99  141.0 95.70161 1.1009301 93.37885 98.02437\n100 141.4 95.80557 1.1405367 93.39925 98.21190\n\n\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+\n  geom_line(data = ef1, aes(x = ND, y = fit))+  \n  geom_ribbon(data = ef1, aes(x = ND, y = NULL, ymin =lower, ymax = upper), alpha = 0.4)    \n\n\n\n\n\n\n\n\noder so:\n\ntd&lt;-data.frame(ND=seq(100,142, 1))\ntd&lt;-data.frame(td, predict(mod, newdata=td, interval=\"confidence\"))\ntd&lt;-data.frame(td, predict(mod2, newdata=td, interval=\"confidence\"))\ntd[1:10,]\n\n    ND      fit      lwr      upr    fit.1    lwr.1    upr.1\n1  100 73.30758 71.48955 75.12561 70.84115 68.61184 73.07046\n2  101 73.91405 72.16610 75.66200 71.78223 69.75529 73.80917\n3  102 74.52053 72.84164 76.19942 72.70657 70.86698 74.54617\n4  103 75.12700 73.51603 76.73798 73.61418 71.94615 75.28221\n5  104 75.73348 74.18911 77.27785 74.50505 72.99194 76.01816\n6  105 76.33995 74.86072 77.81919 75.37918 74.00340 76.75496\n7  106 76.94643 75.53064 78.36222 76.23658 74.97958 77.49358\n8  107 77.55290 76.19865 78.90716 77.07724 75.91965 78.23483\n9  108 78.15938 76.86446 79.45429 77.90117 76.82318 78.97915\n10 109 78.76585 77.52777 80.00394 78.70835 77.69035 79.72636\n\n\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+\n  geom_line(data = td, aes(x = ND, y = fit.1))+ \n  geom_ribbon(data = td, aes(x = ND, y = NULL, ymin = lwr.1, \n                             ymax = upr.1), alpha = 0.4)\n\n\n\n\n\n\n\n\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+\n  geom_line(data = td, aes(x = ND, y = fit.1), size=1)+ \n  geom_ribbon(data = td, aes(x = ND, y = NULL, ymin = lwr.1, \n                             ymax = upr.1), alpha = 0.2)+\n  geom_line(data = td, aes(x = ND, y = fit), col=2, size=1)+    \n  geom_ribbon(data = td, aes(x = ND, y = NULL, ymin = lwr, \n                             ymax = upr, linetype=NA), col=2, alpha = 0.2)+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nExtraaufgabe:\n\nExtrapoliere die Vorhersage des Modells für eine N-Düngung von 250 kg.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\ntd1&lt;-data.frame(ND=seq(100,250, 1))\ntd1$p&lt;-predict(mod, newdata=td1)\ntd1$p2&lt;-predict(mod2, newdata=td1)\n\n\nggplot(dat, aes(x=ND, y=ERT)) + \n  geom_point()+\n  geom_line(data = td1, aes(x = ND, y = p))+    \n  geom_line(data = td1, aes(x = ND, y = p2))\n\n\n\n\n\n\n\n\nWir sollten das Modell immer nur für den beobachteten Wertebereich interpretieren und insbesondere bei polynomialen Modellen nicht extrapolieren.\n\n\n\nEnde Übung 5"
  },
  {
    "objectID": "Themen/07/07_ExpDesign.html",
    "href": "Themen/07/07_ExpDesign.html",
    "title": "Experimental Design",
    "section": "",
    "text": "library(ggplot2)# plotting\nlibrary(dplyr)# data management and summary statistics\nlibrary(ggpubr)# plotting\nlibrary(agricolae)# experimental design\nlibrary(openxlsx)# import and export Excel files\n# Suppress summarise info\noptions(dplyr.summarise.inform = FALSE)"
  },
  {
    "objectID": "Themen/07/07_ExpDesign.html#replication",
    "href": "Themen/07/07_ExpDesign.html#replication",
    "title": "Experimental Design",
    "section": "Replication",
    "text": "Replication\n\nto distinguish systematic treatment effects from random variation\nthe more samples you have:\n\nthe more precise you estimate the mean of the samples (reducing uncertainty in the results and increasing confidence in the conclusions)\nless dramatic when missing data occur (e.g. destroyed trap, broken test tube, farmer leaves the project, wrong application of treatment)\n\n\nHere is a small simulation, were we draw different number of samples from a random normal distribution with a mean of 20 for different sites.\n\n\nShow the code\nn=c(2,3,5,10,20)\nmu=20\nsd=5\nsites=letters[1:6]\nnrep=rep(n, times=n)\ndat=expand.grid(n=nrep, sites=sites)\nset.seed(11112024)\ndat$y=rnorm(length(dat$n), mu, sd)\nmw &lt;- dat %&gt;%\n  group_by(n,sites) %&gt;%\n  summarise(y.m = mean(y)) \nmw.ci&lt;-mw %&gt;%  group_by(n) %&gt;% \n  summarise(\n  n.mw=length(y.m),\n  y.mm = mean(y.m),\n  y.se=sd(y.m)/sqrt(n.mw),\n  y.low= y.mm-qt(1-(0.05/2), n.mw-1)*y.se,\n  y.up= y.mm+qt(1-(0.05/2), n.mw-1)*y.se, \n  sites=\" across sites\")\n\n\nmw.ci &lt;- dat %&gt;%\n  group_by(n,sites) %&gt;%\n  summarise(y.m = mean(y))  %&gt;% # calculate mean values per site and n\n  group_by(n) %&gt;% \n  summarise( # calculate confidence intervals for n (based on mean values per site and n)\n  n.mw=length(y.m),\n  y.mm = mean(y.m),\n  y.se=sd(y.m)/sqrt(n.mw),\n  y.low= y.mm-qt(1-(0.05/2), n.mw-1)*y.se, \n  y.up= y.mm+qt(1-(0.05/2), n.mw-1)*y.se, \n  sites=\" across sites\")\n\n\nggplot(data=dat, aes(y=y, x=sites))+\n  geom_hline(yintercept=20, col=\"grey20\")+\n  geom_point(shape=3, size=1)+\n  stat_summary(fun = mean, geom = \"point\", color = \"blue\", size = 2) +\n  geom_point(data=mw.ci, aes(y=y.mm), col=\"blue\", size=3)+\n  geom_errorbar(data=mw.ci, aes(y=y.mm, ymin=y.low, ymax=y.up), \n                width=0.4, col=\"blue\")+\n   facet_grid(~n, labeller = label_both)+\n  theme_bw()+\n  theme(axis.text.x=element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nWith smaller sample sizes, the mean per site (blue points) fluctuates more, reflecting greater variance. As sample sizes grow, the mean across sites converges closer to the actual mean of 20, demonstrating how replication (larger sample sizes) enhances precision and reduces the impact of random variation in data.\n\n“Are three replications enough?”\nI often hear this question and the answer is: … well it depends…\nLet’s consider the example above and assume a mean of 20 with a standard deviation of 5 in the control group. Now, if we assume a mean of 25 in the treatment group, this results in a treatment effect of 5 (the difference between the groups). We can then create datasets with 2, 3, 5, 10, and 20 samples for each group and use this simulated data to test, using a t-test, whether the difference in group means is statistically significant.\n\n\nShow the code\nsample_sizes=c(2,3,5,10,20) # Different sample sizes to test\ntreatment_effects &lt;- c(5)  # Effect size to test\nstd_devs &lt;- c(5)         # Standard deviations to test\n\n# Generate one example dataset per combination for visualization\nexample_data &lt;- do.call(rbind, lapply(sample_sizes, function(n) {\n  do.call(rbind, lapply(std_devs, function(sd) {\n    do.call(rbind, lapply(treatment_effects, function(effect) {\n      \n      # Generate data for control and treatment groups\n      control &lt;- rnorm(n, mean = 20, sd = sd)\n      treatment &lt;- rnorm(n, mean = 20 + effect, sd = sd)\n      \n      # Combine control and treatment data into a single data frame\n      data.frame(\n        group = rep(c(\"Control\", \"Treatment\"), each = n),\n        value = c(control, treatment),\n        sample_size = n,\n        sd = sd,\n        effect = effect\n      )\n    }))\n  }))\n}))\n\n# Plot the example data for each combination\nggplot(example_data, aes(x = group, y = value, fill = group)) +\n geom_point(shape=3, size=1)+\n  stat_summary(color = \"#00BA38\", fun = mean, geom = \"point\",  size = 2, position = position_nudge(x =0.2)) +\n stat_compare_means(method = \"t.test\", label.y.npc  =0.9) +\n  facet_grid(sd ~ sample_size, labeller = labeller(\n    sd = function(x) paste(\"SD =\", x),\n    sample_size = function(x) paste(\"Sample size =\", x)\n  )) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExcersise\n\n\n\nCopy the code and repeat 10 times. Note for each run and sample size, how often you observe a significant effect.\n\n\nSince these data are generated using a random normal distribution, we would need to repeat this process 1,000 times to observe how often a significant difference between groups appears.\nFortunately, R can handle this for us, allowing us to test various effect sizes and standard deviations as well.\nHere is the code:\n\n\nShow the code\nsample_sizes &lt;- c(2,3,5,10,20)    # Different sample sizes to test\nalpha &lt;- 0.05                          # Significance level for the t-test\nn_simulations &lt;- 1000                  # Number of simulations for each combination\ntreatment_effects &lt;- c(2, 5, 10)  # Different effect sizes to test\nstd_devs &lt;- c(5, 10, 15) \n\n# Different standard deviations to test\n\n# Function to calculate power through simulation\nsimulate_power &lt;- function(n, sd, effect) {\n  significant_results &lt;- 0\n  for (i in 1:n_simulations) {\n    # Generate data for control and treatment groups with specified mean and SD\n    control &lt;- rnorm(n, mean = 20, sd = sd)\n    treatment &lt;- rnorm(n, mean = 20 + effect, sd = sd)\n    \n    # Perform a t-test comparing the two groups\n    test &lt;- t.test(treatment, control)#, alternative = c(\"greater\")\n    \n    # Check if p-value is below alpha, indicating a significant result\n    if (test$p.value &lt; alpha) {\n      significant_results &lt;- significant_results + 1\n    }\n  }\n  # Calculate power as the proportion of significant results out of total simulations\n  return(significant_results / n_simulations)\n}\n\n# Run the simulation for each combination of sample size, standard deviation, and effect size\nresults &lt;- expand.grid(sample_size = sample_sizes, sd = std_devs, effect = treatment_effects)\nresults$power &lt;- mapply(simulate_power, results$sample_size, results$sd, results$effect)\n\n# Plot the power curves\nggplot(results, aes(x = sample_size, y = power*100, color = as.factor(effect))) +\n   geom_hline(yintercept=80, col=\"grey\", linetype = \"dashed\")+\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  facet_grid(sd ~ effect, labeller = labeller(\n    sd = function(x) paste(\"SD =\", x),\n    effect = function(x) paste(\"Effect size =\", x)\n  )) +\n  labs(title = \"Power curve for different sample sizes, effect sizes, and standard deviations\",\n       x = \"Sample size\",\n       y = \"Power\",\n       color = \"Effect size\") +\n  theme_bw() +\n  scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 20))+\n  scale_x_sqrt(breaks=sample_sizes, labels=sample_sizes)\n\n\n\n\n\n\n\n\n\nThus, the experimental design determines the probability of detecting a significant effect, known as the statistical “power.”\nPower increases with:\n\na larger sample size\na greater effect size\nreduced variability (lower standard deviation)\n\nA statistical power of 80% is typically expected, meaning there is an 80% chance of correctly detecting a true effect if it exists. In our example, we would need 17 replications."
  },
  {
    "objectID": "Themen/09/09_2f_GLM.html",
    "href": "Themen/09/09_2f_GLM.html",
    "title": "Analysis of two-factorial experiments with generalised linear (mixed effect) models",
    "section": "",
    "text": "library(ggplot2)# plotting\nlibrary(dplyr)# data management and summary statistics\nlibrary(ggpubr)# plotting\nlibrary(openxlsx)# import and export Excel files\nlibrary(forcats)# factor repordering\nlibrary(DHARMa) # model diagnostics\nlibrary(emmeans) # posthoc tests\nlibrary(multcomp) # cld\nlibrary(multcompView) #cld\nlibrary(glmmTMB) # mixed model\nlibrary(car) # anova for glmmTMB\nlibrary(lme4) # lmer and glmer mixed model\nlibrary(lmerTest) # test lmer\nlibrary(conflicted)\nconflicts_prefer(lmerTest::lmer)\n# Suppress summarise info\noptions(dplyr.summarise.inform = FALSE)\nWe use the same data file as before. data_YSM.xlsx But let’s assume we have measured the number of pests per trap in the experimental plots.\nImport data and convert geno and N to factors, levels of N should not be in alphabetical order\ndf&lt;-read.xlsx(\"data_YSM.xlsx\")\nstr(df)\n\n'data.frame':   60 obs. of  7 variables:\n $ rep    : num  1 2 3 4 5 1 2 3 4 5 ...\n $ geno   : chr  \"g1\" \"g1\" \"g1\" \"g1\" ...\n $ N      : chr  \"low\" \"low\" \"low\" \"low\" ...\n $ yield  : num  55.9 63 69.5 59.6 64.4 ...\n $ pests  : num  3 0 8 1 4 8 4 6 4 16 ...\n $ pests.A: num  82 91 86 58 45 111 85 107 82 86 ...\n $ pests.B: num  82 91 86 58 45 111 85 107 82 86 ...\n\ndf &lt;- df %&gt;%\n  mutate(across(c(geno, N), ~ as.factor(.x)),\n         N=fct_relevel(N, \"low\", \"med\", \"high\"),\n         block=as.factor(rep))\nstr(df)\n\n'data.frame':   60 obs. of  8 variables:\n $ rep    : num  1 2 3 4 5 1 2 3 4 5 ...\n $ geno   : Factor w/ 4 levels \"g1\",\"g2\",\"g3\",..: 1 1 1 1 1 2 2 2 2 2 ...\n $ N      : Factor w/ 3 levels \"low\",\"med\",\"high\": 1 1 1 1 1 1 1 1 1 1 ...\n $ yield  : num  55.9 63 69.5 59.6 64.4 ...\n $ pests  : num  3 0 8 1 4 8 4 6 4 16 ...\n $ pests.A: num  82 91 86 58 45 111 85 107 82 86 ...\n $ pests.B: num  82 91 86 58 45 111 85 107 82 86 ...\n $ block  : Factor w/ 5 levels \"1\",\"2\",\"3\",\"4\",..: 1 2 3 4 5 1 2 3 4 5 ...\nggplot(df, aes(y=pests, x=geno, col=N)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.6)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0, \n                                            dodge.width=0.6), shape=1, size=1)\nAnd we fit a linear model\nmodel &lt;- lm(pests ~ geno * N + block, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = pests ~ geno * N + block, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.3167 -2.6500  0.4167  2.1625  8.8833 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.5167     2.4031   1.047 0.300694    \ngenog2         4.4000     2.9431   1.495 0.142053    \ngenog3         8.0000     2.9431   2.718 0.009355 ** \ngenog4         3.8000     2.9431   1.291 0.203399    \nNmed          15.6000     2.9431   5.300 3.55e-06 ***\nNhigh         31.4000     2.9431  10.669 8.74e-14 ***\nblock2        -3.0833     1.8998  -1.623 0.111737    \nblock3         3.0833     1.8998   1.623 0.111737    \nblock4        -0.9167     1.8998  -0.483 0.631837    \nblock5         4.3333     1.8998   2.281 0.027448 *  \ngenog2:Nmed  -11.6000     4.1622  -2.787 0.007825 ** \ngenog3:Nmed   -7.2000     4.1622  -1.730 0.090669 .  \ngenog4:Nmed   -8.6000     4.1622  -2.066 0.044728 *  \ngenog2:Nhigh  -1.4000     4.1622  -0.336 0.738200    \ngenog3:Nhigh -17.6000     4.1622  -4.228 0.000117 ***\ngenog4:Nhigh   6.6000     4.1622   1.586 0.119973    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.654 on 44 degrees of freedom\nMultiple R-squared:  0.9149,    Adjusted R-squared:  0.8859 \nF-statistic: 31.54 on 15 and 44 DF,  p-value: &lt; 2.2e-16\nlibrary(DHARMa)\nsimulationOutput &lt;- simulateResiduals(fittedModel = model, plot = F)\nplot(simulationOutput)\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\nWe observe that variance in residuals increases with increasing nitrogen fertilisation. Hence the assumption on variance homogeneity is not met.\nplotResiduals(simulationOutput, form = df$block)\nemmeans(model, ~geno*N)\n\n geno N    emmean   SE df lower.CL upper.CL\n g1   low     3.2 2.08 44   -0.994     7.39\n g2   low     7.6 2.08 44    3.406    11.79\n g3   low    11.2 2.08 44    7.006    15.39\n g4   low     7.0 2.08 44    2.806    11.19\n g1   med    18.8 2.08 44   14.606    22.99\n g2   med    11.6 2.08 44    7.406    15.79\n g3   med    19.6 2.08 44   15.406    23.79\n g4   med    14.0 2.08 44    9.806    18.19\n g1   high   34.6 2.08 44   30.406    38.79\n g2   high   37.6 2.08 44   33.406    41.79\n g3   high   25.0 2.08 44   20.806    29.19\n g4   high   45.0 2.08 44   40.806    49.19\n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \n\nCIs=cld(emmeans(model, ~N|geno), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)\nNegative confidence interval. But we cannot measure -1 pests per trap.\nggplot(df, aes(y=pests, x=N, col=N)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.6)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0, \n                                            dodge.width=0.6), shape=1, size=1)+\n  geom_point(data=CIs, aes(y=emmean), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 60, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")\nDo you think that these confidence interval match the observed data?"
  },
  {
    "objectID": "Themen/09/09_2f_GLM.html#generalized-linear-model-for-count-data",
    "href": "Themen/09/09_2f_GLM.html#generalized-linear-model-for-count-data",
    "title": "Analysis of two-factorial experiments with generalised linear (mixed effect) models",
    "section": "Generalized linear model for count data",
    "text": "Generalized linear model for count data\nWe use the function glm and specify the distribution with the family-argument poisson for count data. By default poisson GLMs use the log link.\n\nmodel2=glm(pests ~ geno * N + block, data = df, family=\"poisson\")\nsummary(model2)\n\n\nCall:\nglm(formula = pests ~ geno * N + block, family = \"poisson\", data = df)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.12766    0.25701   4.388 1.15e-05 ***\ngenog2        0.86500    0.29802   2.902 0.003702 ** \ngenog3        1.25276    0.28347   4.419 9.90e-06 ***\ngenog4        0.78276    0.30178   2.594 0.009492 ** \nNmed          1.77071    0.27044   6.547 5.85e-11 ***\nNhigh         2.38070    0.26131   9.111  &lt; 2e-16 ***\nblock2       -0.17793    0.09833  -1.810 0.070372 .  \nblock3        0.15100    0.09052   1.668 0.095276 .  \nblock4       -0.04967    0.09505  -0.523 0.601272    \nblock5        0.20626    0.08938   2.308 0.021022 *  \ngenog2:Nmed  -1.34785    0.34161  -3.946 7.96e-05 ***\ngenog3:Nmed  -1.21109    0.31812  -3.807 0.000141 ***\ngenog4:Nmed  -1.07756    0.34058  -3.164 0.001557 ** \ngenog2:Nhigh -0.78185    0.31609  -2.473 0.013381 *  \ngenog3:Nhigh -1.57774    0.30682  -5.142 2.71e-07 ***\ngenog4:Nhigh -0.51995    0.31827  -1.634 0.102327    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 582.631  on 59  degrees of freedom\nResidual deviance:  64.435  on 44  degrees of freedom\nAIC: 365.46\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(model2)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: pests\n       LR Chisq Df Pr(&gt;Chisq)    \ngeno       5.78  3  0.1229236    \nN        428.38  2  &lt; 2.2e-16 ***\nblock     22.29  4  0.0001756 ***\ngeno:N    61.75  6  1.982e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndrop1(model2, test=\"Chi\")\n\nSingle term deletions\n\nModel:\npests ~ geno * N + block\n       Df Deviance    AIC    LRT  Pr(&gt;Chi)    \n&lt;none&gt;      64.435 365.46                     \nblock   4   86.723 379.75 22.288 0.0001756 ***\ngeno:N  6  126.186 415.21 61.751 1.982e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn Poisson GLMs we need to look at the dispersion and assess whether the model assumptions are valid. Since the Poisson distribution is defined by a single parameter lamda which represents both the mean and the variance, we expect the ratio of the mean and the variance to be 1. As a quick check you can devide the residual deviance by the degrees of freedom from the model summary above or use the function testDispersion() from the library(DHARMa).\nHence overdispersion indicated that observed variance is greater than the mean and this can lead to underestimated standard errors, too narrow confidence intervals and invalid p-values.\nOverdispersion can occur if\n\nthe model misses important explanatory variables or\ndue to presence of outliers, non-linear pattern or zero-inflation.\n\nPossible solutions are extending the model by important explanatory variables (however do not overfit), applying quasipoisson or negative binomial GLMs, or fitting a zero-inflation term (in glmmmTM).\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model2, plot = F)\ntestDispersion(simulationOutput)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 0.84688, p-value = 0.528\nalternative hypothesis: two.sided\n\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\nWhen calculating the estimated marginal means we now can differentiate between the link scale (at which data were modeled) and the response scale, which is the back-transformed original scale.\n\nemmeans(model2, ~N*geno)\n\n N    geno emmean     SE  df asymp.LCL asymp.UCL\n low  g1     1.15 0.2500 Inf     0.664      1.64\n med  g1     2.92 0.1030 Inf     2.722      3.13\n high g1     3.53 0.0761 Inf     3.385      3.68\n low  g2     2.02 0.1620 Inf     1.701      2.34\n med  g2     2.44 0.1310 Inf     2.184      2.70\n high g2     3.62 0.0730 Inf     3.474      3.76\n low  g3     2.41 0.1340 Inf     2.144      2.67\n med  g3     2.97 0.1010 Inf     2.768      3.16\n high g3     3.21 0.0895 Inf     3.034      3.38\n low  g4     1.94 0.1690 Inf     1.605      2.27\n med  g4     2.63 0.1200 Inf     2.395      2.86\n high g4     3.80 0.0668 Inf     3.666      3.93\n\nResults are averaged over the levels of: block \nResults are given on the log (not the response) scale. \nConfidence level used: 0.95 \n\n\nFor a Poisson model, this means exponentiating the log-transformed values, so the estimated marginal means are presented as predicted counts rather than log counts. We do this by using the argument type=\"response\".\n\nemmeans(model2, ~N*geno, type=\"response\")\n\n N    geno  rate    SE  df asymp.LCL asymp.UCL\n low  g1    3.17 0.792 Inf      1.94      5.17\n med  g1   18.62 1.920 Inf     15.21     22.80\n high g1   34.27 2.610 Inf     29.52     39.79\n low  g2    7.53 1.220 Inf      5.48     10.35\n med  g2   11.49 1.510 Inf      8.88     14.86\n high g2   37.24 2.720 Inf     32.27     42.97\n low  g3   11.09 1.480 Inf      8.54     14.42\n med  g3   19.41 1.960 Inf     15.92     23.67\n high g3   24.76 2.220 Inf     20.78     29.51\n low  g4    6.93 1.170 Inf      4.98      9.66\n med  g4   13.87 1.660 Inf     10.97     17.53\n high g4   44.57 2.980 Inf     39.10     50.81\n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nIntervals are back-transformed from the log scale \n\n\nWe can also interpret the ratios of counts in the Poisson GLM. A ratio greater than 1 indicates that the count for one level of N is higher than the count for the other level.\n\ncontrast(emmeans(model2, ~N|geno, type=\"response\"), method=\"trt.vs.ctrl\", infer=c(T,T))\n\ngeno = g1:\n contrast   ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value\n med / low   5.88 1.590 Inf      3.22     10.71    1   6.547  &lt;.0001\n high / low 10.81 2.830 Inf      6.05     19.32    1   9.111  &lt;.0001\n\ngeno = g2:\n contrast   ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value\n med / low   1.53 0.319 Inf      0.96      2.43    1   2.026  0.0801\n high / low  4.95 0.880 Inf      3.33      7.35    1   8.989  &lt;.0001\n\ngeno = g3:\n contrast   ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value\n med / low   1.75 0.293 Inf      1.21      2.54    1   3.341  0.0017\n high / low  2.23 0.359 Inf      1.56      3.19    1   4.993  &lt;.0001\n\ngeno = g4:\n contrast   ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value\n med / low   2.00 0.414 Inf      1.26      3.17    1   3.348  0.0016\n high / low  6.43 1.170 Inf      4.29      9.63    1  10.241  &lt;.0001\n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nConf-level adjustment: dunnettx method for 2 estimates \nIntervals are back-transformed from the log scale \nP value adjustment: dunnettx method for 2 tests \nTests are performed on the log scale \n\n\n\nCI2s=cld(emmeans(model2, ~N|geno, type=\"response\"), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI2s$.group =gsub(\" \", \"\", CI2s$.group, fixed = TRUE)\nCI2s\n\ngeno = g1:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   3.17 0.792 Inf      1.74      5.76 a     \n med  18.62 1.920 Inf     14.55     23.83 b     \n high 34.27 2.610 Inf     28.57     41.10 c     \n\ngeno = g2:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   7.53 1.220 Inf      5.11     11.09 a     \n med  11.49 1.510 Inf      8.40     15.72 a     \n high 37.24 2.720 Inf     31.28     44.34 b     \n\ngeno = g3:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low  11.09 1.480 Inf      8.06     15.27 a     \n med  19.41 1.960 Inf     15.25     24.71 b     \n high 24.76 2.220 Inf     20.00     30.66 b     \n\ngeno = g4:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   6.93 1.170 Inf      4.63     10.38 a     \n med  13.87 1.660 Inf     10.42     18.45 b     \n high 44.57 2.980 Inf     38.00     52.28 c     \n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nIntervals are back-transformed from the log scale \nP value adjustment: sidak method for 3 tests \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=pests, x=N, col=N)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.6)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(position=position_jitterdodge(jitter.width = 0.1, jitter.height = 0, \n                                            dodge.width=0.6), shape=1, size=1)+\n  geom_point(data=CI2s, aes(y=rate), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI2s, aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI2s, aes(y = 60, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\nThe confidence intervals reflect nicely the data, in particular the wider spread with increasing mean.\n\nggplot(df, aes(y=pests, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n   geom_point(data=CI2s, aes(y=rate), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI2s, aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI2s, aes(y = 60, label =.group), col=1)+\n scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\n\nggplot(df, aes(y=pests, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n   geom_point(data=CI2s, aes(y=rate), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI2s, aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI2s, aes(y = 60, label =.group), col=1)+\n  scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")+\n  scale_y_sqrt(breaks=c(0,3,10,20,40,60))\n\n\n\n\n\n\n\n\nI prefer to scale the y-axis using square root or logarithmic intervals to better reflect the analysis (e.g., a GLM with a log link). This approach highlights differences in the lower range of values, making smaller effects more visible, while preventing higher values from dominating the presentation."
  },
  {
    "objectID": "Themen/09/09_2f_GLM.html#generalized-linear-mixed-effect-model-with-block-as-random-effect-glmmtmb",
    "href": "Themen/09/09_2f_GLM.html#generalized-linear-mixed-effect-model-with-block-as-random-effect-glmmtmb",
    "title": "Analysis of two-factorial experiments with generalised linear (mixed effect) models",
    "section": "Generalized linear mixed effect model with block as random effect (glmmTMB)",
    "text": "Generalized linear mixed effect model with block as random effect (glmmTMB)\n\nlibrary(glmmTMB)\nlibrary(car)\nmodel3 &lt;- glmmTMB(pests ~ geno * N + (1|block), data = df, family=\"poisson\")\nsummary(model3)\n\n Family: poisson  ( log )\nFormula:          pests ~ geno * N + (1 | block)\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   372.0    399.2   -173.0    346.0       47 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev.\n block  (Intercept) 0.01482  0.1217  \nNumber of obs: 60, groups:  block, 5\n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.1558     0.2559   4.517 6.28e-06 ***\ngenog2         0.8650     0.2980   2.902 0.003702 ** \ngenog3         1.2528     0.2835   4.419 9.90e-06 ***\ngenog4         0.7828     0.3018   2.594 0.009492 ** \nNmed           1.7707     0.2704   6.547 5.85e-11 ***\nNhigh          2.3807     0.2613   9.111  &lt; 2e-16 ***\ngenog2:Nmed   -1.3478     0.3416  -3.946 7.96e-05 ***\ngenog3:Nmed   -1.2111     0.3181  -3.807 0.000141 ***\ngenog4:Nmed   -1.0776     0.3406  -3.164 0.001557 ** \ngenog2:Nhigh  -0.7818     0.3161  -2.473 0.013381 *  \ngenog3:Nhigh  -1.5777     0.3068  -5.142 2.71e-07 ***\ngenog4:Nhigh  -0.5199     0.3183  -1.634 0.102328    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nAnova(model3)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: pests\n          Chisq Df Pr(&gt;Chisq)    \ngeno     4.7845  3     0.1883    \nN      330.8214  2  &lt; 2.2e-16 ***\ngeno:N  57.6457  6  1.352e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndrop1(model3, test=\"Chisq\")\n\nSingle term deletions\n\nModel:\npests ~ geno * N + (1 | block)\n       Df    AIC    LRT  Pr(&gt;Chi)    \n&lt;none&gt;    371.95                     \ngeno:N  6 421.71 61.751 1.982e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCI3s=cld(emmeans(model3, ~N|geno, type=\"response\"), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI3s$.group =gsub(\" \", \"\", CI3s$.group, fixed = TRUE)\nCI3s\n\ngeno = g1:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   3.18 0.813 Inf      1.72      5.85 a     \n med  18.66 2.180 Inf     14.12     24.66 b     \n high 34.35 3.210 Inf     27.47     42.95 c     \n\ngeno = g2:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   7.54 1.290 Inf      5.01     11.35 a     \n med  11.51 1.640 Inf      8.20     16.17 a     \n high 37.32 3.400 Inf     30.03     46.39 b     \n\ngeno = g3:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low  11.12 1.600 Inf      7.88     15.69 a     \n med  19.46 2.230 Inf     14.79     25.59 b     \n high 24.82 2.600 Inf     19.32     31.87 b     \n\ngeno = g4:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   6.95 1.230 Inf      4.55     10.62 a     \n med  13.90 1.830 Inf     10.15     19.02 b     \n high 44.67 3.850 Inf     36.36     54.87 c     \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nIntervals are back-transformed from the log scale \nP value adjustment: sidak method for 3 tests \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=pests, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n   geom_point(data=CI3s, aes(y=rate), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI3s, aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI3s, aes(y = 60, label =.group), col=1)+\n  scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")+\n  scale_y_sqrt(breaks=c(0,3,10,20,40,60))"
  },
  {
    "objectID": "Themen/09/09_2f_GLM.html#generalized-linear-mixed-effect-model-with-block-as-random-effect-lme4",
    "href": "Themen/09/09_2f_GLM.html#generalized-linear-mixed-effect-model-with-block-as-random-effect-lme4",
    "title": "Analysis of two-factorial experiments with generalised linear (mixed effect) models",
    "section": "Generalized linear mixed effect model with block as random effect (lme4)",
    "text": "Generalized linear mixed effect model with block as random effect (lme4)\n\nmodel4 &lt;- glmer(pests ~ geno * N + (1|block), data = df, family=\"poisson\")\nsummary(model4)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: pests ~ geno * N + (1 | block)\n   Data: df\n\n     AIC      BIC   logLik deviance df.resid \n   372.0    399.2   -173.0    346.0       47 \n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.88306 -0.79432  0.06297  0.53184  2.47315 \n\nRandom effects:\n Groups Name        Variance Std.Dev.\n block  (Intercept) 0.01483  0.1218  \nNumber of obs: 60, groups:  block, 5\n\nFixed effects:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    1.1555     0.2558   4.518 6.25e-06 ***\ngenog2         0.8653     0.2979   2.905 0.003673 ** \ngenog3         1.2530     0.2833   4.423 9.75e-06 ***\ngenog4         0.7832     0.3016   2.597 0.009411 ** \nNmed           1.7709     0.2703   6.552 5.68e-11 ***\nNhigh          2.3810     0.2612   9.117  &lt; 2e-16 ***\ngenog2:Nmed   -1.3481     0.3414  -3.949 7.86e-05 ***\ngenog3:Nmed   -1.2113     0.3179  -3.810 0.000139 ***\ngenog4:Nmed   -1.0780     0.3404  -3.167 0.001540 ** \ngenog2:Nhigh  -0.7821     0.3159  -2.476 0.013296 *  \ngenog3:Nhigh  -1.5780     0.3066  -5.146 2.66e-07 ***\ngenog4:Nhigh  -0.5204     0.3181  -1.636 0.101820    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) genog2 genog3 genog4 Nmed   Nhigh  gng2:Nm gng3:Nm gng4:Nm\ngenog2      -0.820                                                           \ngenog3      -0.862  0.740                                                    \ngenog4      -0.809  0.695  0.731                                             \nNmed        -0.903  0.776  0.815  0.766                                      \nNhigh       -0.935  0.803  0.844  0.793  0.884                               \ngenog2:Nmed  0.715 -0.872 -0.645 -0.606 -0.792 -0.700                        \ngenog3:Nmed  0.768 -0.659 -0.891 -0.651 -0.850 -0.752  0.673                 \ngenog4:Nmed  0.717 -0.616 -0.647 -0.886 -0.794 -0.702  0.629   0.675         \ngenog2:Nhgh  0.773 -0.943 -0.698 -0.655 -0.731 -0.827  0.823   0.622   0.581 \ngenog3:Nhgh  0.796 -0.684 -0.924 -0.675 -0.753 -0.852  0.596   0.823   0.598 \ngenog4:Nhgh  0.767 -0.659 -0.693 -0.948 -0.726 -0.821  0.575   0.617   0.840 \n            gng2:Nh gng3:Nh\ngenog2                     \ngenog3                     \ngenog4                     \nNmed                       \nNhigh                      \ngenog2:Nmed                \ngenog3:Nmed                \ngenog4:Nmed                \ngenog2:Nhgh                \ngenog3:Nhgh  0.704         \ngenog4:Nhgh  0.679   0.699 \n\nAnova(model4)\n\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: pests\n          Chisq Df Pr(&gt;Chisq)    \ngeno     4.7916  3     0.1877    \nN      331.2410  2  &lt; 2.2e-16 ***\ngeno:N  57.7201  6  1.306e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ndrop1(model4, test=\"Chisq\")\n\nSingle term deletions\n\nModel:\npests ~ geno * N + (1 | block)\n       npar    AIC    LRT   Pr(Chi)    \n&lt;none&gt;      371.95                     \ngeno:N    6 421.71 61.751 1.982e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nCI4s=cld(emmeans(model4, ~N|geno, type=\"response\"), method=\"pairwise\", adjust=\"sidak\", Letters=letters)\nCI4s$.group =gsub(\" \", \"\", CI4s$.group, fixed = TRUE)\nCI4s\n\ngeno = g1:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   3.18 0.812 Inf      1.72      5.85 a     \n med  18.66 2.180 Inf     14.13     24.65 b     \n high 34.35 3.210 Inf     27.47     42.94 c     \n\ngeno = g2:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   7.54 1.290 Inf      5.01     11.35 a     \n med  11.51 1.640 Inf      8.20     16.17 a     \n high 37.32 3.400 Inf     30.03     46.39 b     \n\ngeno = g3:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low  11.12 1.600 Inf      7.88     15.69 a     \n med  19.46 2.230 Inf     14.79     25.59 b     \n high 24.82 2.600 Inf     19.33     31.87 b     \n\ngeno = g4:\n N     rate    SE  df asymp.LCL asymp.UCL .group\n low   6.95 1.230 Inf      4.55     10.62 a     \n med  13.90 1.830 Inf     10.16     19.02 b     \n high 44.67 3.850 Inf     36.37     54.87 c     \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 3 estimates \nIntervals are back-transformed from the log scale \nP value adjustment: sidak method for 3 tests \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\n\nggplot(df, aes(y=pests, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n   geom_point(data=CI4s, aes(y=rate), \n             shape=16,  size=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CI4s, aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.2, position = position_nudge(x = 0.4))+\n  geom_text(data=CI4s, aes(y = 60, label =.group), col=1)+\n  scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")+\n  scale_y_sqrt(breaks=c(0,3,10,20,40,60))\n\n\n\n\n\n\n\n\n\nComparison of all 4 models\n\ncolnames(CIs)[1:8]&lt;-colnames(CI2s)\nCI.comp=rbind(CIs, CI2s, CI3s, CI4s)\nCI.comp$model=factor(rep(c(\"lm\", \"glm\", \"glmmTMB\",  \"glmer\"), each=12), levels = c(\"lm\", \"glm\", \"glmmTMB\",  \"glmer\"))\n\n\nggplot(data=CI.comp, aes(y=rate, x=N, col=model, group=model))+\n  geom_point(position=position_dodge(width=0.4))+\n  geom_errorbar(aes(y=rate, ymin=asymp.LCL, ymax=asymp.UCL), \n                width=0.4, \n                position=position_dodge(width=0.4))+\n  facet_grid(~geno)+\n  theme(legend.position=\"bottom\")\n\n\n\n\n\n\n\n\nConfidence intervals of\n\nlm negative\nlm constant across fitted values (does not represent natural behavior of count data)\nglm(m) do not differ much\n\nuse mixed effect models\n\nmany blocks and if you are not interested in block effect\ninterest in predictions without block effect\nrepeated measurements\nincomplete block design"
  },
  {
    "objectID": "Themen/09/09_2f_GLM.html#excercise",
    "href": "Themen/09/09_2f_GLM.html#excercise",
    "title": "Analysis of two-factorial experiments with generalised linear (mixed effect) models",
    "section": "Excercise",
    "text": "Excercise\nFit a model to explain pests.A and perform model diagnostics.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nggplot(df, aes(y=pests.A, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n    scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\nmodel.A=glmmTMB(pests.A ~ geno * N + block, data = df, family=\"poisson\")\nsummary(model.A)\n\n Family: poisson  ( log )\nFormula:          pests.A ~ geno * N + block\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   583.1    616.6   -275.6    551.1       44 \n\n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.31704    0.05744   75.16  &lt; 2e-16 ***\ngenog2        0.26321    0.06990    3.77 0.000166 ***\ngenog3        0.30887    0.06922    4.46 8.10e-06 ***\ngenog4        0.01915    0.07398    0.26 0.795731    \nNmed          0.43986    0.06739    6.53 6.72e-11 ***\nNhigh         0.84295    0.06286   13.41  &lt; 2e-16 ***\nblock2       -0.09133    0.03765   -2.43 0.015293 *  \nblock3        0.06989    0.03616    1.93 0.053242 .  \nblock4       -0.10176    0.03776   -2.70 0.007038 ** \nblock5       -0.06139    0.03736   -1.64 0.100394    \ngenog2:Nmed  -0.52860    0.09479   -5.58 2.45e-08 ***\ngenog3:Nmed  -0.26365    0.09094   -2.90 0.003744 ** \ngenog4:Nmed  -0.07026    0.09552   -0.74 0.462038    \ngenog2:Nhigh -0.22358    0.08496   -2.63 0.008495 ** \ngenog3:Nhigh -0.51113    0.08623   -5.93 3.07e-09 ***\ngenog4:Nhigh  0.07497    0.08800    0.85 0.394245    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model.A, plot = F)\ntestDispersion(simulationOutput)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 2.5578, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\n\nmodel.A=glmmTMB(pests.A ~ geno * N + block, data = df, family=\"nbinom2\")\nsummary(model.A)\n\n Family: nbinom2  ( log )\nFormula:          pests.A ~ geno * N + block\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   547.9    583.5   -257.0    513.9       43 \n\n\nDispersion parameter for nbinom2 family (): 69.8 \n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.31795    0.08443   51.14  &lt; 2e-16 ***\ngenog2        0.26287    0.10313    2.55 0.010810 *  \ngenog3        0.30753    0.10271    2.99 0.002752 ** \ngenog4        0.02115    0.10599    0.20 0.841812    \nNmed          0.44156    0.10145    4.35 1.34e-05 ***\nNhigh         0.84539    0.09852    8.58  &lt; 2e-16 ***\nblock2       -0.08873    0.06250   -1.42 0.155694    \nblock3        0.07517    0.06152    1.22 0.221738    \nblock4       -0.12482    0.06256   -2.00 0.046026 *  \nblock5       -0.05979    0.06226   -0.96 0.336893    \ngenog2:Nmed  -0.53126    0.14311   -3.71 0.000205 ***\ngenog3:Nmed  -0.26693    0.14063   -1.90 0.057689 .  \ngenog4:Nmed  -0.07079    0.14361   -0.49 0.622028    \ngenog2:Nhigh -0.21968    0.13679   -1.61 0.108287    \ngenog3:Nhigh -0.50813    0.13765   -3.69 0.000223 ***\ngenog4:Nhigh  0.07364    0.13874    0.53 0.595589    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model.A, plot = F)\ntestDispersion(simulationOutput)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 0.89791, p-value = 0.72\nalternative hypothesis: two.sided\n\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\n\n\n\nFit a model to explain pests.B and perform model diagnostics.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nggplot(df, aes(y=pests.B, x=N, col=N)) +\n  geom_point(shape=1, size=1.5)+\n    scale_color_manual(values=c(rgb(240,215,35, max = 255), \n                             rgb(190,210,35, max = 255), \n                              rgb(35,80,150, max = 255)                              ),\n                     limits = c(\"low\",\"med\", \"high\"))+\n  facet_grid(~geno, scales=\"free\", labeller = labeller(geno=label_both))+\n  theme_bw() +\n  theme(legend.position = \"none\")+\n  ylab(\"Number of pests per trap and 48h\")+\n  xlab(\"Nitrogen fertilisation\")\n\n\n\n\n\n\n\n\n\nmodel.B=glmmTMB(pests.B ~ geno * N + block, data = df, family=\"nbinom2\")\nsummary(model.B)\n\n Family: nbinom2  ( log )\nFormula:          pests.B ~ geno * N + block\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   589.4    625.0   -277.7    555.4       43 \n\n\nDispersion parameter for nbinom2 family (): 22.4 \n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.30165    0.12329   34.89  &lt; 2e-16 ***\ngenog2        0.26666    0.15099    1.77 0.077371 .  \ngenog3        0.18550    0.15205    1.22 0.222459    \ngenog4        0.02580    0.15311    0.17 0.866210    \nNmed          0.44259    0.14981    2.95 0.003134 ** \nNhigh         0.85157    0.14793    5.76 8.58e-09 ***\nblock2       -0.02200    0.09566   -0.23 0.818104    \nblock3        0.07735    0.09497    0.81 0.415397    \nblock4       -0.12953    0.09551   -1.36 0.175042    \nblock5       -0.06121    0.09579   -0.64 0.522836    \ngenog2:Nmed  -0.53444    0.21161   -2.53 0.011549 *  \ngenog3:Nmed  -0.39042    0.21220   -1.84 0.065784 .  \ngenog4:Nmed  -0.06973    0.21197   -0.33 0.742202    \ngenog2:Nhigh -0.22383    0.20740   -1.08 0.280489    \ngenog3:Nhigh -0.74386    0.21080   -3.53 0.000417 ***\ngenog4:Nhigh  0.06699    0.20879    0.32 0.748319    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model.B, plot = F)\ntestDispersion(simulationOutput)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 0.73908, p-value = 0.168\nalternative hypothesis: two.sided\n\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\n\nmodel.B1=glmmTMB(pests.B ~ geno * N + block, \n                 dispformula=~geno, data = df, family=\"nbinom2\")\nsummary(model.B1)\n\n Family: nbinom2  ( log )\nFormula:          pests.B ~ geno * N + block\nDispersion:               ~geno\nData: df\n\n     AIC      BIC   logLik deviance df.resid \n   568.2    610.1   -264.1    528.2       40 \n\n\nConditional model:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   4.31621    0.09452   45.67  &lt; 2e-16 ***\ngenog2        0.26437    0.10217    2.59 0.009667 ** \ngenog3        0.18128    0.19762    0.92 0.358992    \ngenog4        0.02155    0.11058    0.19 0.845508    \nNmed          0.44180    0.11649    3.79 0.000149 ***\nNhigh         0.84560    0.11397    7.42 1.18e-13 ***\nblock2       -0.07315    0.06582   -1.11 0.266459    \nblock3        0.05245    0.06453    0.81 0.416325    \nblock4       -0.11103    0.06528   -1.70 0.088952 .  \nblock5       -0.05801    0.07500   -0.77 0.439288    \ngenog2:Nmed  -0.53088    0.14169   -3.75 0.000179 ***\ngenog3:Nmed  -0.38185    0.27739   -1.38 0.168649    \ngenog4:Nmed  -0.07132    0.15030   -0.47 0.635145    \ngenog2:Nhigh -0.22298    0.13533   -1.65 0.099432 .  \ngenog3:Nhigh -0.74073    0.27629   -2.68 0.007341 ** \ngenog4:Nhigh  0.07312    0.14568    0.50 0.615705    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nDispersion model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   3.7929     0.5878   6.453  1.1e-10 ***\ngenog2        1.4763     1.1278   1.309  0.19054    \ngenog3       -1.8739     0.7011  -2.673  0.00752 ** \ngenog4        0.7112     1.1171   0.637  0.52436    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsimulationOutput &lt;- simulateResiduals(fittedModel = model.B1, plot = F)\ntestDispersion(simulationOutput)\n\n\n\n\n\n\n\n\n\n    DHARMa nonparametric dispersion test via sd of residuals fitted vs.\n    simulated\n\ndata:  simulationOutput\ndispersion = 0.94674, p-value = 0.936\nalternative hypothesis: two.sided\n\nplot(simulationOutput)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$geno)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$N)\n\n\n\n\n\n\n\nplotResiduals(simulationOutput, form = df$block)\n\n\n\n\n\n\n\n\nCompare models by AICc. The lower the better.\n\nlibrary(bbmle)\nAICctab(model.B, model.B1, base=T)\n\n         AICc  dAICc df\nmodel.B1 589.8   0.0 20\nmodel.B  603.9  14.1 17"
  },
  {
    "objectID": "Themen/10/Einfuehrung_in_R_Markdown_V03.html",
    "href": "Themen/10/Einfuehrung_in_R_Markdown_V03.html",
    "title": "Einführung in R Markdown",
    "section": "",
    "text": "https://raw.githubusercontent.com/rstudio/cheatsheets/main/translations/german/rmarkdown_de.pdf https://posit.co/wp-content/uploads/2022/10/rmarkdown-1.pdf https://bookdown.org/yihui/rmarkdown-cookbook/"
  },
  {
    "objectID": "Themen/10/Einfuehrung_in_R_Markdown_V03.html#überschrift-2",
    "href": "Themen/10/Einfuehrung_in_R_Markdown_V03.html#überschrift-2",
    "title": "Einführung in R Markdown",
    "section": "Überschrift 2",
    "text": "Überschrift 2\n\nÜberschrift 3\n\nÜberschrift 4\n\nÜberschrift 5\n\nÜberschrift 6\nFormeln \\(A = \\pi*r^{2}\\)\n\n\n\n\n\n\nListe erstellen\n\nListe 1\nListe 2\nListe 3\n\nListe 3.1\nListe 3.2\n\n\n\n\nnummerierte Liste\n\nPunkt 1\nPunkt 2\n\nPunkt 2.1\nPunkt 2.2\n\n\n\n\nTabelle erstellen\n\n\n\nTabÜ\nTabÜ2\n\n\n\n\nInhalt 1\nInhalt 2\n\n\nInhalt 1.2\nInhalt 2.2\n\n\n\n\n\nBild einfügen\n\n\n\nSeitenumbruch"
  }
]