---
title: "ANOVA"
---

```{r, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, error= TRUE, message=FALSE, comment = NA, options(Encoding="UTF-8"))
```

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(ggpubr)
library(ggfortify)
library(stringr)
```

### Unterscheiden sich die Gruppen?

```{r, echo=FALSE, fig.width=6.5, fig.height=3.5, message=F, warning=FALSE}
n=1000
set.seed(12345)
dat=data.frame(Y=c(rnorm(n, 10, 2), rnorm(n, 20, 2), rnorm(n, 10, 5), rnorm(n, 20, 5), 
                   rnorm(n, 10, 5), rnorm(n, 30, 5)), 
               Behandlung=rep(c("A","B"), each=n, times=3), 
               Experiment=factor(rep(c("Exp 1", "Exp 2", "Exp 3"), each=2*n)))
dat2=dat %>% 
  group_by(Behandlung, Experiment) %>% 
  summarize(min=min(Y), 
            max=max(Y), 
            sd=sd(Y), 
            mean=mean(Y)) 
dat2$Y=0.22
ggplot(data=dat, aes(colour=Behandlung, fill=Behandlung)) + 
  geom_density(aes(Y), adjust=1, alpha=.2)+
  geom_errorbarh(data=dat2, aes(y=Y, x=0, xmax = mean+sd, xmin = mean-sd, height = .01))+
  geom_point(data=dat2, aes(y=Y, x=mean))+
  facet_grid(~Experiment)+
  coord_cartesian(ylim=c(0,0.23))+
  theme(legend.position = "none")

ggplot(data=dat, aes(y=Y, x=Behandlung, colour=Behandlung)) + 
  geom_boxplot()+
#+
  #geom_errorbarh(data=dat2, aes(y=Y, x=0, xmax = mean+sd, xmin = mean-sd, height = .01))+
 # geom_point(data=dat2, aes(y=Y, x=mean))+
  facet_grid(~Experiment)+
  #coord_cartesian(ylim=c(0,0.23))+
  theme(legend.position = "none")
```

```{r results='asis', echo=F}
knitr::kable(dat %>% 
  group_by(Experiment,Behandlung ) %>% 
  summarize(MW=round(mean(Y),0), SD=round(sd(Y),1), N=length(Y)))
```

### Beispieldaten ANOVA in Anlehnung an Carsten Dormann "Parametrische Statistik" S. 191ff

```{r, echo=FALSE, message=FALSE, fig.width=6.5, fig.height=3.5}

dat=data.frame(AZ=c(5,8,7,9,9,12,23,15,18,20), Pos= c(seq(0.7,1.3, length=5), seq(1.7,2.3, length=5)), Gruppe= rep(c("A", "B"), each=5))
dat=dat %>% group_by(Gruppe) %>% mutate(AZ.m = mean(AZ), min=min(Pos), max=max(Pos))
p1=ggplot(dat, aes(x=Pos, y=AZ, colour=Gruppe)) +
  geom_segment(aes(x=Pos, xend=Pos, y=AZ, yend=mean(AZ)), linewidth=1, data=dat, colour="grey70") +
  geom_hline(yintercept = mean(dat$AZ), colour="grey70") + 
  geom_point(size=2)+ 
  ggtitle("SS Total")+
  scale_x_continuous(breaks=c(1,2), labels=levels(dat$Gruppe), name ="Behandlung")

p2=ggplot(dat, aes(x=Pos, y=AZ, colour=Gruppe)) +
  geom_segment(aes(x=Pos, xend=Pos, y=AZ.m, yend=mean(AZ), colour=Gruppe), linewidth=1, data=dat) +
  geom_segment(aes(x=min, xend=max, y=AZ.m, yend=AZ.m, colour=Gruppe), linewidth=1, data=dat) +
  geom_hline(yintercept = mean(dat$AZ), colour="grey70") + 
  geom_point(size=2)+ 
  ggtitle("SS Effekt")+
  scale_x_continuous(breaks=c(1,2), labels=levels(dat$Gruppe), name ="Behandlung")

p3=ggplot(dat, aes(x=Pos, y=AZ, colour=Gruppe)) +
  geom_segment(aes(x=Pos, xend=Pos, y=AZ, yend=AZ.m), linewidth=1, data=dat, colour="grey70") +
  geom_segment(aes(x=min, xend=max, y=AZ.m, yend=AZ.m, colour=Gruppe), linewidth=1, data=dat) +
  geom_point(size=2)+
  ggtitle("SS Residuen")+
  scale_x_continuous(breaks=c(1,2), labels=levels(dat$Gruppe), name ="Behandlung")
ggarrange(p1, p2, p3, labels = c("A", "B", "C"), nrow=1, ncol=3, common.legend = F, legend = "none")

```

A)  Gesamtvarianz der Daten = Abweichungsquadrate zum Gesamtmittelwert = SS Total
B)  Abweichungsquadrate der Gruppen zum Gesamtmittelwert = SS Effekt
C)  Abweichungsquadrate zum Mittelwert der beiden Gruppen = SS Residuen

SS~Total~ = SS~Effekt~ + SS~Residuen~\
F-Wert = (SS~Effekt~/df~Effekt~)/(SS~Residuen~/df~Residuen~)

df~Effekt~ = k-1, wobei k die Anzahl der Gruppen (Faktorlevels) ist\
df~Residuen~ = n-k, wobei n der Stichprobenumfang ist

F-Wert = MS~Effekt~/MS~Residuen~

aus dem F-Wert und den `degrees of freedom` resultiert dann der p-Wert

R² = SS~Effekt~/SS~Total~ \* 100

entsprechend können *signifikante Unterschiede* verschiedene Ursachen haben:

-   große Mittelwertsdifferenzen zwischen den Gruppen (hohe SS~Effekt~)
-   geringe Variabilität innerhalb der Gruppen (niedrige SS~Residuen~)
-   hoher Stichprobenumfang bzw. Anzahl Wiederholungen je Gruppe (erhöht df~Residuen~ und senkt damit MS~Residuen~)

Varianzanalyse (*Analysis of Variance*)

-   `mod<-aov(Abhängige ~ Erklärungsvariable, data=md)`
-   Abhängige ist kontinuierlich
-   Erklärungsvariable ist ein Faktor

Voraussetzungen:

-   zufällige Stichprobennahme (unabhängige Fehler)
-   Varianzhomogenität/Homoskedastizität
-   annähernde Normalverteilung der Fehler (Residuen), und **nicht** der Abhängigen!

## Beispiel ANOVA Proteingehalt

Die Proteingehalte von jeweils 8 zufällig ausgewählten Weizenproben der 4 Qualitätsklassen E, A, B und C wurden ermittelt. Unterscheiden sich die Qualitätsklassen im Proteingehalt?

```{r, echo=F, eval=F}
n=8
set.seed(12345)
md=data.frame( ID=1:(n*4),
               Quali=rep(c("E","A","B","C"), each=n),
               Prot=c(rnorm(n, 14.5, 1.5), rnorm(n, 13.0, 1.5), 
                      rnorm(n, 12.2, 1.5), rnorm(n, 11, 1.5)))
#md
library(openxlsx)
write.xlsx(md, "Protein.xlsx")
```

## Daten einlesen, kennenlernen und plotten

[Protein.xlsx](https://github.com/DoreenGabriel/Kurs/blob/main/Themen/04/Protein.xlsx){target="_blank"}

```{r}
library(openxlsx)
md<-read.xlsx("Protein.xlsx")
```

### Struktur der eingelesenen Daten überprüfen

```{r}
str(md)
unique(md$Quali)
md$Quali=as.factor(md$Quali)# Erklärungsvariable muss als Faktor deklariert sein
levels(md$Quali)
```

### Daten plotten (Ausreißer, Eingabefehler, Varianzhomogenität visuell überprüfen)

```{r}
ggplot(md, aes(x=Quali, y=Prot)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA) +
  geom_jitter(width=0.25, height=0, shape=1)+
  stat_summary(fun = "mean", colour = "red", size = 2, geom = "point") 
```

## Modell formulieren

Wichtig ist, dass die Abhängige kontinuierlich und die Erklärungsvariable ein Faktor ist.

```{r}
mod<-lm(Prot ~ Quali, data=md) # Prot ist die Abhängige, Quali die Erklärungsvariable
anova(mod)
```

`Quali` hat einen signifikanten Effekt auf den Proteingehalt.

Mit der Funktion `summary()`können wir die geschätzten Effekte sehen.

```{r}
summary(mod) 
```

Bevor wir hier aber ins Detail gehen, müssen wir zunächst eine Modelldiagnostik durchführen. 

::: {.callout-tip collapse="true"}
### alternative Funktion aov

... gelangt zu den gleichen Ergebnissen und wird hier lediglich der Vollständigkeit halber erwähnt.

```{r}
mod.a<-aov(Prot ~ Quali, data=md) # 
summary(mod.a)
summary.lm(mod.a)
```
::: 


## Modelldiagnostik

Wir überprüfen die Annahmen der ANOVA visuell auf:

-   annähernde Normalverteilung der Fehler (i.e. Residuen)
-   Varianzhomogenität

Ich nutze hierfür die `library(DHARMa)`.

[https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html){target="_blank"}

```{r}
library(DHARMa)
simulationOutput <- simulateResiduals(fittedModel = mod, plot = F)
plot(simulationOutput)
```

-   Die erste Grafik zeigt einen QQ-Plot der standardisierten `Residuen`, der uns Informationen über die Normalverteilung der Residuen liefert. Wenn die Punkte ungefähr entlang der Winkelhalbierenden (rote Linie) liegen, deutet dies darauf hin, dass die Residuen approximativ normalverteilt sind. Außerdem werden uns p-Werte für den KS-Test (Kolmogorov-Smirnov-Test auf Normalverteilung), ein Dispersion- und Ausreißertest angezeigt.

-   Die zweite Grafik plottet die `Residuen` gegen die `Fitted Values`. Wir wollen hier sehen, dass die Streuung um die 0.5 sowohl bei hohen als auch bei niedrigen Werten in etwa gleich ist (**Varianzhomogenität**). Hier scheint ein leichter Trend vorzuliegen (ist aber m.E. noch ok). Der Plot ist auch hilfreich zum Identifizieren von auffälligen Stichproben. Diese werden als rote Sternchen abgebildet (müssen aber noch nicht zwingend als Ausreißer bezeichnet werden).

-   Um die Varianzhomogenität zwischen den Gruppen zu prüfen, sollten wir die Residuen gegen die Erklärungsvariablen plotten.

```{r}
plotResiduals(simulationOutput, form = md$Quali)
```

Solange alle Tests nicht signifikant sind (und keine roten Linien oder Boxen angezeigt werden), ist alles (mehr oder weniger) gut. ABER es sei angemerkt, dass die Teststärke (Power) der Tests von der Anzahl der Beobachtungen abhängt. Je mehr Beobachtungen wir haben, umso höher ist die Power des Tests. Damit werden häufig signifikante Unterschiede z.B. der Varianzen bei großem Stichprobenumfang beobachtet, obwohl diese praktisch nicht relevant sind. Außerdem werden häufig keine signifikanten Unterschiede bei kleinem Stichprobenumfang beobachtet, obwohl gravierende Unterschiede vorhanden sind.

Die *visuelle* Modelldiagnostik wird daher häufig als wichtiger angesehen als die p-Wert-basierten Tests auf Normalverteilung und Varianzhomogenität (Cochran, Bartlett und Levenes Test).

::: {.callout-tip collapse="true"}
### Tests auf Varianzhomogenität

```{r, message=FALSE}

var.test(md$Prot[md$Quali=="E"], md$Prot[md$Quali=="B"] )
bartlett.test(Prot ~ Quali, data=md)
library(car)
leveneTest(Prot ~ Quali, data=md) 
library(outliers)
cochran.test(Prot ~ Quali, data=md)
```
:::

In unserem Beispiel ist alles ok. Sowohl visuell als auch nach Aussage der Tests.

#### Hier ein Beispiel für Varianzheterogenität mit veränderten Daten.

```{r}
md$Prot2= md$Prot
set.seed(1309)
md$Prot2[md$Quali=="E"] =rnorm(8, 14.5, 13)
ggplot(md, aes(x=Quali, y=Prot2)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA) +
  geom_jitter(width=0.25, height=0, shape=1)+
  stat_summary(fun = "mean", colour = "red", size = 2, geom = "point") 
```

```{r}
mod2<-lm(Prot2 ~ Quali, data=md)
simulationOutput <- simulateResiduals(fittedModel = mod2, plot = F)
plot(simulationOutput)
plotResiduals(simulationOutput, form = md$Quali)
```

Die Residuen weisen eine größere Streuung mit größer werdenden `fitted values` auf bzw. unterscheiden sich die Varianzen der Gruppen. Um dem entgegenzuwirken, könnten wir 1.) entweder die Analyse mit transformierten Daten vornehmen oder 2.) *besser* einen Funktion anwenden, die die unterschiedliche Varianz in den Gruppen berücksichtigt oder 3.) ein Generalisertes Lineares Modell anwenden, welches die Verteilungsannahme der abhängigen Variable berücksichtigt - denn häufig weisen bspw. Zähldaten eine größere Streuung mit größer werdenden `fitted values` auf. Siehe dazu [Analysis of two-factorial experiments with generalised linear (mixed effect) models](https://doreengabriel.github.io/Kurs/Themen/09/09_2f_GLM.html){target="_blank"} 

## Modellinterpretation

Zurück zu unserem Modell, bei dem die Modelldiagnostik keine Auffälligkeiten zeigte. 

```{r}
summary(mod) 
```

-   R² ist `r round(summary.lm(mod)$r.sq*100,1)` %. Adjusted R² ist `r round(summary.lm(mod)$adj.r.sq*100,1)` %.
-   Hinter dem Intercept verbirgt sich das erste Level von `Quali`, i.e. `A`. `A` hat demnach einen geschätzten mittleren Proteingehalt von `r round(coef(mod)[1],1)`.
-   Um den geschätzten mittleren Proteingehalt für `B` zu ermitteln, müssen wir Intercept + Estimate `QualiB` rechnen, d.h. `r round(coef(mod)[1],1)` `r round(coef(mod)[2],1)` = `r round(coef(mod)[1]+coef(mod)[2],1)`
-   Um den geschätzten mittleren Proteingehalt für `C` zu ermitteln, müssen wir Intercept + Estimate `QualiC` rechnen, d.h. `r round(coef(mod)[1],1)` `r round(coef(mod)[3],1)` = `r round(coef(mod)[1]+coef(mod)[3],1)`
-   und für `E` Intercept + Estimate `QualiE`: `r round(coef(mod)[1],1)` + `r round(coef(mod)[4],1)` = `r round(coef(mod)[1]+coef(mod)[4],1)`

### Post-hoc Test

Die ANOVA hat einen signifikanten Effekt von `Quali` auf `Prot` gezeigt. Allerdings wissen wir nicht, welche Weizenqualitätsklassen sich voneinander unterscheiden. Bei Faktoren mit mehr als zwei Ausprägungen wird daher ein Post-hoc Test durchgeführt. Dieser korrigiert die Irrtumswahrscheinlichkeit um die Anzahl der Vergleiche, da bei beispielsweise 100 Ausprägungen schon rein zufällig fünf signifikante Unterschiede auftreten können.

### Bespiel für multiples Testen ohne und mit Adjustierung des p-Wertes

```{r}
pairwise.t.test(md$Prot, md$Quali, p.adj = "none") # p-Werte werden nicht korrigiert, nicht gut! 

# Bonferroni-Korrektur (Bonferroni multipliziert p mit der Anzahl Tests, sehr konservativ)
pairwise.t.test(md$Prot, md$Quali, p.adj = "bonferroni") # besser
```

### Post-hoc Test: package `emmeans`

Die `library(emmeans)` mit der Funktion `emmeans()` bietet eine Vielzahl an Möglichkeiten um einen Post-hoc Test am gefitteten Modell (hier die ANOVA) durchzuführen. Mit dem Argument `method="pairwise"` kann man alle Behandlungen miteinander per Tukey-Test vergleichen, i.e. paarweise.

```{r, message=FALSE, warning=FALSE}
library(emmeans)
contrast(emmeans(mod, ~Quali), method="pairwise")
```

Mit `method="trt.vs.ctrl"` wird ein Dunnett-Test durchgeführt, der alle Behandlungen gegen **eine** Kontrolle testet. Die p-Werte werden automatisch um die Anzahl der Tests korrigiert.

```{r, message=FALSE, warning=FALSE}
contrast(emmeans(mod, ~Quali), method="trt.vs.ctrl")
```

Hier wird immer gegen die Qualität A geprüft, weil diese das erste Level der Variable `Quali` ist.

Mit dem Argument `ref` kann ich ein anderes Level wählen. Hier die E-Qualität.

```{r, message=FALSE, warning=FALSE}
contrast(emmeans(mod, ~Quali), method="trt.vs.ctrl", ref=4)
```

Alternativ kann ich bereits im `data.frame` die Faktorenlevels entsprechend meiner Interpretation ändern und damit das Modell anpassen. (siehe dazu Reihenfolge ändern in Kap. Grafik)

Interessant sind auch die Konfidenzintervalle. Wenn Konfidenzintervalle sich nicht überlappen, geht man in der Regel von signifikanten Unterschieden aus. Es kann auch sein, dass Konfidenzintervalle leicht überlappen, und trotzdem signifikante Unterschiede vorliegen. [https://core.ac.uk/download/pdf/82702323.pdf](https://core.ac.uk/download/pdf/82702323.pdf){target="_blank"} Hier sollte man immer auf die p-Werte des Tests schauen.

```{r, fig.height=3, fig.width=4}
summary(emmeans(mod, ~Quali)) #Konfidenzintervalle
plot(emmeans(mod, ~Quali))
```

Um Gruppenunterschiede leicht verständlich anzugeben bzw. zu visualisieren, kann das *compact letter display* genutzt werden. Hierfür benötigen wir die `library(multcompView)` und `library(multcomp)`.

```{r, message=FALSE}
library(multcompView)
library(multcomp)
cld(emmeans(mod, ~Quali), adjust="sidak", Letters=letters) # Compact letter display für Gruppenunterschiede 
```

Gruppen, die keinen Buchstaben gemeinsam haben, sind im Mittelwert signifikant unterschiedlich. Qualitätsklasse `E` hat einen signifikant höheren Proteingehalt im Vergleich zu `B` und `C`, während `E` und `A` sich nicht signifikant unterscheiden.

## Präsentation der Ergebnisse

So könnte man die Daten und die Ergebnisse des Modells präsentieren. Ich speichere die geschätzten Mittelwerte und das Konfidenzintervall als Objekt `CIs` und plotte diese neben die jittered Boxplots der Gruppen. Das Einzeichnen der Buchstaben muss nicht sein. Der Vollständigkeit halber soll es hier aber gezeigt werden.

```{r}
CIs=cld(emmeans(mod, ~Quali), adjust="sidak", sort = FALSE, Letters=letters)
CIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert
CIs$.group =gsub(" ", "", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen
CIs$.group # besser
str(CIs)
ggplot(md, aes(x=Quali, y=Prot)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA, width = 0.6) +
  geom_jitter(width=0.25, height=0, shape=1)+
  geom_point(data=CIs, aes(y=emmean), 
             shape=16,  size=2, col=2, 
             position = position_nudge(x = 0.4))+
  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), 
                width=0.1, col=2, position = position_nudge(x = 0.4))+
  geom_text(data=CIs, aes(y = 17, label =.group))+
  scale_y_continuous(labels=scales::number_format(accuracy = 0.01, 
                                                  decimal.mark =","))+
  theme_bw() +
  ylab("Proteingehalt %")+
  xlab("Qualitätsklasse")
```

Im Text sollte man erwähnen, dass

-   `Quali` einen signifikanten Einfluss auf `Prot` hat. Nutze die Funktion `anova(mod)` und gibt den p-Wert zusammen mit den `degrees of freedom` und `F-Wert` an.
-   der Post-hoc Test gezeigt hat, dass `E` mit im Mittel `r round(CIs$emmean[CIs$Quali=="E"],1)` % einen signifikant höheren Proteingehalt hatte als `B` und `C` mit `r round(CIs$emmean[CIs$Quali=="B"],1)` % und `r round(CIs$emmean[CIs$Quali=="C"],1)` % , während `E` und `A` sich nicht unterscheiden. Die Proteingehalte von `A`, `B` und `C` unterscheiden sich nicht signifikant (p\>0.05). Hierzu nutzt du die Funktion `contrast(emmeans(mod, c("Quali")), method="pairwise")`.
-   das R² des Modells `r round(summary(mod)$r.sq*100,1)` beträgt. `summary(mod)$r.sq`
-   die Modellannahmen für die ANOVA (Varianzhomogenität und annähernde Normalverteilung der Residuen) visuell mit dem Paket `DHARMa` überprüft wurden.



### add on: Unterschiede zu einer Kontrolle darstellen (absolut)

Wie bereits erwähnt, können wir durch geeignete Modellinterpretation alle Behandlungen gegen eine bestimmte Kontrollgruppe testen. Nehmen wir an, die Qualität C sei unsere Standardqualität und wir möchten die Unterschiede der übrigen Qualitäten im Vergleich zu C quantifizieren. 
Dies lässt sich mit `method="trt.vs.ctrl"` umsetzen, wobei wir über das Argument `ref` die gewünschte Kontrollgruppe – in diesem Fall die C-Qualität – festlegen. Mit dem Argument `infer=c(T,T)` wird das 95%-Konfidenzintervall für die Unterschiede zwischen den Gruppen berechnet.

```{r}
contrast(emmeans(mod, ~Quali),  method="trt.vs.ctrl", ref="C", infer=c(T,T))
```

Das Ergebnis wird als `data.frame` `CI.con` gespeichert.

```{r}
CI.con=data.frame(contrast(emmeans(mod, ~Quali), method="trt.vs.ctrl", ref="C", infer=c(T,T)))
CI.con
```

Im nächsten Schritt wird zur besseren Visualisierung die Information aus die Spalte `contrast` aufbereitet und in eine neue Spalte `contrast2` geschrieben: Aus den Namen wie `E - C` oder `A - C` wird das ` - C` entfernt. Gleichzeitig wird mit `levels=c("E","A","B")` eine gewünschte Reihenfolge der Gruppen festgelegt. 

```{r}
CI.con$contrast2=factor(str_replace_all(CI.con$contrast, " - C", ""), levels=c("E", "A", "B"))
CI.con
```



```{r}
ggplot(data=CI.con, aes(y=estimate, x=contrast2))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL), width=0.1)+
  geom_point(size=3)+
  coord_flip()+
  theme_bw() +
  ylab("Differenz im mittleren Proteingehalt und 95%-Konfidenzintervall \n im Vergleich zur C-Qualität")+
  scale_x_discrete(limits=rev, name="Qualitätsklasse")
```

Die Grafik zeigt die geschätzten Differenzen im mittleren Proteingehalt der Qualitätsklassen `E`, `A` und `B` im Vergleich zur Referenz `C`, jeweils mit 95%-Konfidenzintervallen. Die gestrichelte Linie markiert den Referenzwert (kein Unterschied zu `C`).


### add on: Unterschiede zu einer Kontrolle darstellen (Cohen’s d)

Um die Größenordnung der Unterschiede zur C-Qualität unabhängig von der absoluten Skala der Messwerte zu veranschaulichen, können wir Cohen’s d-ähnliche Effektstärken berechnen.
**Cohen’s d** ist eine **standardisierte Effektgröße**, die den Unterschied zweier Mittelwerte ins Verhältnis zur Streuung setzt. Mit der Funktion `eff_size` kann Cohen’s d aus dem Modell berechnet werden, d.h. aus den geschätzten Mittelwerten und der geschätzten Residual-Standardabweichung. 

Mit `sigma = sigma(mod)` und `edf = df.residual(mod)` werden die Residual-Standardabweichung und die geschätzten Freiheitsgrade aus dem Modell übergeben. 

```{r}
eff_size(emmeans(mod, ~Quali), sigma = sigma(mod), edf = df.residual(mod), 
                        method = "trt.vs.ctrl", ref = "C")
```
Prinzipiell gilt für Cohen`s d: 

+ kleiner Effekt: d ≈ 0.2
+ mittlerer Effekt: d ≈ 0.5
+ großer Effekt: d ≈ 0.8

Für obiges Beispiel bedeutet das: 

+ `A` zeigt einen großen, aber statistisch unsicheren Effekt (das Konfidenzintervall schließt die 0 mit ein).
+ `B` zeigt nur einen kleinen, statistisch unsicheren Effekt.
+ `E` unterscheidet sich klar und deutlich von `C` (großer, signifikanter Effekt, das Konfidenzintervall liegt vollständig über 0).


### add on: Unterschiede zu einer Kontrolle darstellen (prozentual)

Um die Unterschiede zu einer Referenzgruppe anschaulicher darzustellen, können die Mittelwertsdifferenzen **prozentual** zur C-Qualität angegeben werden. So wird sichtbar, um wie viel Prozent die anderen Qualitätsklassen vom Standard abweichen.

Prozentuale Unterschiede sind oft intuitiver verständlich als Rohwerte oder standardisierte Effektgrößen. Sie sind insbesondere für Präsentationen oder für praxisorientierte Zielgruppen (z. B. Landwirte, Praktiker) besser geeignet. Auch beim Vergleich unterschiedlicher Messgrößen (z. B. Proteingehalt, Gewicht, usw) in Relation zur Behandlung kann die Berechnung der prozentualen Unterschiede eine gute Grundlage für die Interpretation liefern. 

Zu beachten ist jedoch, dass prozentuale Änderungen immer relativ zur Referenz zu interpretieren sind. Sind diese sehr klein, können die Prozentwerte stark verzerrt werden. Daher empfiehlt es sich, immer auch die geschätzten Werte (`emmeans`) oder Rohdifferenzen (wie oben) anzugeben.  



```{r}
emm1=data.frame(emmeans(mod, ~Quali))
emm1
C.p=emm1$emmean[emm1$Quali=="C"]
C.p
```

Hier werden die geschätzten Mittelwerte der Qualitätsklassen berechnet und der Mittelwert der C-Qualität (`C.p`) als Referenz gespeichert.

```{r}
CI.con
CI.con$p.change=CI.con$estimate/C.p*100
CI.con$p.change.low=CI.con$lower.CL/C.p*100
CI.con$p.change.up=CI.con$upper.CL/C.p*100
CI.con
```

Die absoluten Differenzen zu C werden in prozentuale Abweichungen umgerechnet. Neben dem Schätzwert (`p.change`) werden auch die unteren (`p.change.low`) und oberen (`p.change.up`) Konfidenzgrenzen in Prozent berechnet.

```{r}
ggplot(data=CI.con, aes(y=p.change, x=contrast2))+
  geom_hline(yintercept=0, linetype="dashed")+
  geom_errorbar(aes(ymin=p.change.low, ymax=p.change.up), width=0.1)+
  geom_point(size=3)+
  coord_flip()+
  theme_bw() +
  ylab("prozentualer Unterschied im mittleren Proteingehalt und 95%-Konfidenzintervall \n im Vergleich zur C-Qualität")+
  scale_x_discrete(limits=rev, name="Qualitätsklasse")#+  xlab()
```

### add on: Faktorlevels in Grafik umsortieren

Zurück zu unseren emmeans und Originaldaten: Schön wäre es, die Qualitäten in absteigender Reihenfolge darzustellen. E steht für Elite und ist die beste Qualität.

```{r}
library(forcats)
md %>% 
ggplot(aes(x=fct_relevel(Quali, "E"), y=Prot)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA, width = 0.6) +
  geom_jitter(width=0.25, height=0, shape=1)+
  geom_point(data=CIs, aes(y=emmean), 
           shape=16,  size=2, col=2, 
             position = position_nudge(x = 0.4))+
  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), 
                width=0.1, col=2, position = position_nudge(x = 0.4))+
  geom_text(data=CIs, aes(y = 20, label =.group))+
  theme_bw()
```

oder in aufsteigender Reihenfolge, basierend auf den Messwerten.

```{r}
CIs$Prot=CIs$emmean
md %>% 
ggplot(aes(x=fct_reorder(Quali, Prot), y=Prot)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA, width = 0.6) +
  geom_jitter(width=0.25, height=0, shape=1)+
  geom_point(data=CIs, aes(y=emmean), 
           shape=16,  size=2, col=2, 
             position = position_nudge(x = 0.4))+
  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), 
                width=0.1, col=2, position = position_nudge(x = 0.4))+
  geom_text(data=CIs, aes(y = 20, label =.group))+
  theme_bw() 
```

## Übung 4

In einem Gefäßversuch wurde die pflanzenliche Biomasse (`BM`) in den 4 Düngemittelvarianten (`DM`: Kontrolle, Düngemittel A, B und C) an jeweils 10 Proben gemessen.

```{r, eval=FALSE, echo=F}
n=10
set.seed(12345)
g=data.frame( ID=1:(n*4),
               DM=factor(rep(c("K","A","B","C"), each=n)),
               BM=c(rnorm(n, 10, 1.5), rnorm(n, 11.0, 1.5), 
                      rnorm(n, 14, 1.5), rnorm(n, 18, 1.5))^2)
write.xlsx(g, "Gefaessversuch.xlsx")
```

-   Importiere bitte die Daten [Gefaessversuch.xlsx](https://github.com/DoreenGabriel/Kurs/blob/main/Themen/04/Gefaessversuch.xlsx){target="_blank"} in R und mach Dich mit dem Datensatz vertraut.

::: {.callout-tip collapse="true"}
### Daten einlesen und prüfen

```{r}
library(openxlsx)
g<-read.xlsx("Gefaessversuch.xlsx")
str(g)
```

```{r}
ggplot(g, aes(x=DM, y=BM)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA) +
  geom_jitter(width=0.25, height=0, shape=1)+
  stat_summary(fun = "mean", colour = "red", size = 2, geom = "point") 
```

wir können die Kontrolle als erstes Level definieren.

```{r}
g$DM=fct_relevel(g$DM, "K")
ggplot(g, aes(x=DM, y=BM)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA) +
  geom_jitter(width=0.25, height=0, shape=1)+
  stat_summary(fun = "mean", colour = "red", size = 2, geom = "point") 
```
:::

-   Unterscheidet sich die Biomasse zwischen den Varianten?

::: {.callout-tip collapse="true"}
### Modell formulieren

```{r}
mod<-lm(BM ~ DM, data=g)
anova(mod)
```

Ja, aber bevor wir das Modell interpretieren, müssen wir uns unbedingt die Residuen anschauen.
:::

-   Sind die Voraussetzung für eine ANOVA gegeben? Prüfe die Residuen.

::: {.callout-tip collapse="true"}
### Modelldiagnostik

```{r}
library(DHARMa)
simulationOutput <- simulateResiduals(fittedModel = mod, plot = F)
plot(simulationOutput)
```

```{r}
plotResiduals(simulationOutput, form = g$DM)
```

Nein, das sieht nicht gut aus. Die Varianz wird mit jedem Level etwas größer. Hier könnte man nun die Abhängige Variable transformieren, um die Varianz zu stabilisieren.

Plotten wir die Daten mit einer Wurzel-transformierten Y-Achse:

```{r}
ggplot(g, aes(x=DM, y=BM)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA) +
  geom_jitter(width=0.25, height=0, shape=1)+
  stat_summary(fun = "mean", colour = "red", size = 2, geom = "point") +
  scale_y_sqrt()
```

Das sieht besser aus. Die Boxen der Boxplots weisen eine ähnliche Höhe auf.

Nun können wir entweder

-   eine neue Variable in unseren `data.frame` definieren, die die wurzel-transformierten Werte enthält, z.B. `g$BM.sq=sqrt(g$BM)`
-   und mit dieser Variable das Modell fitten `mod<-lm(BM.sq ~ DM, data=g)`
-   und später die emmeans und CIs zurücktransformieren `CIs$emmean.2=CIs$emmean^2` (gleiches für die Konfidenzintervalle)

oder

-   die Transformation im Modell definieren. Das hat bei der späteren Nutzung von `emmeans()` den Vorteil, dass die Werte auf die *Response Skala* automatisch tranformiert werden können.

```{r}
mod1<-lm(sqrt(BM) ~ DM, data=g)
anova(mod1)
```

```{r}
simulationOutput <- simulateResiduals(fittedModel = mod1, plot = F)
plot(simulationOutput)
plotResiduals(simulationOutput, form = g$DM)
```

Auch wenn wir Warnmeldungen für die obigen Plots erhalten, so ist doch die Annahme der Varianzhomogenität und annähernede Normalverteilung der Residuen erfüllt. Wir können das Modell nun interpretieren.

### Modellinterpretation

```{r}
library(emmeans)
library(multcomp)
library(multcompView)
cld(emmeans(mod1, ~DM), adjust = "sidak", Letters=letters)
```

Die emmeans sind recht niedrig, was an der Wurzeltransformation liegt.

```{r}
cld(emmeans(mod1, ~DM, type="response"), adjust = "sidak", Letters=letters)
```

Mit dem Argument `type="response"` werden die emmeans auf die Originalskala zurücktransformiert. Beachte, dass jetzt die Variable `reponse` heißt und der Code für die Grafik angepasst werden muss. Die p-Werte der paarweisen Vergleiche können wir über die `contrast()`-Funktion erhalten. Alternativ kann mit dem Argument `method="trt.vs.ctrl"` ein Dunnett-Test durchgeführt werden, der die Düngemittel A, B und C gegen die **Kontrolle** testet.

```{r}
contrast(emmeans(mod1, ~DM), method="pairwise")
contrast(emmeans(mod1, ~DM), method="trt.vs.ctrl")
```

```{r}
contrast(emmeans(mod1, ~DM), adjust = "sidak", method="pairwise")
contrast(emmeans(mod1, ~DM), adjust = "sidak", method="trt.vs.ctrl")
```

```{r}
CIs=cld(emmeans(mod1, ~DM, type = "response" ), adjust = "sidak", sort = FALSE, Letters=letters)
CIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert
CIs$.group =gsub(" ", "", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen
CIs$.group # besser
str(CIs)
```

```{r}
ggplot(g, aes(x=DM, y=BM)) +
  stat_boxplot(geom ="errorbar", width = 0.5)+
  geom_boxplot(outlier.shape=NA, width = 0.6) +
  geom_jitter(width=0.25, height=0, shape=1)+
  geom_point(data=CIs, aes(y=response), 
             shape=16,  size=2, col=2, 
             position = position_nudge(x = 0.4))+
  geom_errorbar(data=CIs, aes(y=response, ymin=lower.CL, ymax=upper.CL), 
                width=0.1, col=2, position = position_nudge(x = 0.4))+
  geom_text(data=CIs, aes(y = 550, label =.group))+
  theme_bw() +
  scale_y_sqrt(breaks=c(50, 100,200,300,400,500))+
  ylab("Biomasse (g)")+
  xlab("Düngemittel")
```
:::

Ende Übung 4
