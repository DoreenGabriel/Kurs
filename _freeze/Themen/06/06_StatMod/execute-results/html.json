{
  "hash": "e4ba57274725f26770b180aa1fba08c4",
  "result": {
    "markdown": "---\ntitle: \"Statistische Modellierung\"\n---\n\n\n-   Alle Modelle sind falsch.\n-   Manche Modelle sind besser als andere.\n-   Das richtige Modell kann niemals mit absoluter Sicherheit bestimmt werden.\n-   Je einfacher ein Modell ist, desto besser. *\"the principle of parsimony: the correct explanation is the simplest explanation\"*\n-   *\"Man muss die Dinge so einfach wie möglich machen. Aber nicht einfacher.\"* Albert Einstein\n\n## Prinzip der Parsimonität - Wie viele Parameter bedarf es um einen Elefanten zu modellieren?\n\n![](Elephant.png)\n\nA)  36, B) 5, C) 10, D) 20 und E) 30 Parameter\n\n*The 30-term elephant \"may not satisfy the third-grade art teacher, but would carry most chemical engineers into preliminary design.\"*\n\naus:\\\nBurnham K, Anderson D. 2002. Model selection and multimodel inference. Springer, USA.\\\nWei J. 1975. Least square fitting of an elephant. Chemtech 5: 128-129.\n\n## Ziel der statistischen Modellierung\n\n-   Selektion des minimalen adäquaten Modells aus einem großen Pool verschieden komplexer Modelle\n\n## Modelltypen\n\n-   Volles Model (*full model*, maximales Modell, globales Modell, alle Erklärungsvariablen inkl. Interaktionen, Freiheitsgrade = n - p - 1)\n-   *candidate model* (verschiedene mögliche Modelle die *subsets* des globalen Modells sind, d.h. unterschiedliche Erklärungsvariablen beinhalten)\n-   Minimales adäquates Modell (*mimimal adequate model*, vereinfachtes oder *\"bestes\"* Modell entsprechend dem Prinzip der Parsimonität)\n-   Nullmodell (*null model*, nur Intercept \\~1, i.e. Mittelwert, wird gefittet)\n-   Gesättigtes Modell (*saturated model*, eine Erklärungsvariable für jeden Punkt = keine Freiheitsgrade)\n\n## Erklärungsvariablen\n\n-   Welche Erklärungsvariablen?\n    -   biologisch sinnvoll\n    -   entsprechend Fragestellung und Literatur\n    -   Designvariablen\n-   Korrelation zwischen Erklärungsvariablen prüfen\n    -   kann zu verzerrten Schätzungen der Modellparameter und Fehler führen\n    -   Daumenregel r \\< 0,7\n    -   *variance inflation factor* VIF \\< 3\n-   Anzahl Erklärungsvariablen an Stichprobenumfang anpassen\n    -   Gefahr der Überparametrisierung\n    -   Daumenregel je Parameter 10 Stichproben (häufig nicht realisierbar)\n    -   in landwirtschaftlichen Versuchen häufig 4 Wdh\n-   Beziehungen zwischen Abhängigen und Erklärungsvariable überprüfen\n    -   Linearität vs. Kurvatur [Übung 5](https://doreengabriel.github.io/Kurs/Themen/05/05_Regression.html#%C3%BCbung-5){target=\"_blank\"}\n    -   Verteilung der kontinierlichen Erklärungsvariable (Schiefe, Länge des Gradienten)\n    -   N bei kategorialen Erklärungsvariable (balanciert, Anzahl Stichproben je Gruppe)\n-   Welche Interaktionen? (alle, keine, nur zweifach, entsprechend Fragestellung)\n\n## Statistische Interaktion (Wechselwirkung)\n\nwenn der Effekt einer Erklärungsvariable von dem Wert der anderen Erklärungsvariable abhängt\n\n![](interaktion.png)\n\n## Mehrere Erklärungsvariablen im Modell\n\n| Nr  | Modellformel                    | Modellparameter                                          |\n|---------------|---------------|-------------------------------------------|\n| 1   | `lm(y~x+z)`                     | zwei Erklärungsvariablen                                 |\n| 2   | `lm(y~x*z)`                     | zwei Erklärungsvariablen und deren Interaktion           |\n| 3   | `lm(y~x+z+x:z)`                 | zwei Erklärungsvariablen und deren Interaktion           |\n| 4   | `lm(y~x+z+w)`                   | drei Erklärungsvariablen                                 |\n| 5   | `lm(y~x+z+w+x:z+z:w+w:x)`       | drei Erklärungsvariablen und alle Zweifach-Interaktionen |\n| 6   | `lm(y~(x+z+w)^2)`               | drei Erklärungsvariablen und alle Zweifach-Interaktionen |\n| 7   | `lm(y~x+z+w+x:z+z:w+w:x+z:w:x)` | drei Erklärungsvariablen und alle Interaktionen          |\n| 8   | `lm(y~x*z*w)`                   | drei Erklärungsvariablen und alle Interaktionen          |\n\nModell Nr. 2 und 3 sind identische Modelle, ebenso Nr. 5 und 6 und Nr. 7 und 8.\n\n## Beispiel: Modell- und Variablenselektion\n\nWir wollen nun verschiedene Modell- und Variablenselektionsstrategien an einem Beispieldatensatz zur Pflanzendiversität in Weizenfeldern rechnen.\n\nLiteratur zum Thema:\n\nHeinze et al. (2018) [Variable selection -- A review and recommendations for the practicing statistician](https://onlinelibrary.wiley.com/doi/full/10.1002/bimj.201700067){target=\"_blank\"}\n\n#### Fragestellung:\n\nWie beeinflusst Bewirtschaftung (ökologisch vs. konventionell), Bodengüte (ertragreich vs. ertragsarm) und Landschaftsstruktur (strukturreich vs. strukturarm) die Pflanzendiversität in Weizenfeldern?\n\n#### Untersuchungsdesign:\n\nIn 36 ökologisch und konventionell bewirtschafteten Weizenflächen (`Man = con vs. org`), welche sowohl in ihrer Bodengüte (*Soil quality* = `SQ`) als auch in der umgebenden Landschaftsstruktur (% Ackeranteil = `Arab`) variierten, wurde die Shannon-Diversität von Ackerwildkräutern (`Weeds`) ermittelt.\n\n### Daten einlesen, kennenlernen, plotten\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openxlsx)\nof=read.xlsx(\"organic_farming.xlsx\")\nstr(of)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t36 obs. of  5 variables:\n $ ID   : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Man  : chr  \"con\" \"org\" \"con\" \"org\" ...\n $ Arab : num  21.2 21.4 24.3 26.3 31.3 29.4 36.1 34.6 38.9 41.9 ...\n $ SQ   : num  82 63 52 40 94 74 69 53 83 86 ...\n $ Weeds: num  3.35 3.5 3.28 3.57 2.96 3.35 3 3.5 3 3.54 ...\n```\n:::\n\n```{.r .cell-code}\nof$Man=as.factor(of$Man)\nsummary(of)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       ID         Man          Arab             SQ            Weeds      \n Min.   : 1.00   con:18   Min.   :21.20   Min.   :38.00   Min.   :1.410  \n 1st Qu.: 9.75   org:18   1st Qu.:41.15   1st Qu.:54.75   1st Qu.:2.438  \n Median :18.50            Median :60.50   Median :62.50   Median :2.980  \n Mean   :18.50            Mean   :59.89   Mean   :65.83   Mean   :2.789  \n 3rd Qu.:27.25            3rd Qu.:80.65   3rd Qu.:79.25   3rd Qu.:3.290  \n Max.   :36.00            Max.   :94.10   Max.   :95.00   Max.   :3.570  \n```\n:::\n:::\n\n\nWir plotten zunächst die Daten entsprechend unserer Fragestellung:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(ggpubr)\np1=ggplot(of, aes(x=Man, y=Weeds, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np2=ggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\np3=ggplot(of, aes(x=SQ, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\np4=ggplot(of, aes(x=Man, y=Arab, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np5=ggplot(of, aes(x=Man, y=SQ, colour=Man)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\np6=ggplot(of, aes(x=SQ, y=Arab, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\n\nggarrange(p1, p2, p3, p4, p5, p6, common.legend = TRUE, legend = \"bottom\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\nIm Plot oben rechts sehen wir, dass die Diversität in ökologisch bewirtschafteten Flächen höher ist als in konventionellen. Wir sehen aber auch, dass die Variabilität sich deutlich (und um ein Vielfaches) zwischen `org` und `con` unterscheidet.\n\n::: {.callout-tip collapse=\"true\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nof %>% \n  group_by(Man) %>% \n  summarise(MW=mean(Weeds),\n            VAR=var(Weeds))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 x 3\n  Man      MW    VAR\n  <fct> <dbl>  <dbl>\n1 con    2.35 0.441 \n2 org    3.23 0.0558\n```\n:::\n:::\n\n:::\n\nIst das ein Problem? NEIN. Wir müssen die Residuen nach der Analyse auf Varianzhomogenität checken. Wenn unsere Erklärungsvariablen die Variabilität in den Daten erklären, dann sollte der Restfehler varianzhomogen sein.\\\nAusserdem sehen wir einen negativen Zusammenhang zwischen `Weeds`und `Arab` für `org` und `con` sowie eine mögliche Interaktion zwischen `Weeds` und `SQ` für `org` und `con`. Wir plotten ausserdem die Erklärungsvariablen gegeneinander, um mögliche Muster oder Zusammenhänge zu erkennen. Wir sehen, dass die Erklärungsvariablen `Arab` und `SQ` einen ähnlich weiten Wertebereich in `org`und `con` aufweisen. Außerdem scheint es keinen Zusammenhang zwischen `Arab` und `SQ` zu geben. Gut so.\n\n## Korrelation zwischen Erklärungsvariablen testen\n\nBevor wir ein Modell formulieren, sollten wir die Korrelation zwischen den Erklärungsvariablen prüfen. Eng korrelierte Erklärungsvariablen können zu verzerrten Modellkoeffizienten, hohen Standardfehlern der Koeffizienten und damit zu instabilen Modellen und den falschen Schlussfolgerungen führen.\n\nsiehe auch Dormann et al. (2012) [Collinearity: a review of methods to deal with it and a simulation study evaluating their performance](https://nsojournals.onlinelibrary.wiley.com/doi/full/10.1111/j.1600-0587.2012.07348.x){target=\"_blank\"}\n\n### mit der ggpairs() und library(GGally)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GGally)\nggpairs(of, columns = c(2:4), ggplot2::aes(colour = Man))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n### mit einer Korrelationsmatrix\n\nUm eine Korrelationsmatrix zu erstellen, müssen alle Variablen numerisch sein. Ich codiere hier die Variable `Man` in eine dummy-Variable um. Da sie nur zwei Levels hat, wird eine Spalte mit der Information Man = 1 und org = 0 ausreichen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nof$Man.con=ifelse(of$Man == \"con\", 1, 0)\n```\n:::\n\n\nSollte man einen Faktor mit mehr als zwei Levels haben, könnte man so fortfahren: `of$Man.org=ifelse(of$Man == \"org\", 1, 0)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc)\nrcorr(as.matrix(of[,c(3:4, 6)]), type=\"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Arab    SQ Man.con\nArab     1.00 -0.16    0.00\nSQ      -0.16  1.00    0.13\nMan.con  0.00  0.13    1.00\n\nn= 36 \n\n\nP\n        Arab   SQ     Man.con\nArab           0.3495 0.9978 \nSQ      0.3495        0.4609 \nMan.con 0.9978 0.4609        \n```\n:::\n:::\n\n\nDie *Pearson Korrelationskoeffizienten* sind alle \\< 0,7 bzw. \\>-0,7. Pearson Korrelationskoeffizienten nutzt man für lineare Zusammenhänge. Alternativ kann man die *Spearman Rang-Korrelation* nutzen, welche auf Rängen basiert und für monotone Zusammenhänge, i.e. monoton steigend oder fallend, eine Aussage trifft.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrcorr(as.matrix(of[,c(3:4, 6)]), type=\"spearman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Arab    SQ Man.con\nArab     1.00 -0.17    0.01\nSQ      -0.17  1.00    0.11\nMan.con  0.01  0.11    1.00\n\nn= 36 \n\n\nP\n        Arab   SQ     Man.con\nArab           0.3172 0.9753 \nSQ      0.3172        0.5142 \nMan.con 0.9753 0.5142        \n```\n:::\n:::\n\n\nEine gute Möglichkeit zur Abbildung einer Korrelationsmatrix bietet die `library(corrplot)` mit der Funktion `corrplot()` und `corrplot.mixed()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrplot)\ncorrplot(cor(of[,c(3:4, 6)]), method = \"ellipse\")\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-8-1.png){width=576}\n:::\n\n```{.r .cell-code}\ncorrplot.mixed(cor(of[,c(3:4, 6)]), upper = \"ellipse\", tl.col =1, tl.cex=0.75)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-8-2.png){width=576}\n:::\n:::\n\n\n### mit dem Variance Inflation Factor (VIF)\n\nDie potentielle Korrelation zwischen Erklärungsvariablen kann auch mit dem *Variance Inflation Factor* (VIF) getestet werden. Der VIF ist ein Maß für die Multikollineraität und gibt an, wie gut die einzelnen Erklärungsvariablen durch die anderen Erklärungsvariablen erklärt werden. Der VIF steht also für die Redundanz innerhalb der Erklärungsvariablen. Ich fitte ein Modell mit den Haupteffekten ohne Interaktionen. Solange alle VIFs \\< 3 sind, ist alles in Ordnung. Es gibt auch Quellen, die \\<5 oder gar \\<10 angeben. Sollte ein VIF höher als dein gewähltes Kriterium sein, dann entfernst du schrittweise die Variable mit dem höchsten VIF, berechnest den VIF erneut und führst dies fort, bis alle Variablen unterhalb dem gewählten Kriterium sind.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLade nötiges Paket: carData\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'car'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDas folgende Objekt ist maskiert 'package:dplyr':\n\n    recode\n```\n:::\n\n```{.r .cell-code}\nvif(lm(Weeds~Man+Arab+SQ, data=of))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Man     Arab       SQ \n1.016819 1.026933 1.043731 \n```\n:::\n:::\n\n\nAlle Methoden führen zu dem Schluss, dass wir ein Modell mit allen drei Erklärungsvariablen formulieren können.\n\n## Modell formulieren\n\nIch fitte hier ein Modell inklusive Dreifachinteraktion, obwohl der Stichprobenumfang schon relativ klein ist und es auch Argumente dafür gibt, mit einem Modell nur mit Zweifachinteraktionen zu starten, i.e. ohne Dreifachinteraktion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod<-lm(Weeds~Arab*Man*SQ, data=of)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Arab * Man * SQ, data = of)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.271803 -0.100298  0.008768  0.093416  0.257560 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     3.748e+00  5.252e-01   7.136 9.15e-08 ***\nArab           -2.440e-02  7.899e-03  -3.090  0.00449 ** \nManorg         -1.398e-01  7.234e-01  -0.193  0.84813    \nSQ              3.181e-03  7.190e-03   0.442  0.66161    \nArab:Manorg     2.073e-02  1.121e-02   1.849  0.07505 .  \nArab:SQ        -3.852e-05  1.140e-04  -0.338  0.73805    \nManorg:SQ      -1.419e-03  1.070e-02  -0.133  0.89538    \nArab:Manorg:SQ -3.233e-05  1.695e-04  -0.191  0.85012    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1554 on 28 degrees of freedom\nMultiple R-squared:  0.956,\tAdjusted R-squared:  0.945 \nF-statistic: 86.88 on 7 and 28 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## Modellvereinfachung, -selektion\n\nWir werden nun verschiedene Methoden der Modell- und Variablenselektion kennenlernen.\n\n### Schrittweise Modellvereinfachung mit drop1() basierend auf Teststatistik\n\n-   Der klassische Weg: *backward selection*\n-   maximales Modell fitten\n-   schrittweises Entfernen von nicht-signifikanten Interaktionen\n    -   dabei mit der Interaktion der höchsten Ordnung beginnen (Dreifach- vor Zweifach-Interaktionen)\n    -   höchster p-Wert\n    -   altes mit neuem Modell vergleichen (Fehler/deviance)\n-   Entfernen von nicht-signifikanten Erklärungsvariablen (Haupteffekte)\n    -   wenn nicht in signifikanter Interaktion enthalten\n-   Das minimale adäquate Modell enthält nur noch signifikante Parameter\\*.\n\n\\*nicht signifikante Haupteffekte sind im Modell möglich, wenn sie Teil einer signifikanten Interaktion sind\n\nWir testen mit der Funktion `drop1()` die Dreifachinteraktion.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(mod, test=\"F\") # Signifikanztest für Dreifachinteraktion\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWeeds ~ Arab * Man * SQ\n            Df  Sum of Sq     RSS     AIC F value Pr(>F)\n<none>                    0.67648 -127.08               \nArab:Man:SQ  1 0.00087887 0.67736 -129.03  0.0364 0.8501\n```\n:::\n:::\n\n\nDer p-Wert ist größer 0.05. Also können wir die Dreifachinteraktion entfernen, indem ein neues Modell `mod1` durch die Funktion `update()` gefittet wird, welches alle Effekte wie `mod` besitzt `~.`, außer (daher das `-`) die Interaktion `Arab:Man:SQ`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1<-update(mod, ~.-Arab:Man:SQ) # Term wird aus Model entfernt \n```\n:::\n\n\nWenn wir nun die Funktion `drop1()` für `mod1` nutzen, werden uns alle p-Werte für die Zweifachinteraktionen angezeigt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(mod1, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man + Arab:SQ + Man:SQ\n         Df Sum of Sq     RSS      AIC F value    Pr(>F)    \n<none>                0.67736 -129.030                      \nArab:Man  1   1.48614 2.16351  -89.224 63.6264 8.501e-09 ***\nArab:SQ   1   0.00958 0.68695 -130.525  0.4103    0.5268    \nMan:SQ    1   0.02171 0.69908 -129.894  0.9297    0.3429    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n`Arab:SQ` hat den höchsten p-Wert (und \\> 0,05), also raus damit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2<-update(mod1, ~.-Arab:SQ )\ndrop1(mod2, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man + Man:SQ\n         Df Sum of Sq     RSS      AIC F value    Pr(>F)    \n<none>                0.68695 -130.525                      \nArab:Man  1   1.59208 2.27903  -89.352 69.5286 2.628e-09 ***\nMan:SQ    1   0.02135 0.70830 -131.423  0.9324     0.342    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n`Man:SQ` hat den höchsten p-Wert (und \\> 0,05), also raus damit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod3<-update(mod2, ~.-Man:SQ)\ndrop1(mod3, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + SQ + Arab:Man\n         Df Sum of Sq     RSS      AIC F value    Pr(>F)    \n<none>                0.70830 -131.423                      \nSQ        1   0.00188 0.71018 -133.327  0.0824     0.776    \nArab:Man  1   1.66223 2.37052  -89.935 72.7506 1.238e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nDer p-Wert für `SQ` als Haupteffekt erscheint, weil `SQ` nicht mehr in einer Interaktion enthalten ist. `SQ` hat den höchsten p-Wert (und \\> 0,05), also raus damit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod4<-update(mod3, ~.-SQ)\ndrop1(mod4, test=\"F\") # \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nWeeds ~ Arab + Man + Arab:Man\n         Df Sum of Sq     RSS     AIC F value   Pr(>F)    \n<none>                0.71018 -133.33                     \nArab:Man  1    1.7458 2.45599  -90.66  78.665 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\np \\< 0,05, wir sollten keine weitere Variable entfernen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAnalog gibt es auch eine Funktion `add1()` bei der eine *forward selection* durchgeführt werden kann.\\\nSowohl die klassische *backward* also auch die *forward selection* sind für Modelle mit wenigen Erklärungsvariablen denkbar.\n\n## Übung 6.1.\n\nDie Aktivität von Lurchen wurde in den drei Habitattypen (Teichumgebung, Hecke und Wald) bei unterschiedlichen Witterungsbedingungen (Temperatur und Luftfeuchte) gemessen.\n\n-   Importiere die Daten [Lurche.xlsx](https://github.com/DoreenGabriel/Kurs/blob/main/Themen/06/Lurche.xlsx){target=\"_blank\"} und mach dich mit den Daten vertraut.\n\n::: {.callout-tip collapse=\"true\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openxlsx)\ndat=read.xlsx(\"Lurche.xlsx\")\nstr(dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t90 obs. of  4 variables:\n $ Hab : chr  \"Teich\" \"Teich\" \"Teich\" \"Teich\" ...\n $ Temp: num  14.3 18.3 15.3 19.1 19.5 12.4 16.2 19.1 16.4 15.7 ...\n $ Hum : num  45 57.4 53.9 51.2 60.3 46.3 50.7 56.6 51.1 48.7 ...\n $ Akt : num  39.9 50.4 52.7 53.6 54.8 47.1 49.2 46.9 43.9 43.6 ...\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(GGally)\nggpairs(dat, columns = 1:4, ggplot2::aes(colour = Hab))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nim obigen Plot ist zu erkennen:\n\n-   drei Habitate mit jeweils 30 Beobachtungen\n-   Temperatur, Luftfeuchte und Aktivität variieren zwischen den Habitaten\n-   Temperatur und Luftfeuchte sind positiv korreliert (r = 0.86)\n\nIch plotte die Daten entsprechend der Fragestellung:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x=Hab, y=Akt, colour=Hab)) +\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, shape=1)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nDie Aktivität scheint sich zwischen den verschienen Habitattypen zu unterscheiden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(dat, aes(x=Temp, y=Akt, colour=Hab)) +\n  geom_point()+\n  geom_smooth(method=lm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nEs scheint einen positiven Zusammenhang zwischen der Temperatur und der Aktivität in den verschiedenen Habitaten zu geben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=dat, aes(y=Akt, x=Hum, col=Hab))+\n  geom_point()+\n  geom_smooth(method=lm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nGleiches Muster für den Zusammenhang zwischen Aktivität und Luftfeuchte.\n\nDie Korrelationsmatrix zeigen eine enge Korrelation (r = 0.86) zwischen Temperatur und Luftfeuchte. Die Korrelationskoeffizienten der Dummy-Variablen zeigen die Unterschiele der kontinuierlichen Variablen in den jeweiligen Habitattypen an. z.B. ist in Habitattyp Teich die die Temperatur höher (r = 0,47) und im Wald kälter (r = 0,37).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Hmisc)\ndat$Hab.H=ifelse(dat$Hab == \"Hecke\", 1, 0)\ndat$Hab.T=ifelse(dat$Hab == \"Teich\", 1, 0)\ndat$Hab.W=ifelse(dat$Hab == \"Wald\", 1, 0)\nrcorr(as.matrix(dat[,c(2:7)]), type=\"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Temp   Hum   Akt Hab.H Hab.T Hab.W\nTemp   1.00  0.86  0.63 -0.11  0.47 -0.37\nHum    0.86  1.00  0.49 -0.21  0.39 -0.18\nAkt    0.63  0.49  1.00 -0.18  0.88 -0.70\nHab.H -0.11 -0.21 -0.18  1.00 -0.50 -0.50\nHab.T  0.47  0.39  0.88 -0.50  1.00 -0.50\nHab.W -0.37 -0.18 -0.70 -0.50 -0.50  1.00\n\nn= 90 \n\n\nP\n      Temp   Hum    Akt    Hab.H  Hab.T  Hab.W \nTemp         0.0000 0.0000 0.3097 0.0000 0.0004\nHum   0.0000        0.0000 0.0470 0.0001 0.0863\nAkt   0.0000 0.0000        0.0955 0.0000 0.0000\nHab.H 0.3097 0.0470 0.0955        0.0000 0.0000\nHab.T 0.0000 0.0001 0.0000 0.0000        0.0000\nHab.W 0.0004 0.0863 0.0000 0.0000 0.0000       \n```\n:::\n\n```{.r .cell-code}\nrcorr(as.matrix(dat[,c(2:7)]), type=\"spearman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Temp   Hum   Akt Hab.H Hab.T Hab.W\nTemp   1.00  0.86  0.60 -0.11  0.46 -0.34\nHum    0.86  1.00  0.45 -0.23  0.38 -0.15\nAkt    0.60  0.45  1.00 -0.03  0.81 -0.77\nHab.H -0.11 -0.23 -0.03  1.00 -0.50 -0.50\nHab.T  0.46  0.38  0.81 -0.50  1.00 -0.50\nHab.W -0.34 -0.15 -0.77 -0.50 -0.50  1.00\n\nn= 90 \n\n\nP\n      Temp   Hum    Akt    Hab.H  Hab.T  Hab.W \nTemp         0.0000 0.0000 0.2851 0.0000 0.0009\nHum   0.0000        0.0000 0.0289 0.0002 0.1590\nAkt   0.0000 0.0000        0.7534 0.0000 0.0000\nHab.H 0.2851 0.0289 0.7534        0.0000 0.0000\nHab.T 0.0000 0.0002 0.0000 0.0000        0.0000\nHab.W 0.0009 0.1590 0.0000 0.0000 0.0000       \n```\n:::\n:::\n\n\nAufgrund der engen Korrelation zwischen Temperatur und Luftfeuchte sollten wir nur eine der beiden Variablen ins Modell nehmen. Aber welche? Das können wir basierend auf unserem Fachwissen entscheiden. Oder den Variance Inflation Faktor nutzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nvif(lm(Akt~Temp+Hum+Hab, data=dat))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         GVIF Df GVIF^(1/(2*Df))\nTemp 4.839203  1        2.199819\nHum  4.302632  1        2.074279\nHab  1.458039  2        1.098860\n```\n:::\n:::\n\n\nBasierend auf VIF sollten wir Temperatur aus dem Modell entfernen, weil es am stärksten durch die anderen beiden Erklärungsvariablen erklärt werden kann. Ob das so gut ist, werden wir weiter unten sehen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvif(lm(Akt~Hab+Hum, data=dat))# ok\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        GVIF Df GVIF^(1/(2*Df))\nHab 1.181775  2        1.042638\nHum 1.181775  1        1.087095\n```\n:::\n\n```{.r .cell-code}\nvif(lm(Akt~Temp+Hab, data=dat))# ok\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         GVIF Df GVIF^(1/(2*Df))\nTemp 1.329152  1        1.152888\nHab  1.329152  2        1.073726\n```\n:::\n\n```{.r .cell-code}\nvif(lm(Akt~Temp+Hum, data=dat))# nicht ok, nur zu Demo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Temp      Hum \n3.922289 3.922289 \n```\n:::\n:::\n\n:::\n\n-   Modelliere die Aktivität der Lurche mit einer backward selektion.\n\n::: {.callout-tip collapse=\"true\"}\nWir haben nun die drei Optionen:\n\n1.  wir ignorieren erstmal die Korrelation zwischen Luftfeuchte und Temperatur und beginnen mit diesem Modell `Akt~Temp*Hum*Hab`.\\\n\n2.  wir nutzen das Modell, welches laut VIF besser ist `Akt~Hum*Hab`.\\\n\n3.  wir sind stärker an dem Temperatureffekt interessiert und weniger am Luftfeuchteeffekt `Akt~Temp*Hab`.\n\n4.  Option\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMod=lm(Akt~Temp*Hab*Hum, data=dat)\nsummary(Mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Temp * Hab * Hum, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.7350  -2.7489  -0.5331   2.4653  11.0886 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)\n(Intercept)        44.58138   44.73999   0.996    0.322\nTemp               -0.34632    3.04932  -0.114    0.910\nHabTeich          -94.39330   77.21012  -1.223    0.225\nHabWald            40.79471   82.99665   0.492    0.624\nHum                -0.92737    0.97549  -0.951    0.345\nTemp:HabTeich       4.94912    4.60881   1.074    0.286\nTemp:HabWald       -5.37073    6.14458  -0.874    0.385\nTemp:Hum            0.04262    0.06108   0.698    0.487\nHabTeich:Hum        2.45347    1.66790   1.471    0.145\nHabWald:Hum        -0.68025    1.77685  -0.383    0.703\nTemp:HabTeich:Hum  -0.10959    0.09360  -1.171    0.245\nTemp:HabWald:Hum    0.08468    0.12569   0.674    0.503\n\nResidual standard error: 4.585 on 78 degrees of freedom\nMultiple R-squared:  0.9165,\tAdjusted R-squared:  0.9047 \nF-statistic: 77.82 on 11 and 78 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(Mod, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp * Hab * Hum\n             Df Sum of Sq    RSS    AIC F value Pr(>F)\n<none>                    1639.9 285.23               \nTemp:Hab:Hum  2    54.349 1694.2 284.17  1.2926 0.2804\n```\n:::\n\n```{.r .cell-code}\nMod1<-update(Mod, ~.-Temp:Hab:Hum) ; drop1(Mod1, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum + Hab:Hum\n         Df Sum of Sq    RSS    AIC F value Pr(>F)\n<none>                1694.2 284.17               \nTemp:Hab  2    38.176 1732.4 282.17  0.9013 0.4101\nTemp:Hum  1     2.864 1697.1 282.32  0.1353 0.7140\nHab:Hum   2    31.542 1725.8 281.82  0.7447 0.4781\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nMod2<-update(Mod1, ~.-Temp:Hum) ; drop1(Mod2, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab + Hab:Hum\n         Df Sum of Sq    RSS    AIC F value Pr(>F)\n<none>                1697.1 282.32               \nTemp:Hab  2    38.137 1735.2 280.32  0.9101 0.4065\nHab:Hum   2    36.434 1733.5 280.23  0.8695 0.4230\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nMod3<-update(Mod2, ~.-Hab:Hum) ; drop1(Mod3, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Hum + Temp:Hab\n         Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>                1733.5 280.23                  \nHum       1      0.29 1733.8 278.24  0.0139 0.90640  \nTemp:Hab  2    147.81 1881.3 283.59  3.5386 0.03351 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nMod4<-update(Mod3, ~.-Hum) ; drop1(Mod4, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp + Hab + Temp:Hab\n         Df Sum of Sq    RSS    AIC F value Pr(>F)  \n<none>                1733.8 278.24                 \nTemp:Hab  2    148.93 1882.7 281.66  3.6076 0.0314 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsummary(Mod4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Temp + Hab + Temp:Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp:HabTeich   0.9145     0.5128   1.783  0.07812 . \nTemp:HabWald   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,\tAdjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n2.  Option\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMod.H=lm(Akt~Hum*Hab, data=dat)\ndrop1(Mod.H, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Hum * Hab\n        Df Sum of Sq    RSS    AIC F value  Pr(>F)  \n<none>               1887.0 285.86                  \nHum:Hab  2    164.72 2051.7 289.39  3.6665 0.02974 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsummary(Mod.H)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Hum * Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.5959  -2.9024   0.0721   3.1631  10.2446 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)  \n(Intercept)   10.2926     7.2294   1.424   0.1582  \nHum            0.3191     0.1515   2.106   0.0382 *\nHabTeich      -4.7113    10.9687  -0.430   0.6686  \nHabWald       -6.1098    11.4749  -0.532   0.5958  \nHum:HabTeich   0.4825     0.2181   2.212   0.0297 *\nHum:HabWald   -0.1044     0.2402  -0.434   0.6650  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.74 on 84 degrees of freedom\nMultiple R-squared:  0.9039,\tAdjusted R-squared:  0.8982 \nF-statistic:   158 on 5 and 84 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n3.  Option\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMod.T=lm(Akt~Temp*Hab, data=dat)\ndrop1(Mod.T, test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nAkt ~ Temp * Hab\n         Df Sum of Sq    RSS    AIC F value Pr(>F)  \n<none>                1733.8 278.24                 \nTemp:Hab  2    148.93 1882.7 281.66  3.6076 0.0314 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nsummary(Mod.T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Temp * Hab, data = dat)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp:HabTeich   0.9145     0.5128   1.783  0.07812 . \nTemp:HabWald   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,\tAdjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nOption 1 und 3 führen zum gleichen Modell. Aber auch Option 2 liefert ein sehr gutes Modell mit hohem R² und signifikannter Interaktion.\n\nWir könnten beide Modelle per AIC vergleichen. `Mod.T` hat den niedrigeren AIC und wäre damit besser. Mehr zum AIC kommt weiter unten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAIC(Mod.H, Mod.T)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      df      AIC\nMod.H  7 543.2706\nMod.T  7 535.6523\n```\n:::\n:::\n\n:::\n\n## Modellselektion basierend auf Informationskriterien\n\nWenn wir eine Vielzahl an Erklärungsvariablen haben und damit eine Vielzahl an potentiellen Erklärungsmodellen, führt eine schrittweise Vereinfachung zu vielen aufeinanderfolgenden Signifikanztests. Die durchgeführten Signifikanztests sind nicht voneinander unabhängig. Das Problem des multiplen Testens tritt auf. Der p-Wert verliert seine eigentliche Bedeutung und müsste um die Anzahl der Tests korrigiert werden. Daher steht diese Vorgehensweise bei vielen Anwendern in der Kritik.\n\nBesser ist es, die Modell- bzw. Variablenselektion basierend auf Informationskriterien durchzuführen.\n\nInformationskriterien wägen für uns zwischen der Anpassungsgüte (*fit*) und der Komplexität (Anzahl Parameter *k*) des Modells ab:\n\n-   Das Akaikes Informationskriterium (*Akaike Information Criterion* - AIC) berechnet sich aus der Log-Likelihood und der Anzahl Modellparameter.\\\n-   Das korrigierte Akaikes Informationskriterium (AICc) bestraft stärker um die Anzahl der Modellparameter, wenn der Stichprobenumfang klein ist und verhindert damit stärker den Overfit als AIC. **Daumenregel**: Nutze AICc wenn das Verhältnis aus Stichprobenumfang (n) zu Anzahl Modellparameter (k) n/k \\< 40 ist.\\\n-   Bayessches Informationskriterium (*Bayesian Information Criterion* - BIC) berücksichtigt neben Log-likelihood und Anzahl Modellparametern auch den Stichprobenumfang.\n\n::: callout-important\n# Wichtig\n\nJe niedriger der AIC (AICc, BIC), desto besser das Modell. Es zählt nicht der absolute Wert (z.B. AIC = 100 ist unwichtig).\n:::\n\nBeispiel:\n\n| Modell   | AIC  |\n|----------|------|\n| Modell 1 | 100  |\n| Modell 2 | 98.8 |\n| Modell 3 | 108  |\n\nDamit wäre Modell 2 das bessere Modell.\n\nWährend die absoluten AIC-Werte also keine Bedeutung haben, können die delta AIC-Werte genutzt werden, um das *Level of Empirical Support* des jeweiligen Modells einzuordnen. Burnham und Anderson (2002) *Model Selection and Multimodel Inference* Seite 170 geben folgende Kennwerte an:\n\n| delta AIC | *Level of Empirical Support* |\n|-----------|------------------------------|\n| 0-2       | substantial                  |\n| 4-7       | considerably less            |\n| \\> 10     | none                         |\n\nEntsprechend wären Modell 2 und Modell 1 von Bedeutung, während Modell 3 keine Berücksichtigung erfahren muss.\n\n::: callout-important\n# Wichtig\n\nEs können nur Modelle verglichen werden, die auf den gleichen Datensatz (i.e. gleiche Abhängige y) gefittet wurden.\n:::\n\nVon einem Vergleich von Modellen, die mit verschiedenen R-Packages gefitted wurden, würde ich abraten.\n\nAuch negative AIC-Werte können auftreten. Auch hier gilt, je kleiner desto besser.\n\n## Schrittweise Verfahren basierend auf AIC mit step()\n\nMit der Funktion `step()` kann eine Modellselektion automatisiert auf Basis des AIC erfolgen. Hier ein Beispiel für eine Rückwärtsselektion, bei dem ausgehend vom vollen Modell schrittweise Erklärungsvariablen entfernt werden und die daraus resultierenden Modelle via AIC verglichen werden. Diese Prozedur stoppt, wenn beim Entfernen der Variablen der AIC (wieder) ansteigen würde.\n\n### step backward\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.b<-step(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=-127.08\nWeeds ~ Arab * Man * SQ\n\n              Df  Sum of Sq     RSS     AIC\n- Arab:Man:SQ  1 0.00087887 0.67736 -129.03\n<none>                      0.67648 -127.08\n\nStep:  AIC=-129.03\nWeeds ~ Arab + Man + SQ + Arab:Man + Arab:SQ + Man:SQ\n\n           Df Sum of Sq     RSS      AIC\n- Arab:SQ   1   0.00958 0.68695 -130.525\n- Man:SQ    1   0.02171 0.69908 -129.894\n<none>                  0.67736 -129.030\n- Arab:Man  1   1.48614 2.16351  -89.224\n\nStep:  AIC=-130.52\nWeeds ~ Arab + Man + SQ + Arab:Man + Man:SQ\n\n           Df Sum of Sq     RSS      AIC\n- Man:SQ    1   0.02135 0.70830 -131.423\n<none>                  0.68695 -130.525\n- Arab:Man  1   1.59208 2.27903  -89.352\n\nStep:  AIC=-131.42\nWeeds ~ Arab + Man + SQ + Arab:Man\n\n           Df Sum of Sq     RSS      AIC\n- SQ        1   0.00188 0.71018 -133.327\n<none>                  0.70830 -131.423\n- Arab:Man  1   1.66223 2.37052  -89.935\n\nStep:  AIC=-133.33\nWeeds ~ Arab + Man + Arab:Man\n\n           Df Sum of Sq     RSS     AIC\n<none>                  0.71018 -133.33\n- Arab:Man  1    1.7458 2.45599  -90.66\n```\n:::\n\n```{.r .cell-code}\nsummary(mod.b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### step forward\n\nBeim Vorwärtsverfahren müssen wir zunächst das Null-Modell fitten\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod0<-lm(Weeds~1, data=of) \n```\n:::\n\n\nund dann die Argumente `scope` und `direction` bedienen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.fw=step(mod0, scope=list(lower=mod0, upper=mod), direction=\"forward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=-28.64\nWeeds ~ 1\n\n       Df Sum of Sq     RSS     AIC\n+ Man   1    6.9169  8.4531 -48.164\n+ Arab  1    6.0033  9.3667 -44.469\n<none>              15.3700 -28.640\n+ SQ    1    0.1196 15.2504 -26.921\n\nStep:  AIC=-48.16\nWeeds ~ Man\n\n       Df Sum of Sq    RSS     AIC\n+ Arab  1    5.9971 2.4560 -90.660\n+ SQ    1    0.4693 7.9838 -48.220\n<none>              8.4531 -48.164\n\nStep:  AIC=-90.66\nWeeds ~ Man + Arab\n\n           Df Sum of Sq     RSS      AIC\n+ Arab:Man  1   1.74581 0.71018 -133.327\n<none>                  2.45599  -90.660\n+ SQ        1   0.08547 2.37052  -89.935\n\nStep:  AIC=-133.33\nWeeds ~ Man + Arab + Man:Arab\n\n       Df Sum of Sq     RSS     AIC\n<none>              0.71018 -133.33\n+ SQ    1  0.001882 0.70830 -131.42\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod.fw)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Man + Arab + Man:Arab, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg:Arab  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n### step both\n\nMit dem Argument `direction=\"both\"` wird die Vorwärts- und Rückwärtsselektion kombiniert.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.both=step(mod0, scope=list(upper=mod), direction=\"both\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=-28.64\nWeeds ~ 1\n\n       Df Sum of Sq     RSS     AIC\n+ Man   1    6.9169  8.4531 -48.164\n+ Arab  1    6.0033  9.3667 -44.469\n<none>              15.3700 -28.640\n+ SQ    1    0.1196 15.2504 -26.921\n\nStep:  AIC=-48.16\nWeeds ~ Man\n\n       Df Sum of Sq     RSS     AIC\n+ Arab  1    5.9971  2.4560 -90.660\n+ SQ    1    0.4693  7.9838 -48.220\n<none>               8.4531 -48.164\n- Man   1    6.9169 15.3700 -28.640\n\nStep:  AIC=-90.66\nWeeds ~ Man + Arab\n\n           Df Sum of Sq    RSS      AIC\n+ Arab:Man  1    1.7458 0.7102 -133.327\n<none>                  2.4560  -90.660\n+ SQ        1    0.0855 2.3705  -89.935\n- Arab      1    5.9971 8.4531  -48.164\n- Man       1    6.9107 9.3667  -44.469\n\nStep:  AIC=-133.33\nWeeds ~ Man + Arab + Man:Arab\n\n           Df Sum of Sq     RSS     AIC\n<none>                  0.71018 -133.33\n+ SQ        1   0.00188 0.70830 -131.42\n- Man:Arab  1   1.74581 2.45599  -90.66\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod.both)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Man + Arab + Man:Arab, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg:Arab  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\nAlle drei Verfahren haben zum gleichen besten Modell geführt. Das ist nicht immer so. Zusätzlich wird mit der Funktion `step()` immer nur **ein** bestes Modell selektiert und es bleibt offen, ob es noch andere ähnlich gute Modelle gibt.\n\n## Übung 6.2.\n\n-   Modelliere die Aktivität der Lurche mit der step-Funktion.\n\n::: {.callout-tip collapse=\"true\"}\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(Mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=285.23\nAkt ~ Temp * Hab * Hum\n\n               Df Sum of Sq    RSS    AIC\n- Temp:Hab:Hum  2    54.349 1694.2 284.17\n<none>                      1639.9 285.23\n\nStep:  AIC=284.16\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum + Hab:Hum\n\n           Df Sum of Sq    RSS    AIC\n- Hab:Hum   2    31.542 1725.8 281.82\n- Temp:Hab  2    38.176 1732.4 282.17\n- Temp:Hum  1     2.864 1697.1 282.32\n<none>                  1694.2 284.17\n\nStep:  AIC=281.82\nAkt ~ Temp + Hab + Hum + Temp:Hab + Temp:Hum\n\n           Df Sum of Sq    RSS    AIC\n- Temp:Hum  1     7.757 1733.5 280.23\n- Temp:Hab  2    71.066 1796.8 281.46\n<none>                  1725.8 281.82\n\nStep:  AIC=280.23\nAkt ~ Temp + Hab + Hum + Temp:Hab\n\n           Df Sum of Sq    RSS    AIC\n- Hum       1      0.29 1733.8 278.24\n<none>                  1733.5 280.23\n- Temp:Hab  2    147.81 1881.3 283.59\n\nStep:  AIC=278.24\nAkt ~ Temp + Hab + Temp:Hab\n\n           Df Sum of Sq    RSS    AIC\n<none>                  1733.8 278.24\n- Temp:Hab  2    148.93 1882.7 281.66\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Temp + Hab + Temp:Hab, data = dat)\n\nCoefficients:\n  (Intercept)           Temp       HabTeich        HabWald  Temp:HabTeich  \n       9.3750         1.1049         4.6331        -2.6065         0.9145  \n Temp:HabWald  \n      -0.5432  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nMod0<-lm(Akt~1, data=dat) \nMod.fw=step(Mod0, scope=list(lower=Mod0, upper=Mod), direction=\"forward\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=486.68\nAkt ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ Hab   2   17034.7  2602.6 308.80\n+ Temp  1    7778.7 11858.7 443.29\n+ Hum   1    4794.1 14843.3 463.49\n<none>              19637.4 486.68\n\nStep:  AIC=308.8\nAkt ~ Hab\n\n       Df Sum of Sq    RSS    AIC\n+ Temp  1    719.91 1882.7 281.66\n+ Hum   1    550.96 2051.7 289.39\n<none>              2602.6 308.80\n\nStep:  AIC=281.66\nAkt ~ Hab + Temp\n\n           Df Sum of Sq    RSS    AIC\n+ Temp:Hab  2   148.927 1733.8 278.24\n<none>                  1882.7 281.66\n+ Hum       1     1.406 1881.3 283.59\n\nStep:  AIC=278.24\nAkt ~ Hab + Temp + Hab:Temp\n\n       Df Sum of Sq    RSS    AIC\n<none>              1733.8 278.24\n+ Hum   1    0.2905 1733.5 280.23\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nMod.both=step(Mod0, scope=list(upper=Mod), direction=\"both\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=486.68\nAkt ~ 1\n\n       Df Sum of Sq     RSS    AIC\n+ Hab   2   17034.7  2602.6 308.80\n+ Temp  1    7778.7 11858.7 443.29\n+ Hum   1    4794.1 14843.3 463.49\n<none>              19637.4 486.68\n\nStep:  AIC=308.8\nAkt ~ Hab\n\n       Df Sum of Sq     RSS    AIC\n+ Temp  1     719.9  1882.7 281.66\n+ Hum   1     551.0  2051.7 289.39\n<none>               2602.6 308.80\n- Hab   2   17034.7 19637.4 486.68\n\nStep:  AIC=281.66\nAkt ~ Hab + Temp\n\n           Df Sum of Sq     RSS    AIC\n+ Temp:Hab  2     148.9  1733.8 278.24\n<none>                   1882.7 281.66\n+ Hum       1       1.4  1881.3 283.59\n- Temp      1     719.9  2602.6 308.80\n- Hab       2    9976.0 11858.7 443.29\n\nStep:  AIC=278.24\nAkt ~ Hab + Temp + Hab:Temp\n\n           Df Sum of Sq    RSS    AIC\n<none>                  1733.8 278.24\n+ Hum       1      0.29 1733.5 280.23\n- Hab:Temp  2    148.93 1882.7 281.66\n```\n:::\n:::\n\n:::\n\n## Modellvergleiche basierend auf AIC mit dregde()\n\nMit der Funktion `dredge()` aus dem Paket `MuMIn` können verschiedene *candidate models* (i.e. alle Kombinationsmöglichkeiten zwischen den Erklärungsvariablen) anhand eines Informationskriteriums z.B. `rank = \"AICc\"` verglichen werden. Weitere Informationskriterien werden über das Argument `extra = alist(AICc, AIC, BIC, Cp, \"R^2\")` berechnet. Zudem wird auch das Akaike Gewicht (`weight`) angegeben, welches eine relatives Maß für die *Wahrscheinlichkeit* (englisch: *rate of support or evidence*) ist, dass das jeweilige Modell das bessere unter den *candidate models* ist. Im Allgemeinen haben Modelle innerhalb von delta AIC \\< 2 einen ähnlich guten *support*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MuMIn)\ndd=dredge(mod)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dredge(mod): 'global.model''s 'na.action' argument is not set and options('na.action') is \"na.omit\"\n```\n:::\n:::\n\n\nWir müssen im globalen Modell `mod` das Argument `na.action` = `na.fail` setzen oder die R-Optionen mit `options(na.action = \"na.fail\")` verändern.\n\n::: callout-important\n# Wichtig\n\nEs dürfen keine *missing values (NA)* sowohl in der Abhängigen als auch in den Erklärungsvariablen vorkommen. Nutze ggfls. die Funktion `complete.cases()`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod<-lm(Weeds~Arab*Man*SQ, data=of, na.action=na.fail)\ndd=dredge(mod, rank = \"AICc\", extra = alist(AICc, AIC, BIC, \"R^2\")) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFixed term is \"(Intercept)\"\n```\n:::\n:::\n\n\nMit dem Argument `m.lim=c(0,4)` kann man die Anzahl der Parameter beschränken, z.B. auf minimal 0 und maximal 4 Parameter. Die obige Funktion würde dann so aussehen: `dredge(mod, rank = \"AICc\", extra = alist(AICc, AIC, BIC, \"R^2\"), m.lim=c(0,4))`. Da wir aber ein recht überschaubares Modell haben, ist dies nicht nötig.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n    (Int)       Arb Man         SQ Arb:Man     Arb:SQ Man:SQ Arb:Man:SQ   AICc\n12  3.984 -0.027250   +                  +                              -27.16\n16  4.025 -0.027390   + -0.0004843       +                              -24.36\n48  3.910 -0.027010   +  0.0008750       +                 +            -22.36\n32  3.807 -0.023870   +  0.0026240       + -5.212e-05                   -21.73\n64  3.687 -0.023420   +  0.0040560       + -5.315e-05      +            -19.53\n128 3.748 -0.024400   +  0.0031810       + -3.852e-05      +          + -15.99\n4   3.408 -0.017640   +                                                  14.79\n8   3.173 -0.017290   +  0.0031580                                       16.23\n24  2.453 -0.005464   +  0.0138700         -1.828e-04                    17.29\n40  2.961 -0.016800   +  0.0058460                         +             17.71\n56  2.251 -0.005091   +  0.0164200         -1.810e-04      +             18.94\n3   2.351             +                                                  56.75\n39  1.399             +  0.0140300                         +             56.85\n7   1.856             +  0.0073020                                       57.23\n2   3.847 -0.017650                                                      60.44\n6   3.884 -0.017710     -0.0005160                                       62.98\n22  4.612 -0.030090     -0.0116100          1.917e-04                    65.15\n1   2.789                                                                75.89\n5   2.549                0.0036570                                       77.99\n       AIC     BIC      R^2 df  logLik   AICc  delta weight\n12  -29.16 -21.250 0.953800  5  19.582 -27.16   0.00  0.700\n16  -27.26 -17.760 0.953900  6  19.630 -24.36   2.80  0.172\n48  -26.36 -15.280 0.955300  7  20.181 -22.36   4.80  0.063\n32  -25.73 -14.650 0.954500  7  19.865 -21.73   5.43  0.046\n64  -24.87 -12.200 0.955900  8  20.433 -19.53   7.63  0.015\n128 -22.91  -8.662 0.956000  9  20.457 -15.99  11.17  0.003\n4    13.50  19.840 0.840200  4  -2.752  14.79  41.96  0.000\n8    14.23  22.150 0.845800  5  -2.114  16.23  43.39  0.000\n24   14.39  23.900 0.853400  6  -1.197  17.29  44.45  0.000\n40   14.81  24.310 0.851700  6  -1.406  17.71  44.87  0.000\n56   14.94  26.020 0.859200  7  -0.470  18.94  46.10  0.000\n3    56.00  60.750 0.450000  3 -25.000  56.75  83.91  0.000\n39   54.85  62.770 0.523400  5 -22.424  56.85  84.01  0.000\n7    55.94  62.280 0.480600  4 -23.972  57.23  84.40  0.000\n2    59.69  64.450 0.390600  3 -26.847  60.44  87.61  0.000\n6    61.69  68.020 0.390700  4 -26.843  62.98  90.14  0.000\n22   63.15  71.060 0.399800  5 -26.573  65.15  92.31  0.000\n1    75.52  78.690 0.000000  2 -35.762  75.89 103.05  0.000\n5    77.24  81.990 0.007784  3 -35.621  77.99 105.16  0.000\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nWurden sehr viele Modelle gefittet, kann man mit dem folgenden Befehl die Top 5 sehen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndd[1:5]# die besten 5 Modelle nach AICc\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n   (Int)      Arb Man         SQ Arb:Man     Arb:SQ Man:SQ   AICc    AIC    BIC\n12 3.984 -0.02725   +                  +                   -27.16 -29.16 -21.25\n16 4.025 -0.02739   + -0.0004843       +                   -24.36 -27.26 -17.76\n48 3.910 -0.02701   +  0.0008750       +                 + -22.36 -26.36 -15.28\n32 3.807 -0.02387   +  0.0026240       + -5.212e-05        -21.73 -25.73 -14.65\n64 3.687 -0.02342   +  0.0040560       + -5.315e-05      + -19.53 -24.87 -12.20\n      R^2 df logLik   AICc delta weight\n12 0.9538  5 19.582 -27.16  0.00  0.702\n16 0.9539  6 19.630 -24.36  2.80  0.173\n48 0.9553  7 20.181 -22.36  4.80  0.064\n32 0.9545  7 19.865 -21.73  5.43  0.046\n64 0.9559  8 20.433 -19.53  7.63  0.015\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nDer Output zeigt uns\n\n-   das Modell\n-   die Modellparameter: (Int) für Intercept, Arb, Man, SQ, Arb:Ma, Arb:SQ, und Man:SQ\n    -   wobei für Faktoren nur ein + angezeigt wird, wenn diese im Modell enthalten sind\n    -   für kontinuierliche Erklärungsvariablen wird der geschätzte Koeffizient angezeigt\n-   die Informationskriterien: AICc, AIC, BIC, R²\n-   die degree of freedoms und die Log-Likelihood\n-   das Informationskriterium, welches zum Vergleich der Modelle genutzt wurde (hier AICc)\n-   das daraus berechnete delta (hier delta AICc)\n-   das Akaike weight, welches alle `candidate models` vergleicht (die Summe ergibt 1) und damit ein Maß für *relative* Güte der Modelle ist.\n\nMit der Funktion `subset()` werden die Top-Modelle innerhalb delta AICc \\< 4 (oder \\<2) angezeigt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubset(dd, delta < 4) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Weeds ~ Arab * Man * SQ, data = of, na.action = na.fail)\n---\nModel selection table \n   (Int)      Arb Man         SQ Arb:Man   AICc    AIC    BIC    R^2 df logLik\n12 3.984 -0.02725   +                  + -27.16 -29.16 -21.25 0.9538  5 19.582\n16 4.025 -0.02739   + -0.0004843       + -24.36 -27.26 -17.76 0.9539  6 19.630\n     AICc delta weight\n12 -27.16   0.0  0.802\n16 -24.36   2.8  0.198\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nZur Präsentation der Ergebnisse würde man zur obigen Tabelle noch das **globale Modell** und das **Nullmodell** hinzufügen.\n\nDas beste Modell mit dem niedrigsten AICc ist wieder:\\\n`Weeds ~ Arab + Man + Arab:Man`\n\nWir können auf das beste Model mit der Funktion `get.models()` zugreifen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(get.models(dd, 1)[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Arab + Man + Arab:Man + 1, data = of, na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.dd=get.models(dd, 1)[[1]]\n```\n:::\n\n\nDie Bedeutung der Erklärungsvariablen (*Importance*) kann durch das *sum of Akaike weight* berechnet werden, indem für alle Variablen die Akaike Gewichte der Modelle aufsummiert werden, in denen die Variable enthalten ist. Die entsprechenden *sum of Akaike weights* variieren dann zwischen 1 (wichtig) und 0 (unwichtig).\n\nMit der Funktion `sw()` wird das *sum of Akaike weight* über alle Modelle berechnet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsw(dd)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Arab  Man   Arab:Man SQ    Man:SQ Arab:SQ Arab:Man:SQ\nSum of weights:          1     1     1      0.3  0.08   0.06   <0.01      \nN containing models:    14    14     6       14     6      6       1      \n```\n:::\n:::\n\n\nMit dem Argument `subset` wird das *sum of Akaike weight* über alle Modelle innerhalb delta AICc \\< 4 berechnet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsw(subset(dd, delta <= 4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     Arab Man Arab:Man SQ \nSum of weights:      1.0  1.0 1.0      0.2\nN containing models:   2    2   2        1\n```\n:::\n:::\n\n\nBurnham and Anderson (2002) empfehlen die erste Methode.\n\n## Modellvergleiche basierend auf AIC mit eigenem Set an Candidate Models\n\nWenn man ein sehr komplexes globales Modell mit vielen Erklärungsvariablen und Interaktionen hat, kann das zu sehr vielen *candidate models* führen. Das wird dann auch gerne als *\"fishing\"* bezeichnet und wird ebenso wenig gern gesehen. Daher empfehlen Burnham und Anderson (2002) *a priori* ein Set an *candidate models* zu erstellen und diese zu vergleichen.\n\nAuch hierfür kann das Packet `MuMIn` genutzt werden.\n\nBeispiel angepasst aus: [https://sites.google.com/site/rforfishandwildlifegrads/home/mumin_usage_examples](https://sites.google.com/site/rforfishandwildlifegrads/home/mumin_usage_examples){target=\"_blank\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MuMIn)\noptions(na.action = \"na.fail\") # wir ändern die globalen Optionen\n```\n:::\n\n\nWir erstellen das globale Modell `mod` und verschiedene *candidate models* `mod1` bis `mod11` und das Nullmodell `mod0`. Natürlich können nur Modelle als \"beste\" Modelle identifiziert werden, wenn sie vorher auch gefittet wurden. Daher ist die Wahl der geeigneten *candidate models* die größte wissenschaftliche Herausforderung.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod<-lm(Weeds~Arab*Man*SQ, data=of)\nmod1<-lm(Weeds~Arab*Man+SQ, data=of)\nmod2<-lm(Weeds~Arab+Man*SQ, data=of)\nmod3<-lm(Weeds~Arab*SQ+Man, data=of)\nmod4<-lm(Weeds~Arab*Man, data=of)\nmod5<-lm(Weeds~Man*SQ, data=of)\nmod6<-lm(Weeds~Arab*SQ, data=of)\nmod7<-lm(Weeds~Arab+Man, data=of)\nmod8<-lm(Weeds~Man+SQ, data=of)\nmod9<-lm(Weeds~Arab+SQ, data=of)\nmod10<-lm(Weeds~Arab+Man+SQ, data=of)\nmod0<-lm(Weeds~1, data=of)\nmod11<-lm(Weeds~(Arab+Man+SQ)^2, data=of)# ist das gleiche wie Arab*Man+Arab*SQ+Man*SQ\n```\n:::\n\n\nWir nutzen die Funktion `mod.sel()`, um für alle Modelle das AICc, delta AICc und das *Akaike weight* zu berechnen und ins Objekt `out.put` zu schreiben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout.put<-model.sel(mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, mod,mod0)\nout.put \n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel selection table \n      (Int)       Arb Man         SQ Arb:Man Man:SQ     Arb:SQ Arb:Man:SQ df\nmod4  3.984 -0.027250   +                  +                               5\nmod1  4.025 -0.027390   + -0.0004843       +                               6\nmod11 3.687 -0.023420   +  0.0040560       +      + -5.315e-05             8\nmod   3.748 -0.024400   +  0.0031810       +      + -3.852e-05          +  9\nmod7  3.408 -0.017640   +                                                  4\nmod10 3.173 -0.017290   +  0.0031580                                       5\nmod3  2.453 -0.005464   +  0.0138700                -1.828e-04             6\nmod2  2.961 -0.016800   +  0.0058460              +                        6\nmod5  1.399             +  0.0140300              +                        5\nmod8  1.856             +  0.0073020                                       4\nmod9  3.884 -0.017710     -0.0005160                                       4\nmod6  4.612 -0.030090     -0.0116100                 1.917e-04             5\nmod0  2.789                                                                2\n       logLik  AICc  delta weight\nmod4   19.582 -27.2   0.00  0.786\nmod1   19.630 -24.4   2.80  0.194\nmod11  20.433 -19.5   7.63  0.017\nmod    20.457 -16.0  11.17  0.003\nmod7   -2.752  14.8  41.96  0.000\nmod10  -2.114  16.2  43.39  0.000\nmod3   -1.197  17.3  44.45  0.000\nmod2   -1.406  17.7  44.87  0.000\nmod5  -22.424  56.8  84.01  0.000\nmod8  -23.972  57.2  84.40  0.000\nmod9  -26.843  63.0  90.14  0.000\nmod6  -26.573  65.1  92.31  0.000\nmod0  -35.762  75.9 103.05  0.000\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nMit dem Argument `rank` können wir auch ein anderes Informationskriterium wählen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout.put2<-model.sel(mod1,mod2,mod3,mod4,mod5,mod6,mod7,mod8,mod9,mod10,mod11, mod,mod0, rank=\"AIC\")\nout.put2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel selection table \n      (Int)       Arb Man         SQ Arb:Man Man:SQ     Arb:SQ Arb:Man:SQ df\nmod4  3.984 -0.027250   +                  +                               5\nmod1  4.025 -0.027390   + -0.0004843       +                               6\nmod11 3.687 -0.023420   +  0.0040560       +      + -5.315e-05             8\nmod   3.748 -0.024400   +  0.0031810       +      + -3.852e-05          +  9\nmod7  3.408 -0.017640   +                                                  4\nmod10 3.173 -0.017290   +  0.0031580                                       5\nmod3  2.453 -0.005464   +  0.0138700                -1.828e-04             6\nmod2  2.961 -0.016800   +  0.0058460              +                        6\nmod5  1.399             +  0.0140300              +                        5\nmod8  1.856             +  0.0073020                                       4\nmod9  3.884 -0.017710     -0.0005160                                       4\nmod6  4.612 -0.030090     -0.0116100                 1.917e-04             5\nmod0  2.789                                                                2\n       logLik   AIC  delta weight\nmod4   19.582 -29.2   0.00  0.647\nmod1   19.630 -27.3   1.90  0.250\nmod11  20.433 -24.9   4.30  0.075\nmod    20.457 -22.9   6.25  0.028\nmod7   -2.752  13.5  42.67  0.000\nmod10  -2.114  14.2  43.39  0.000\nmod3   -1.197  14.4  43.56  0.000\nmod2   -1.406  14.8  43.98  0.000\nmod5  -22.424  54.8  84.01  0.000\nmod8  -23.972  55.9  85.11  0.000\nmod9  -26.843  61.7  90.85  0.000\nmod6  -26.573  63.1  92.31  0.000\nmod0  -35.762  75.5 104.69  0.000\nModels ranked by AIC(x) \n```\n:::\n:::\n\n\nWir erstellen nun eine Tabelle mit den Informationskriterien und den Erklärungsvariablen der Modelle.\\\nDie `[c(9,11:13)]` greifen auf 4 Spalten zu und müssen bei anderen Beispielen entsprechend der Anzahl Spalten (i.e. Erklärungsvariablen) ggfls. angepasst werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel.table<-as.data.frame(out.put)[c(9,11:13)]\nsel.table \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      df      AICc      delta       weight\nmod4   5 -27.16372   0.000000 7.860065e-01\nmod1   6 -24.36270   2.801024 1.937276e-01\nmod11  8 -19.53353   7.630191 1.732013e-02\nmod    9 -15.99053  11.173195 2.945762e-03\nmod7   4  14.79426  41.957989 6.086458e-10\nmod10  5  16.22886  43.392586 2.970611e-10\nmod3   6  17.29047  44.454197 1.747108e-10\nmod2   6  17.70841  44.872130 1.417643e-10\nmod5   5  56.84831  84.012037 4.492046e-19\nmod8   4  57.23396  84.397687 3.704258e-19\nmod9   4  62.97609  90.139816 2.098040e-20\nmod6   5  65.14594  92.309661 7.089866e-21\nmod0   2  75.88754 103.051259 3.297080e-23\n```\n:::\n:::\n\n\nZur besseren Lesbarkeit runden wir die Spalten 2 und 3 auf 1 Kommastelle und Spalten 4 auf 2 Kommastellen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel.table[,2:3]<- round(sel.table[,2:3],1)\nsel.table[,4]<- round(sel.table[,4],2)\n```\n:::\n\n\nWir schreiben den Modellnamen in Spalte `Model`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel.table$Model<-rownames(sel.table)\nsel.table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      df  AICc delta weight Model\nmod4   5 -27.2   0.0   0.79  mod4\nmod1   6 -24.4   2.8   0.19  mod1\nmod11  8 -19.5   7.6   0.02 mod11\nmod    9 -16.0  11.2   0.00   mod\nmod7   4  14.8  42.0   0.00  mod7\nmod10  5  16.2  43.4   0.00 mod10\nmod3   6  17.3  44.5   0.00  mod3\nmod2   6  17.7  44.9   0.00  mod2\nmod5   5  56.8  84.0   0.00  mod5\nmod8   4  57.2  84.4   0.00  mod8\nmod9   4  63.0  90.1   0.00  mod9\nmod6   5  65.1  92.3   0.00  mod6\nmod0   2  75.9 103.1   0.00  mod0\n```\n:::\n:::\n\n\n... und schreiben nun die Modellformel in diese Spalte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor(i in 1:nrow(sel.table)) sel.table$Model[i]<- as.character(formula(noquote(sel.table$Model[i]))$call)[2]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsel.table \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      df  AICc delta weight                       Model\nmod4   5 -27.2   0.0   0.79          Weeds ~ Arab * Man\nmod1   6 -24.4   2.8   0.19     Weeds ~ Arab * Man + SQ\nmod11  8 -19.5   7.6   0.02 Weeds ~ (Arab + Man + SQ)^2\nmod    9 -16.0  11.2   0.00     Weeds ~ Arab * Man * SQ\nmod7   4  14.8  42.0   0.00          Weeds ~ Arab + Man\nmod10  5  16.2  43.4   0.00     Weeds ~ Arab + Man + SQ\nmod3   6  17.3  44.5   0.00     Weeds ~ Arab * SQ + Man\nmod2   6  17.7  44.9   0.00     Weeds ~ Arab + Man * SQ\nmod5   5  56.8  84.0   0.00            Weeds ~ Man * SQ\nmod8   4  57.2  84.4   0.00            Weeds ~ Man + SQ\nmod9   4  63.0  90.1   0.00           Weeds ~ Arab + SQ\nmod6   5  65.1  92.3   0.00           Weeds ~ Arab * SQ\nmod0   2  75.9 103.1   0.00                   Weeds ~ 1\n```\n:::\n:::\n\n\nAuch hier könnten wir wieder die Tabelle auf die Modelle reduzieren innerhalb delta AICc \\< 4 plus globales Modell und Nullmodell.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel.table[c(1,2,4,13),c(5,1:4)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       Model df  AICc delta weight\nmod4      Weeds ~ Arab * Man  5 -27.2   0.0   0.79\nmod1 Weeds ~ Arab * Man + SQ  6 -24.4   2.8   0.19\nmod  Weeds ~ Arab * Man * SQ  9 -16.0  11.2   0.00\nmod0               Weeds ~ 1  2  75.9 103.1   0.00\n```\n:::\n:::\n\n\n## Modellvergleiche basierend auf AIC mit glmulti()\n\nEin weiteres Package für Modellvergleiche ist `glmulti` mit gleichnamiger Funktion. Hier können wir eine Vielzahl an Erklärungsvariablen in einem Vektor (hier `pred.var`) im Argument `xr` angeben. Mit `maxsize` legen wir die maximale Anzahl an Erklärungsvariablen fest. Mit `level=1` werden nur Haupteffekte gefittet (Bsp. `models1`), mit `level=2` werden Haupteffekte und Zweifachinteraktionen gefittet (Bsp. `models2`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glmulti)\npred.var=c(\"Arab\", \"Man\", \"SQ\")# alle Erklärungsvariablen\n\nmodels1 <- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8, # max 8 Erklärungsvariablen im Modell -> hier nicht wichtig   \n                     level = 1,  #  nur Haupteffekte\n                     fitfunc = lm,  # lineares Model\n                     confsetsize = 10,  # damit kann man die Anzahl der besten Modelle, die in models1 gespeichert werden, begrenzen\n                     marginality=TRUE,  # zur Erklärung vergleiche Bsp. models2 mit models3\n                     plotty = F, report = F)\ntmp_1 <- weightable(models1)\ntmp_1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                        model     aicc      weights\n1      Weeds ~ 1 + Man + Arab 14.79426 6.720119e-01\n2 Weeds ~ 1 + Man + Arab + SQ 16.22886 3.279881e-01\n3             Weeds ~ 1 + Man 56.75004 5.209496e-10\n4        Weeds ~ 1 + Man + SQ 57.23396 4.089908e-10\n5            Weeds ~ 1 + Arab 60.44469 8.213205e-11\n6       Weeds ~ 1 + Arab + SQ 62.97609 2.316467e-11\n7                   Weeds ~ 1 75.88754 3.640339e-14\n8              Weeds ~ 1 + SQ 77.99259 1.270677e-14\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels2 <- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8, \n                     level = 2,  # fit Haupteffekte und Zweifachinteraktionen  \n                     confsetsize = 10,  \n                     marginality=TRUE,  \n                  plotty = F, report = F)\ntmp_2 <- weightable(models2)\ntmp_2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                       model      aicc\n1                          Weeds ~ 1 + Man + Arab + Man:Arab -27.16372\n2                     Weeds ~ 1 + Man + Arab + SQ + Man:Arab -24.36270\n3            Weeds ~ 1 + Man + Arab + SQ + Man:Arab + Man:SQ -22.36104\n4           Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:Arab -21.73091\n5  Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:Arab + Man:SQ -19.53353\n6                                     Weeds ~ 1 + Man + Arab  14.79426\n7                                Weeds ~ 1 + Man + Arab + SQ  16.22886\n8                      Weeds ~ 1 + Man + Arab + SQ + SQ:Arab  17.29047\n9                       Weeds ~ 1 + Man + Arab + SQ + Man:SQ  17.70841\n10            Weeds ~ 1 + Man + Arab + SQ + SQ:Arab + Man:SQ  18.93916\n        weights\n1  7.016487e-01\n2  1.729359e-01\n3  6.356687e-02\n4  4.638730e-02\n5  1.546125e-02\n6  5.433232e-10\n7  2.651791e-10\n8  1.559601e-10\n9  1.265495e-10\n10 6.839188e-11\n```\n:::\n:::\n\n\nMit dem Argument `marginality=FALSE` werden auch Modelle mit Interaktionen ohne Haupteffekte gefittet. Hierzu gibt es geteilte Meinungen. Es entstehen mehr mögliche Modelle aus denen das/die beste/n Modell/e gewählt werden können. Gleichzeitig kann aber damit auch ein einfacheres Modell mit weniger Erklärungsvariablen gewählt werden.\n\nIm Bespiel `models3` sieht man als zweitbestes Modell `Weeds ~ Arab + Man:Arab`, welches ohne Haupteffekt `Man` gefittet ist.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels3 <- glmulti(\"Weeds\", xr= pred.var, of, crit = aicc, \n                     maxsize = 8,  \n                     level = 2, \n                     confsetsize = 10,  \n                     marginality=FALSE,  # fit interaction even if main term is not in the model\n                  plotty = F, report = F)\ntmp_3 <- weightable(models3)\ntmp_3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                 model      aicc    weights\n1                    Weeds ~ 1 + Man + Arab + Man:Arab -27.16372 0.32769924\n2                          Weeds ~ 1 + Arab + Man:Arab -25.96858 0.18028255\n3            Weeds ~ 1 + Arab + SQ + Man:Arab + Man:SQ -25.43742 0.13823316\n4          Weeds ~ 1 + Man + Arab + SQ:Arab + Man:Arab -24.53325 0.08795781\n5               Weeds ~ 1 + Man + Arab + SQ + Man:Arab -24.36270 0.08076828\n6                     Weeds ~ 1 + Arab + SQ + Man:Arab -23.32596 0.04809674\n7                Weeds ~ 1 + Arab + SQ:Arab + Man:Arab -23.27813 0.04696025\n8  Weeds ~ 1 + Arab + SQ + SQ:Arab + Man:Arab + Man:SQ -22.86406 0.03817823\n9      Weeds ~ 1 + Man + Arab + SQ + Man:Arab + Man:SQ -22.36104 0.02968838\n10          Weeds ~ 1 + Arab + SQ + SQ:Arab + Man:Arab -21.77388 0.02213536\n```\n:::\n:::\n\n\nAlle hier aufgeführten Wege haben zum gleichen besten Modell geführt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Weeds ~ Arab * Man, data = of)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27082 -0.12469  0.01851  0.09372  0.25381 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  3.983767   0.097888  40.697  < 2e-16 ***\nArab        -0.027254   0.001525 -17.868  < 2e-16 ***\nManorg      -0.263862   0.137806  -1.915   0.0645 .  \nArab:Manorg  0.019036   0.002146   8.869 3.92e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.149 on 32 degrees of freedom\nMultiple R-squared:  0.9538,\tAdjusted R-squared:  0.9495 \nF-statistic: 220.2 on 3 and 32 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n::: callout-tip\nDie Wahl des besten Modells basiert zwar immer auf einem Informationskriterium (AIC, BIC), der/die R-UserIn kann sich aber auch für das zweit- oder drittbeste Modell entscheiden, wenn darin bspw. Erklärungsvariablen sind, die einfacher oder schneller zu messen sind und das Modell für zukünftige Vorhersagen genutzt werden soll.\n:::\n\n## Übung 6.3.\n\n-   Modelliere die Aktivität der Lurche mit der dredge-Funktion.\n\n::: {.callout-tip collapse=\"true\"}\nBitte schau Dir die Lösung bis ganz zum Ende an.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MuMIn)\nMod=lm(Akt~Temp*Hab*Hum, data=dat, na.action = na.fail) # Modell mit korrelierten Erklärungsvaribalen\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndd=dredge(Mod)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFixed term is \"(Intercept)\"\n```\n:::\n\n```{.r .cell-code}\ndd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n      (Int) Hab      Hum      Tmp Hab:Hum Hab:Tmp Hum:Tmp Hab:Hum:Tmp df\n22    9.375   +           1.10500               +                      7\n24    9.053   +  0.02051  1.06000               +                      8\n16   12.600   + -0.07901  1.14000       +                              8\n6     6.560   +           1.29900                                      5\n40   52.490   + -0.93190 -1.82300                 0.06228              7\n56   25.740   + -0.33500 -0.03249               + 0.02292              9\n48   23.910   + -0.31840  0.38980       +         0.01563              9\n8     5.786   +  0.04491  1.20600                                      6\n32   13.770   + -0.27980  1.71600       +       +                     10\n12   10.290   +  0.31910                +                              7\n64   25.150   + -0.51900  0.95400       +       + 0.01574             11\n128  44.580   + -0.92740 -0.34630       +       + 0.04262           + 13\n4     3.336   +  0.46600                                               5\n2    25.410   +                                                        4\n5   -26.060               3.70300                                      3\n39   82.750     -2.53700 -1.81600                 0.13170              5\n7   -16.430     -0.49340  4.68300                                      4\n3   -32.960      1.26400                                               3\n1    29.100                                                            2\n      logLik  AICc  delta weight\n22  -260.826 537.0   0.00  0.410\n24  -260.819 539.4   2.40  0.124\n16  -260.863 539.5   2.49  0.118\n6   -264.534 539.8   2.76  0.103\n40  -262.433 540.2   3.21  0.082\n56  -260.617 541.5   4.47  0.044\n48  -260.789 541.8   4.81  0.037\n8   -264.501 542.0   5.00  0.034\n32  -259.863 542.5   5.49  0.026\n12  -264.635 544.6   7.62  0.009\n64  -259.787 545.0   7.94  0.008\n128 -258.319 547.4  10.41  0.002\n4   -268.402 547.5  10.50  0.002\n2   -279.106 566.7  29.66  0.000\n5   -347.350 701.0 163.96  0.000\n39  -345.135 701.0 163.97  0.000\n7   -346.638 701.7 164.73  0.000\n3   -357.452 721.2 184.16  0.000\n1   -370.047 744.2 207.21  0.000\nModels ranked by AICc(x) \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndd[1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n    (Int) Hab      Hum    Tmp Hab:Hum Hab:Tmp Hum:Tmp df   logLik  AICc delta\n22  9.375   +           1.105               +          7 -260.826 537.0  0.00\n24  9.053   +  0.02051  1.060               +          8 -260.819 539.4  2.40\n16 12.600   + -0.07901  1.140       +                  8 -260.863 539.5  2.49\n6   6.560   +           1.299                          5 -264.534 539.8  2.76\n40 52.490   + -0.93190 -1.823                 0.06228  7 -262.433 540.2  3.21\n   weight\n22  0.490\n24  0.148\n16  0.141\n6   0.123\n40  0.098\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nWir haben 5 Modelle innerhalb dAICc\\<4 und ein bestes Modell innerhalb dAICc\\<2.\n\nDas beste Modell hat die Erklärungsvariablen Habitattype und Temperatur und deren Zweifachinteraktion. Sowohl im zweit- als auch drittbesten Modell sind beide korrelierte Erklärungsvariablen enthalten.\n\nSchauen wir uns die Modellkoeffizienten und die Effektplots an:\n\n-   bestes Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(effects)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nlattice theme set by effectsTheme()\nSee ?effectsTheme for details.\n```\n:::\n\n```{.r .cell-code}\nsummary(get.models(dd, 1)[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Hab + Temp + Hab:Temp + 1, data = dat, na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.8564  -2.7385  -0.2605   2.4763  10.2738 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)   \n(Intercept)     9.3750     5.3346   1.757  0.08249 . \nHabTeich        4.6331     8.0730   0.574  0.56757   \nHabWald        -2.6065     7.9357  -0.328  0.74339   \nTemp            1.1049     0.3632   3.042  0.00313 **\nHabTeich:Temp   0.9145     0.5128   1.783  0.07812 . \nHabWald:Temp   -0.5432     0.5612  -0.968  0.33588   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.543 on 84 degrees of freedom\nMultiple R-squared:  0.9117,\tAdjusted R-squared:  0.9065 \nF-statistic: 173.5 on 5 and 84 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nplot(allEffects(get.models(dd, 1)[[1]]))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-69-1.png){width=672}\n:::\n:::\n\n\n-   zweitbestes Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(get.models(dd, 2)[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Hab + Hum + Temp + Hab:Temp + 1, data = dat, \n    na.action = na.fail)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-11.821  -2.713  -0.283   2.507  10.263 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)  \n(Intercept)    9.05305    6.02059   1.504   0.1365  \nHabTeich       4.60112    8.12537   0.566   0.5727  \nHabWald       -2.73638    8.05836  -0.340   0.7350  \nHum            0.02051    0.17389   0.118   0.9064  \nTemp           1.06011    0.52679   2.012   0.0474 *\nHabTeich:Temp  0.91598    0.51598   1.775   0.0795 .\nHabWald:Temp  -0.53702    0.56699  -0.947   0.3463  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.57 on 83 degrees of freedom\nMultiple R-squared:  0.9117,\tAdjusted R-squared:  0.9053 \nF-statistic: 142.9 on 6 and 83 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nplot(allEffects(get.models(dd, 2)[[1]]))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-70-1.png){width=672}\n:::\n:::\n\n\n-   drittbestes Modell\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(get.models(dd, 3)[[1]])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Akt ~ Hab + Hum + Temp + Hab:Hum + 1, data = dat, \n    na.action = na.fail)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-12.3545  -2.7392   0.1654   2.8545  10.4962 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  12.60260    7.02675   1.794  0.07653 . \nHabTeich     -4.18843   10.58337  -0.396  0.69330   \nHabWald      -6.13322   11.06999  -0.554  0.58104   \nHum          -0.07901    0.20786  -0.380  0.70482   \nTemp          1.14035    0.42328   2.694  0.00854 **\nHabTeich:Hum  0.46479    0.21054   2.208  0.03003 * \nHabWald:Hum  -0.07998    0.23187  -0.345  0.73103   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.572 on 83 degrees of freedom\nMultiple R-squared:  0.9116,\tAdjusted R-squared:  0.9052 \nF-statistic: 142.7 on 6 and 83 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\nplot(allEffects(get.models(dd, 3)[[1]]))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-71-1.png){width=672}\n:::\n:::\n\n\nDas zweitbeste Modell zeigt sehr breite Konfidenzintervalle für die Luftfeuchte und das drittbeste Modell sehr unwahrscheinliche Zusammenhänge mit der Luftfeuchte in den verschiedenen Habitaten.\n\nDaher würde ich diese Modelle nicht interpretieren. Um diese Modelle aufgrund der engen Korrelation aus den *candidate models* auszuschließen, gibt es folgende Möglichkeit:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndd1=dredge(Mod, subset = !(Temp & Hum))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nFixed term is \"(Intercept)\"\n```\n:::\n\n```{.r .cell-code}\ndd1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGlobal model call: lm(formula = Akt ~ Temp * Hab * Hum, data = dat, na.action = na.fail)\n---\nModel selection table \n     (Int) Hab    Hum   Tmp Hab:Hum Hab:Tmp df   logLik  AICc  delta weight\n22   9.375   +        1.105               +  7 -260.826 537.0   0.00  0.782\n6    6.560   +        1.299                  5 -264.534 539.8   2.76  0.196\n12  10.290   + 0.3191             +          7 -264.635 544.6   7.62  0.017\n4    3.336   + 0.4660                        5 -268.402 547.5  10.50  0.004\n2   25.410   +                               4 -279.106 566.7  29.66  0.000\n5  -26.060            3.703                  3 -347.350 701.0 163.96  0.000\n3  -32.960     1.2640                        3 -357.452 721.2 184.16  0.000\n1   29.100                                   2 -370.047 744.2 207.21  0.000\nModels ranked by AICc(x) \n```\n:::\n:::\n\n\nHier werden nur Modelle verglichen, die entweder Temperatur oder Luftfeuchte enthalten.\n:::\n\n## Modelldiagnostik\n\nBevor wir das Modell interpretieren, sollten die Modellannahmen visuell überprüft werden, indem wir die Residuen des Modells plotten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is DHARMa 0.4.6. For overview type '?DHARMa'. For recent changes, type news(package = 'DHARMa')\n```\n:::\n\n```{.r .cell-code}\nsimulationOutput <- simulateResiduals(fittedModel = mod4, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-73-1.png){width=672}\n:::\n:::\n\n\nKeine Auffälligkeiten.\n\nNun plotten wir noch die Residuen gegen die Erklärungsvariablen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = of$Man)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-74-1.png){width=672}\n:::\n:::\n\n\nDie Varianzen der Residuen sind sehr ähnlich. Wir erinnern uns an den Plot Weeds \\~ Man, wo starke Unterschiede in den Varianzen vorkamen. Offensichtlich hat die Erklärungsvariable `Arab` einen Großteil dieser Variabilität erklärt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = of$Arab)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-75-1.png){width=672}\n:::\n:::\n\n\nHier sehen wir eine leichte Kurvatur bei niedrigen Werten in Arab, aber es scheint noch ok zu sein. Wir können zusätzlich noch die vom Modell vorhergesagten vs. gemessenen Daten plotten. Je enger die Beziehung, desto besser.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nof$fit=predict(mod4)\nggplot(of, aes(y=Weeds, x=fit, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=\"lm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-76-1.png){width=672}\n:::\n:::\n\n\n## Modellinterpretation\n\n### schnell und einfach mit `library(effects)`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(effects)\nplot(allEffects(mod4))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-77-1.png){width=518.4}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(Effect(c(\"Man\"), mod4))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-78-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(Effect(c(\"Arab\"), mod4, partial.residuals=TRUE))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-78-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nef=allEffects(mod4, xlevels=100)\t\nef1=as.data.frame(ef[[1]])\t\nhead(ef1)\t\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Arab Man      fit         se    lower    upper\n1 21.2 con 3.405986 0.06869007 3.266069 3.545903\n2 21.9 con 3.386908 0.06777461 3.248856 3.524961\n3 22.7 con 3.365105 0.06673391 3.229173 3.501038\n4 23.4 con 3.346027 0.06582835 3.211939 3.480115\n5 24.1 con 3.326950 0.06492773 3.194696 3.459203\n6 24.9 con 3.305147 0.06390474 3.174977 3.435316\n```\n:::\n\n```{.r .cell-code}\ntail(ef1)\t\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Arab Man      fit         se    lower    upper\n195 90.4 org 2.976989 0.05793205 2.858985 3.094992\n196 91.2 org 2.970414 0.05889737 2.850444 3.090384\n197 91.9 org 2.964662 0.05974927 2.842956 3.086367\n198 92.6 org 2.958909 0.06060762 2.835455 3.082363\n199 93.4 org 2.952334 0.06159616 2.826867 3.077802\n200 94.1 org 2.946582 0.06246746 2.819340 3.073824\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = ef1, aes(x = Arab, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Man), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef1, aes(x = Arab, y = fit))+\n  geom_point()+\n  ylab(\"Shannondiversität\")+xlab(\"Ackeranteil (%)\")\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-80-1.png){width=672}\n:::\n:::\n\n\nWir sehen, dass die Diversität\n\n-   mit zunehmendem Ackeranteil sinkt\n-   generell höher in öko vs. konventionell ist\n-   aber je strukturreicher eine Landschaft (je niedriger der Ackeranteil) desto kleiner fallen auch die Unterschiede zwischen öko vs. konventionell bewirtschafteten Feldern aus.\n\nWir können dies auch gezielt mit einem Posthoc-Test testen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(mod4, ~Man|Arab, at=list(Arab=c(22,80))), Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArab = 22:\n Man emmean     SE df lower.CL upper.CL .group\n con   3.38 0.0676 32     3.25     3.52  a    \n org   3.54 0.0671 32     3.40     3.68  a    \n\nArab = 80:\n Man emmean     SE df lower.CL upper.CL .group\n con   1.80 0.0466 32     1.71     1.90  a    \n org   3.06 0.0464 32     2.97     3.16   b   \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\nHier wird nun an zwei gewählten Punkten (i.e. Ackeranteil von 22% und 80%) die vorhergesagte Diversität in öko vs. kon gestestet. Bei 22% Ackeranteil unterscheidet sich die Diversität nicht signifikant zwischen öko und konventionall, bei 80% Ackeranteil schon.\n\nMan beachte den Unterschied zu folgendem Test, bei dem alle vorhergesagten Levels miteinander verglichen werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(emmeans(mod4, ~Man+Arab, at=list(Arab=c(22,80))), sort=F, Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Man Arab emmean     SE df lower.CL upper.CL .group\n con   22   3.38 0.0676 32     3.25     3.52  a    \n org   22   3.54 0.0671 32     3.40     3.68  a    \n con   80   1.80 0.0466 32     1.71     1.90   b   \n org   80   3.06 0.0464 32     2.97     3.16    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 4 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\nDie 22% und 80% sind hier relativ willkürlich gewählt (i.e. zur Demonstration). Man hätte auch das 20- und 80-Perzentil wählen können.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(emmeans(mod4, ~Man|Arab, at=list(Arab=quantile(of$Arab, p=c(0.2,0.8)))), sort=F, Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nArab = 36.1:\n Man emmean     SE df lower.CL upper.CL .group\n con   3.00 0.0505 32     2.90     3.10  a    \n org   3.42 0.0502 32     3.32     3.53   b   \n\nArab = 84.5:\n Man emmean     SE df lower.CL upper.CL .group\n con   1.68 0.0514 32     1.58     1.79  a    \n org   3.03 0.0511 32     2.92     3.13   b   \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\n### Weitere Alternativen zur Modellinterpretation, i.e. Abbildung der Ergebnisse:\n\n#### mit geom_smooth\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_point()+\n  geom_smooth(method=lm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-84-1.png){width=672}\n:::\n:::\n\n\n#### mit predict\n\nWir erstellen einen Testdatensatz `td` mit allen im besten Modell (`mod4`) enthaltenen Variablen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(of)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       ID         Man          Arab             SQ            Weeds      \n Min.   : 1.00   con:18   Min.   :21.20   Min.   :38.00   Min.   :1.410  \n 1st Qu.: 9.75   org:18   1st Qu.:41.15   1st Qu.:54.75   1st Qu.:2.438  \n Median :18.50            Median :60.50   Median :62.50   Median :2.980  \n Mean   :18.50            Mean   :59.89   Mean   :65.83   Mean   :2.789  \n 3rd Qu.:27.25            3rd Qu.:80.65   3rd Qu.:79.25   3rd Qu.:3.290  \n Max.   :36.00            Max.   :94.10   Max.   :95.00   Max.   :3.570  \n    Man.con         fit       \n Min.   :0.0   Min.   :1.419  \n 1st Qu.:0.0   1st Qu.:2.373  \n Median :0.5   Median :3.006  \n Mean   :0.5   Mean   :2.789  \n 3rd Qu.:1.0   3rd Qu.:3.295  \n Max.   :1.0   Max.   :3.544  \n```\n:::\n\n```{.r .cell-code}\ntd<-expand.grid(Arab=seq(21,94,length=10), Man=c(\"con\",\"org\")) \ntd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Arab Man\n1  21.00000 con\n2  29.11111 con\n3  37.22222 con\n4  45.33333 con\n5  53.44444 con\n6  61.55556 con\n7  69.66667 con\n8  77.77778 con\n9  85.88889 con\n10 94.00000 con\n11 21.00000 org\n12 29.11111 org\n13 37.22222 org\n14 45.33333 org\n15 53.44444 org\n16 61.55556 org\n17 69.66667 org\n18 77.77778 org\n19 85.88889 org\n20 94.00000 org\n```\n:::\n:::\n\n\nund nutzen in der `predict`-Funktion das Argument `interval = \"confidence\"` für die Berechnung des Konfidenzintervalls.\n\n**Das Konfidenzintervall**\n\n-   zeigt an, in welchem Bereich mit 95 %-er Wahrscheinlichkeit unser \"wahrer\" Mittelwert liegt\n-   wird kleiner mit größer werdendem Stichprobenumfang\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntd<-data.frame(td, predict(mod4, newdata=td, interval = \"confidence\"))\ntd\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       Arab Man      fit      lwr      upr\n1  21.00000 con 3.411437 3.270985 3.551888\n2  29.11111 con 3.190378 3.070923 3.309832\n3  37.22222 con 2.969319 2.868908 3.069730\n4  45.33333 con 2.748260 2.663611 2.832909\n5  53.44444 con 2.527201 2.452914 2.601488\n6  61.55556 con 2.306142 2.234435 2.377849\n7  69.66667 con 2.085083 2.007396 2.162771\n8  77.77778 con 1.864025 1.773477 1.954572\n9  85.88889 con 1.642966 1.535111 1.750820\n10 94.00000 con 1.421907 1.294093 1.549721\n11 21.00000 org 3.547325 3.407978 3.686672\n12 29.11111 org 3.480667 3.362037 3.599297\n13 37.22222 org 3.414009 3.314143 3.513875\n14 45.33333 org 3.347351 3.262982 3.431721\n15 53.44444 org 3.280693 3.206479 3.354908\n16 61.55556 org 3.214035 3.142327 3.285744\n17 69.66667 org 3.147377 3.069782 3.224973\n18 77.77778 org 3.080719 2.990472 3.170967\n19 85.88889 org 3.014061 2.906763 3.121360\n20 94.00000 org 2.947404 2.820416 3.074391\n```\n:::\n:::\n\n\nAlternativ nutzen wir die `predict`-Funktion mit dem Argument `se.fit` für die Berechnung der Standardfehler, die wir für die Berechnung des Konfidenzintervalls nutzen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np<-predict(mod4, newdata=td, se.fit=T) \nstr(p)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 4\n $ fit           : Named num [1:20] 3.41 3.19 2.97 2.75 2.53 ...\n  ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ...\n $ se.fit        : Named num [1:20] 0.069 0.0586 0.0493 0.0416 0.0365 ...\n  ..- attr(*, \"names\")= chr [1:20] \"1\" \"2\" \"3\" \"4\" ...\n $ df            : int 32\n $ residual.scale: num 0.149\n```\n:::\n\n```{.r .cell-code}\ntd$p<-p$fit\ntd$p.se<-p$se.fit\n#t-Wert für Konfidenzintervall\nt.val<-qt(0.975, mod4$df)\nmod4$df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 32\n```\n:::\n\n```{.r .cell-code}\n#berechnet Konfidenzintervall t * SE\ntd$CI.lwr<-td$p-t.val*td$p.se\ntd$CI.upr<-td$p+t.val*td$p.se\n```\n:::\n\n\n**Das Vorhersageintervall**\n\n-   zeigt an, in welchem Bereich mit 95 %-er Wahrscheinlichkeit zukünftige Beobachtungen liegen\n-   im Allgemeinen größer (weiter) als das Konfidenzintervall\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntd$PI2=predict(mod4, td, interval=\"prediction\")\nhead(td)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      Arab Man      fit      lwr      upr        p       p.se   CI.lwr   CI.upr\n1 21.00000 con 3.411437 3.270985 3.551888 3.411437 0.06895243 3.270985 3.551888\n2 29.11111 con 3.190378 3.070923 3.309832 3.190378 0.05864438 3.070923 3.309832\n3 37.22222 con 2.969319 2.868908 3.069730 2.969319 0.04929514 2.868908 3.069730\n4 45.33333 con 2.748260 2.663611 2.832909 2.748260 0.04155695 2.663611 2.832909\n5 53.44444 con 2.527201 2.452914 2.601488 2.527201 0.03647013 2.452914 2.601488\n6 61.55556 con 2.306142 2.234435 2.377849 2.306142 0.03520344 2.234435 2.377849\n   PI2.fit  PI2.lwr  PI2.upr\n1 3.411437 3.077060 3.745813\n2 3.190378 2.864263 3.516492\n3 2.969319 2.649689 3.288949\n4 2.748260 2.433226 3.063294\n5 2.527201 2.214791 2.839611\n6 2.306142 1.994336 2.617948\n```\n:::\n:::\n\n\nund jetzt die Abbildung mit den berechneten Intervallen\n\n##### mit Konfidenzintervall\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = lwr, ymax = upr, linetype=NA), \n              alpha = 0.2, show.legend = F)+\n  geom_line(data = td, aes(x = Arab, y = fit))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-89-1.png){width=672}\n:::\n:::\n\n\n##### mit Konfidenz- und Vorhersageintervall\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(of, aes(x=Arab, y=Weeds, colour=Man)) +\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = lwr, ymax = upr, linetype=NA), \n              alpha = 0.2, show.legend = F)+\n  geom_ribbon(data = td, aes(x = Arab, y = NULL, ymin = PI2[,2], ymax = PI2[,3], linetype=NA), \n              alpha = 0.2, show.legend = F) +\n  geom_line(data = td, aes(x = Arab, y = fit)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-90-1.png){width=672}\n:::\n:::\n\n\n## Übung 6.4.\n\n-   Interpretiere das beste Modell.\n\n::: {.callout-tip collapse=\"true\"}\nBevor wir das Modell interpretieren, sollten wir die Residuen plotten und auf annähernde Normalverteilung und Varianzhomogenität prüfen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nsimulationOutput <- simulateResiduals(fittedModel = Mod4, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-91-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = dat$Temp)\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-91-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = dat$Hab)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in ensurePredictor(simulationOutput, form): DHARMa:::ensurePredictor:\ncharacter string was provided as predictor. DHARMa has converted to factor\nautomatically. To remove this warning, please convert to factor before\nattempting to plot with DHARMa.\n```\n:::\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-91-3.png){width=672}\n:::\n:::\n\n\ngut.\n\njetzt die Interpretation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nef=allEffects(get.models(dd, 1)[[1]], xlevels=100)    \nef1=as.data.frame(ef[[1]])  \nhead(ef1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Hab Temp      fit       se     lower    upper\n1 Hecke 10.0 20.42370 1.835987 16.772635 24.07476\n2 Teich 10.0 34.20223 2.522392 29.186182 39.21829\n3  Wald 10.0 12.38511 1.746992  8.911021 15.85919\n4 Hecke 10.1 20.53418 1.803662 16.947405 24.12096\n5 Teich 10.1 34.40418 2.488231 29.456055 39.35230\n6  Wald 10.1 12.44127 1.709455  9.041833 15.84071\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=dat, aes(y=Akt, x=Temp, col=Hab))+\n  geom_ribbon(data = ef1, aes(x = Temp, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Hab), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef1, aes(x = Temp, y = fit))+\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-93-1.png){width=672}\n:::\n:::\n\n\nDie Konfidenzintervalle und Regressionslinien gehen über den Wertebereich der einzelnen Habitate hinaus.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'data.table'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nDie folgenden Objekte sind maskiert von 'package:dplyr':\n\n    between, first, last\n```\n:::\n\n```{.r .cell-code}\ndat1=ef1[FALSE,] \nfor(i in unique(levels(ef1$Hab)))\n  { dat2<-ef1[(ef1$Hab==i & ef1$Temp %between% c(min(dat$Temp[dat$Hab==i]), \n                                                 max(dat$Temp[dat$Hab==i]))),] \n  dat1=rbind(dat1, dat2) } \nef11=dat1[complete.cases(dat1), ]\n```\n:::\n\n\nMit diesem Code entferne ich Werte ausserhalb des beobachteten Wertebereiches.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=dat, aes(y=Akt, x=Temp, col=Hab))+\n  geom_ribbon(data = ef11, aes(x = Temp, y = NULL, ymin = lower, ymax = upper, \n                              linetype=NA, fill=Hab), \n              alpha = 0.4, show.legend = F)+\n  geom_line(data = ef11, aes(x = Temp, y = fit))+\n  geom_point()+\n  ylab(\"Aktivität der Lurche (m/h)\") + xlab(\"Lufttemperatur (°C)\")+\n  scale_color_manual(values=c(\"lightgreen\", \"blue\", \"darkgreen\"))+ \n  scale_fill_manual(values=c(\"lightgreen\", \"blue\", \"darkgreen\"))\n```\n\n::: {.cell-output-display}\n![](06_StatMod_files/figure-html/unnamed-chunk-95-1.png){width=672}\n:::\n:::\n\n\nWir sehen, dass die Aktivität der Lurche\n\n-   am Teich höher ist als in der Hecke und im Wald (siehe Posthoc test)\n\n-   mit zunehmender Lufttemperatur steigt\n\n-   diese Zunahme am Teich stärkerer ist als in der Hecke und Wald.\n\nPosthoc-Test für Habitattyp bei 15°C Lufttemperatur\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(Mod4, ~Hab|Temp, at=list(Temp=c(15))), Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTemp = 15:\n Hab   emmean    SE df lower.CL upper.CL .group\n Wald    15.2 1.025 84     13.2     17.2  a    \n Hecke   25.9 0.848 84     24.3     27.6   b   \n Teich   44.3 1.008 84     42.3     46.3    c  \n\nConfidence level used: 0.95 \nP value adjustment: tukey method for comparing a family of 3 estimates \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n:::\n:::\n\n\nWie stark nimmt die Aktivität mit zunehmender Temperatur zu?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemmeans(Mod4, ~Temp|Hab, at=list(Temp=c(15,16)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHab = Hecke:\n Temp emmean    SE df lower.CL upper.CL\n   15   25.9 0.848 84     24.3     27.6\n   16   27.1 0.990 84     25.1     29.0\n\nHab = Teich:\n Temp emmean    SE df lower.CL upper.CL\n   15   44.3 1.008 84     42.3     46.3\n   16   46.3 0.856 84     44.6     48.0\n\nHab = Wald:\n Temp emmean    SE df lower.CL upper.CL\n   15   15.2 1.025 84     13.2     17.2\n   16   15.8 1.322 84     13.1     18.4\n\nConfidence level used: 0.95 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npairs(emmeans(Mod4, ~Temp|Hab, at=list(Temp=c(16,15))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHab = Hecke:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    1.105 0.363 84   3.042  0.0031\n\nHab = Teich:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    2.019 0.362 84   5.578  <.0001\n\nHab = Wald:\n contrast        estimate    SE df t.ratio p.value\n Temp16 - Temp15    0.562 0.428 84   1.313  0.1929\n```\n:::\n:::\n\n\nMit zunehmender Temperatur (je °C) steigt die Aktivität am Teich um 2,02 Einheiten, in der Hecke um 1,11 Einheiten und im Wald um 0,56 Einheiten.\n:::\n",
    "supporting": [
      "06_StatMod_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}