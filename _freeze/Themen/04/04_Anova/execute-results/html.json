{
  "hash": "10086239fdd148006a855f7813abc711",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"ANOVA\"\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(ggpubr)\nlibrary(ggfortify)\nlibrary(stringr)\n```\n:::\n\n\n\n\n### Unterscheiden sich die Gruppen?\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-3-1.png){width=624}\n:::\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-3-2.png){width=624}\n:::\n:::\n\n\n|Experiment |Behandlung | MW|  SD|    N|\n|:----------|:----------|--:|---:|----:|\n|Exp 1      |A          | 10| 2.0| 1000|\n|Exp 1      |B          | 20| 2.0| 1000|\n|Exp 2      |A          | 10| 4.8| 1000|\n|Exp 2      |B          | 20| 4.8| 1000|\n|Exp 3      |A          | 10| 5.1| 1000|\n|Exp 3      |B          | 30| 5.0| 1000|\n\n\n\n\n### Beispieldaten ANOVA in Anlehnung an Carsten Dormann \"Parametrische Statistik\" S. 191ff\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-5-1.png){width=624}\n:::\n:::\n\n\n\n\nA)  Gesamtvarianz der Daten = Abweichungsquadrate zum Gesamtmittelwert = SS Total\nB)  Abweichungsquadrate der Gruppen zum Gesamtmittelwert = SS Effekt\nC)  Abweichungsquadrate zum Mittelwert der beiden Gruppen = SS Residuen\n\nSS~Total~ = SS~Effekt~ + SS~Residuen~\\\nF-Wert = (SS~Effekt~/df~Effekt~)/(SS~Residuen~/df~Residuen~)\n\ndf~Effekt~ = k-1, wobei k die Anzahl der Gruppen (Faktorlevels) ist\\\ndf~Residuen~ = n-k, wobei n der Stichprobenumfang ist\n\nF-Wert = MS~Effekt~/MS~Residuen~\n\naus dem F-Wert und den `degrees of freedom` resultiert dann der p-Wert\n\nR² = SS~Effekt~/SS~Total~ \\* 100\n\nentsprechend können *signifikante Unterschiede* verschiedene Ursachen haben:\n\n-   große Mittelwertsdifferenzen zwischen den Gruppen (hohe SS~Effekt~)\n-   geringe Variabilität innerhalb der Gruppen (niedrige SS~Residuen~)\n-   hoher Stichprobenumfang bzw. Anzahl Wiederholungen je Gruppe (erhöht df~Residuen~ und senkt damit MS~Residuen~)\n\nVarianzanalyse (*Analysis of Variance*)\n\n-   `mod<-aov(Abhängige ~ Erklärungsvariable, data=md)`\n-   Abhängige ist kontinuierlich\n-   Erklärungsvariable ist ein Faktor\n\nVoraussetzungen:\n\n-   zufällige Stichprobennahme (unabhängige Fehler)\n-   Varianzhomogenität/Homoskedastizität\n-   annähernde Normalverteilung der Fehler (Residuen), und **nicht** der Abhängigen!\n\n## Beispiel ANOVA Proteingehalt\n\nDie Proteingehalte von jeweils 8 zufällig ausgewählten Weizenproben der 4 Qualitätsklassen E, A, B und C wurden ermittelt. Unterscheiden sich die Qualitätsklassen im Proteingehalt?\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Daten einlesen, kennenlernen und plotten\n\n[Protein.xlsx](https://github.com/DoreenGabriel/Kurs/blob/main/Themen/04/Protein.xlsx){target=\"_blank\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openxlsx)\nmd<-read.xlsx(\"Protein.xlsx\")\n```\n:::\n\n\n\n\n### Struktur der eingelesenen Daten überprüfen\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(md)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t32 obs. of  3 variables:\n $ ID   : num  1 2 3 4 5 6 7 8 9 10 ...\n $ Quali: chr  \"E\" \"E\" \"E\" \"E\" ...\n $ Prot : num  15.4 15.6 14.3 13.8 15.4 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nunique(md$Quali)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"E\" \"A\" \"B\" \"C\"\n```\n\n\n:::\n\n```{.r .cell-code}\nmd$Quali=as.factor(md$Quali)# Erklärungsvariable muss als Faktor deklariert sein\nlevels(md$Quali)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"A\" \"B\" \"C\" \"E\"\n```\n\n\n:::\n:::\n\n\n\n\n### Daten plotten (Ausreißer, Eingabefehler, Varianzhomogenität visuell überprüfen)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(md, aes(x=Quali, y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n## Modell formulieren\n\nWichtig ist, dass die Abhängige kontinuierlich und die Erklärungsvariable ein Faktor ist.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod<-lm(Prot ~ Quali, data=md) # Prot ist die Abhängige, Quali die Erklärungsvariable\nanova(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: Prot\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nQuali      3 35.666 11.8888  5.0814 0.006198 **\nResiduals 28 65.511  2.3397                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n`Quali` hat einen signifikanten Effekt auf den Proteingehalt.\n\nMit der Funktion `summary()`können wir die geschätzten Effekte sehen.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  13.2728     0.5408  24.543   <2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,\tAdjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198\n```\n\n\n:::\n:::\n\n\n\n\nBevor wir hier aber ins Detail gehen, müssen wir zunächst eine Modelldiagnostik durchführen. \n\n::: {.callout-tip collapse=\"true\"}\n### alternative Funktion aov\n\n... gelangt zu den gleichen Ergebnissen und wird hier lediglich der Vollständigkeit halber erwähnt.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod.a<-aov(Prot ~ Quali, data=md) # \nsummary(mod.a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value Pr(>F)   \nQuali        3  35.67   11.89   5.081 0.0062 **\nResiduals   28  65.51    2.34                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary.lm(mod.a)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\naov(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  13.2728     0.5408  24.543   <2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,\tAdjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198\n```\n\n\n:::\n:::\n\n\n\n::: \n\n\n## Modelldiagnostik\n\nWir überprüfen die Annahmen der ANOVA visuell auf:\n\n-   annähernde Normalverteilung der Fehler (i.e. Residuen)\n-   Varianzhomogenität\n\nIch nutze hierfür die `library(DHARMa)`.\n\n[https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html](https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html){target=\"_blank\"}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nsimulationOutput <- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n-   Die erste Grafik zeigt einen QQ-Plot der standardisierten `Residuen`, der uns Informationen über die Normalverteilung der Residuen liefert. Wenn die Punkte ungefähr entlang der Winkelhalbierenden (rote Linie) liegen, deutet dies darauf hin, dass die Residuen approximativ normalverteilt sind. Außerdem werden uns p-Werte für den KS-Test (Kolmogorov-Smirnov-Test auf Normalverteilung), ein Dispersion- und Ausreißertest angezeigt.\n\n-   Die zweite Grafik plottet die `Residuen` gegen die `Fitted Values`. Wir wollen hier sehen, dass die Streuung um die 0.5 sowohl bei hohen als auch bei niedrigen Werten in etwa gleich ist (**Varianzhomogenität**). Hier scheint ein leichter Trend vorzuliegen (ist aber m.E. noch ok). Der Plot ist auch hilfreich zum Identifizieren von auffälligen Stichproben. Diese werden als rote Sternchen abgebildet (müssen aber noch nicht zwingend als Ausreißer bezeichnet werden).\n\n-   Um die Varianzhomogenität zwischen den Gruppen zu prüfen, sollten wir die Residuen gegen die Erklärungsvariablen plotten.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = md$Quali)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n\n\nSolange alle Tests nicht signifikant sind (und keine roten Linien oder Boxen angezeigt werden), ist alles (mehr oder weniger) gut. ABER es sei angemerkt, dass die Teststärke (Power) der Tests von der Anzahl der Beobachtungen abhängt. Je mehr Beobachtungen wir haben, umso höher ist die Power des Tests. Damit werden häufig signifikante Unterschiede z.B. der Varianzen bei großem Stichprobenumfang beobachtet, obwohl diese praktisch nicht relevant sind. Außerdem werden häufig keine signifikanten Unterschiede bei kleinem Stichprobenumfang beobachtet, obwohl gravierende Unterschiede vorhanden sind.\n\nDie *visuelle* Modelldiagnostik wird daher häufig als wichtiger angesehen als die p-Wert-basierten Tests auf Normalverteilung und Varianzhomogenität (Cochran, Bartlett und Levenes Test).\n\n::: {.callout-tip collapse=\"true\"}\n### Tests auf Varianzhomogenität\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvar.test(md$Prot[md$Quali==\"E\"], md$Prot[md$Quali==\"B\"] )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tF test to compare two variances\n\ndata:  md$Prot[md$Quali == \"E\"] and md$Prot[md$Quali == \"B\"]\nF = 0.6686, num df = 7, denom df = 7, p-value = 0.6085\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.1338567 3.3396057\nsample estimates:\nratio of variances \n         0.6686019 \n```\n\n\n:::\n\n```{.r .cell-code}\nbartlett.test(Prot ~ Quali, data=md)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tBartlett test of homogeneity of variances\n\ndata:  Prot by Quali\nBartlett's K-squared = 1.0564, df = 3, p-value = 0.7876\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(car)\nleveneTest(Prot ~ Quali, data=md) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  3  0.3349 0.8002\n      28               \n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(outliers)\ncochran.test(Prot ~ Quali, data=md)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tCochran test for outlying variance\n\ndata:  Prot ~ Quali\nC = 0.36079, df = 8, k = 4, p-value = 0.6601\nalternative hypothesis: Group C has outlying variance\nsample estimates:\n       A        B        C        E \n1.805174 2.503336 3.376528 1.673735 \n```\n\n\n:::\n:::\n\n\n\n:::\n\nIn unserem Beispiel ist alles ok. Sowohl visuell als auch nach Aussage der Tests.\n\n#### Hier ein Beispiel für Varianzheterogenität mit veränderten Daten.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmd$Prot2= md$Prot\nset.seed(1309)\nmd$Prot2[md$Quali==\"E\"] =rnorm(8, 14.5, 13)\nggplot(md, aes(x=Quali, y=Prot2)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod2<-lm(Prot2 ~ Quali, data=md)\nsimulationOutput <- simulateResiduals(fittedModel = mod2, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = md$Quali)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n:::\n\n\n\n\nDie Residuen weisen eine größere Streuung mit größer werdenden `fitted values` auf bzw. unterscheiden sich die Varianzen der Gruppen. Um dem entgegenzuwirken, könnten wir 1.) entweder die Analyse mit transformierten Daten vornehmen oder 2.) *besser* einen Funktion anwenden, die die unterschiedliche Varianz in den Gruppen berücksichtigt oder 3.) ein Generalisertes Lineares Modell anwenden, welches die Verteilungsannahme der abhängigen Variable berücksichtigt - denn häufig weisen bspw. Zähldaten eine größere Streuung mit größer werdenden `fitted values` auf. Siehe dazu [Analysis of two-factorial experiments with generalised linear (mixed effect) models](https://doreengabriel.github.io/Kurs/Themen/09/09_2f_GLM.html){target=\"_blank\"} \n\n## Modellinterpretation\n\nZurück zu unserem Modell, bei dem die Modelldiagnostik keine Auffälligkeiten zeigte. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Prot ~ Quali, data = md)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1099 -0.9705  0.2110  0.9566  2.5819 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  13.2728     0.5408  24.543   <2e-16 ***\nQualiB       -1.0279     0.7648  -1.344    0.190    \nQualiC       -1.5594     0.7648  -2.039    0.051 .  \nQualiE        1.2036     0.7648   1.574    0.127    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.53 on 28 degrees of freedom\nMultiple R-squared:  0.3525,\tAdjusted R-squared:  0.2831 \nF-statistic: 5.081 on 3 and 28 DF,  p-value: 0.006198\n```\n\n\n:::\n:::\n\n\n\n\n-   R² ist 35.3 %. Adjusted R² ist 28.3 %.\n-   Hinter dem Intercept verbirgt sich das erste Level von `Quali`, i.e. `A`. `A` hat demnach einen geschätzten mittleren Proteingehalt von 13.3.\n-   Um den geschätzten mittleren Proteingehalt für `B` zu ermitteln, müssen wir Intercept + Estimate `QualiB` rechnen, d.h. 13.3 -1 = 12.2\n-   Um den geschätzten mittleren Proteingehalt für `C` zu ermitteln, müssen wir Intercept + Estimate `QualiC` rechnen, d.h. 13.3 -1.6 = 11.7\n-   und für `E` Intercept + Estimate `QualiE`: 13.3 + 1.2 = 14.5\n\n### Post-hoc Test\n\nDie ANOVA hat einen signifikanten Effekt von `Quali` auf `Prot` gezeigt. Allerdings wissen wir nicht, welche Weizenqualitätsklassen sich voneinander unterscheiden. Bei Faktoren mit mehr als zwei Ausprägungen wird daher ein Post-hoc Test durchgeführt. Dieser korrigiert die Irrtumswahrscheinlichkeit um die Anzahl der Vergleiche, da bei beispielsweise 100 Ausprägungen schon rein zufällig fünf signifikante Unterschiede auftreten können.\n\n### Bespiel für multiples Testen ohne und mit Adjustierung des p-Wertes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npairwise.t.test(md$Prot, md$Quali, p.adj = \"none\") # p-Werte werden nicht korrigiert, nicht gut! \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  md$Prot and md$Quali \n\n  A      B      C     \nB 0.1897 -      -     \nC 0.0510 0.4928 -     \nE 0.1268 0.0069 0.0012\n\nP value adjustment method: none \n```\n\n\n:::\n\n```{.r .cell-code}\n# Bonferroni-Korrektur (Bonferroni multipliziert p mit der Anzahl Tests, sehr konservativ)\npairwise.t.test(md$Prot, md$Quali, p.adj = \"bonferroni\") # besser\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPairwise comparisons using t tests with pooled SD \n\ndata:  md$Prot and md$Quali \n\n  A     B     C    \nB 1.000 -     -    \nC 0.306 1.000 -    \nE 0.761 0.041 0.007\n\nP value adjustment method: bonferroni \n```\n\n\n:::\n:::\n\n\n\n\n### Post-hoc Test: package `emmeans`\n\nDie `library(emmeans)` mit der Funktion `emmeans()` bietet eine Vielzahl an Möglichkeiten um einen Post-hoc Test am gefitteten Modell (hier die ANOVA) durchzuführen. Mit dem Argument `method=\"pairwise\"` kann man alle Behandlungen miteinander per Tukey-Test vergleichen, i.e. paarweise.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\ncontrast(emmeans(mod, ~Quali), method=\"pairwise\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate    SE df t.ratio p.value\n A - B       1.028 0.765 28   1.344  0.5437\n A - C       1.559 0.765 28   2.039  0.1982\n A - E      -1.204 0.765 28  -1.574  0.4093\n B - C       0.532 0.765 28   0.695  0.8981\n B - E      -2.231 0.765 28  -2.918  0.0328\n C - E      -2.763 0.765 28  -3.613  0.0061\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n```\n\n\n:::\n:::\n\n\n\n\nMit `method=\"trt.vs.ctrl\"` wird ein Dunnett-Test durchgeführt, der alle Behandlungen gegen **eine** Kontrolle testet. Die p-Werte werden automatisch um die Anzahl der Tests korrigiert.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate    SE df t.ratio p.value\n B - A       -1.03 0.765 28  -1.344  0.4116\n C - A       -1.56 0.765 28  -2.039  0.1295\n E - A        1.20 0.765 28   1.574  0.2937\n\nP value adjustment: dunnettx method for 3 tests \n```\n\n\n:::\n:::\n\n\n\n\nHier wird immer gegen die Qualität A geprüft, weil diese das erste Level der Variable `Quali` ist.\n\nMit dem Argument `ref` kann ich ein anderes Level wählen. Hier die E-Qualität.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\", ref=4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate    SE df t.ratio p.value\n A - E       -1.20 0.765 28  -1.574  0.2937\n B - E       -2.23 0.765 28  -2.918  0.0190\n C - E       -2.76 0.765 28  -3.613  0.0033\n\nP value adjustment: dunnettx method for 3 tests \n```\n\n\n:::\n:::\n\n\n\n\nAlternativ kann ich bereits im `data.frame` die Faktorenlevels entsprechend meiner Interpretation ändern und damit das Modell anpassen. (siehe dazu Reihenfolge ändern in Kap. Grafik)\n\nInteressant sind auch die Konfidenzintervalle. Wenn Konfidenzintervalle sich nicht überlappen, geht man in der Regel von signifikanten Unterschieden aus. Es kann auch sein, dass Konfidenzintervalle leicht überlappen, und trotzdem signifikante Unterschiede vorliegen. [https://core.ac.uk/download/pdf/82702323.pdf](https://core.ac.uk/download/pdf/82702323.pdf){target=\"_blank\"} Hier sollte man immer auf die p-Werte des Tests schauen.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(emmeans(mod, ~Quali)) #Konfidenzintervalle\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Quali emmean    SE df lower.CL upper.CL\n A       13.3 0.541 28     12.2     14.4\n B       12.2 0.541 28     11.1     13.4\n C       11.7 0.541 28     10.6     12.8\n E       14.5 0.541 28     13.4     15.6\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\nplot(emmeans(mod, ~Quali))\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-23-1.png){width=384}\n:::\n:::\n\n\n\n\nUm Gruppenunterschiede leicht verständlich anzugeben bzw. zu visualisieren, kann das *compact letter display* genutzt werden. Hierfür benötigen wir die `library(multcompView)` und `library(multcomp)`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(multcompView)\nlibrary(multcomp)\ncld(emmeans(mod, ~Quali), adjust=\"sidak\", Letters=letters) # Compact letter display für Gruppenunterschiede \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Quali emmean    SE df lower.CL upper.CL .group\n C       11.7 0.541 28     10.3     13.2  a    \n B       12.2 0.541 28     10.8     13.7  a    \n A       13.3 0.541 28     11.8     14.7  ab   \n E       14.5 0.541 28     13.0     15.9   b   \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\nGruppen, die keinen Buchstaben gemeinsam haben, sind im Mittelwert signifikant unterschiedlich. Qualitätsklasse `E` hat einen signifikant höheren Proteingehalt im Vergleich zu `B` und `C`, während `E` und `A` sich nicht signifikant unterscheiden.\n\n## Präsentation der Ergebnisse\n\nSo könnte man die Daten und die Ergebnisse des Modells präsentieren. Ich speichere die geschätzten Mittelwerte und das Konfidenzintervall als Objekt `CIs` und plotte diese neben die jittered Boxplots der Gruppen. Das Einzeichnen der Buchstaben muss nicht sein. Der Vollständigkeit halber soll es hier aber gezeigt werden.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCIs=cld(emmeans(mod, ~Quali), adjust=\"sidak\", sort = FALSE, Letters=letters)\nCIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \" ab\" \" a \" \" a \" \"  b\"\n```\n\n\n:::\n\n```{.r .cell-code}\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen\nCIs$.group # besser\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"ab\" \"a\"  \"a\"  \"b\" \n```\n\n\n:::\n\n```{.r .cell-code}\nstr(CIs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'summary_emm' and 'data.frame':\t4 obs. of  7 variables:\n $ Quali   : Factor w/ 4 levels \"A\",\"B\",\"C\",\"E\": 1 2 3 4\n $ emmean  : num  13.3 12.2 11.7 14.5\n $ SE      : num  0.541 0.541 0.541 0.541\n $ df      : num  28 28 28 28\n $ lower.CL: num  11.8 10.8 10.3 13\n $ upper.CL: num  14.7 13.7 13.2 15.9\n $ .group  : chr  \"ab\" \"a\" \"a\" \"b\"\n - attr(*, \"estName\")= chr \"emmean\"\n - attr(*, \"clNames\")= chr [1:2] \"lower.CL\" \"upper.CL\"\n - attr(*, \"pri.vars\")= chr \"Quali\"\n - attr(*, \"adjust\")= chr \"sidak\"\n - attr(*, \"side\")= num 0\n - attr(*, \"delta\")= num 0\n - attr(*, \"type\")= chr \"link\"\n - attr(*, \"mesg\")= chr [1:5] \"Confidence level used: 0.95\" \"Conf-level adjustment: sidak method for 4 estimates\" \"P value adjustment: sidak method for 6 tests\" \"significance level used: alpha = 0.05\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(md, aes(x=Quali, y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n             shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 17, label =.group))+\n  scale_y_continuous(labels=scales::number_format(accuracy = 0.01, \n                                                  decimal.mark =\",\"))+\n  theme_bw() +\n  ylab(\"Proteingehalt %\")+\n  xlab(\"Qualitätsklasse\")\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\n\n\nIm Text sollte man erwähnen, dass\n\n-   `Quali` einen signifikanten Einfluss auf `Prot` hat. Nutze die Funktion `anova(mod)` und gibt den p-Wert zusammen mit den `degrees of freedom` und `F-Wert` an.\n-   der Post-hoc Test gezeigt hat, dass `E` mit im Mittel 14.5 % einen signifikant höheren Proteingehalt hatte als `B` und `C` mit 12.2 % und 11.7 % , während `E` und `A` sich nicht unterscheiden. Die Proteingehalte von `A`, `B` und `C` unterscheiden sich nicht signifikant (p\\>0.05). Hierzu nutzt du die Funktion `contrast(emmeans(mod, c(\"Quali\")), method=\"pairwise\")`.\n-   das R² des Modells 35.3 beträgt. `summary(mod)$r.sq`\n-   die Modellannahmen für die ANOVA (Varianzhomogenität und annähernde Normalverteilung der Residuen) visuell mit dem Paket `DHARMa` überprüft wurden.\n\n\n\n### add on: Unterschiede zu einer Kontrolle darstellen (absolut)\n\nWie bereits erwähnt, können wir durch geeignete Modellinterpretation alle Behandlungen gegen eine bestimmte Kontrollgruppe testen. Nehmen wir an, die Qualität C sei unsere Standardqualität und wir möchten die Unterschiede der übrigen Qualitäten im Vergleich zu C quantifizieren. \nDies lässt sich mit `method=\"trt.vs.ctrl\"` umsetzen, wobei wir über das Argument `ref` die gewünschte Kontrollgruppe – in diesem Fall die C-Qualität – festlegen. Mit dem Argument `infer=c(T,T)` wird das 95%-Konfidenzintervall für die Unterschiede zwischen den Gruppen berechnet.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(emmeans(mod, ~Quali),  method=\"trt.vs.ctrl\", ref=\"C\", infer=c(T,T))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate    SE df lower.CL upper.CL t.ratio p.value\n A - C       1.559 0.765 28   -0.351     3.47   2.039  0.1295\n B - C       0.532 0.765 28   -1.379     2.44   0.695  0.8021\n E - C       2.763 0.765 28    0.853     4.67   3.613  0.0033\n\nConfidence level used: 0.95 \nConf-level adjustment: dunnettx method for 3 estimates \nP value adjustment: dunnettx method for 3 tests \n```\n\n\n:::\n:::\n\n\n\n\nDas Ergebnis wird als `data.frame` `CI.con` gespeichert.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCI.con=data.frame(contrast(emmeans(mod, ~Quali), method=\"trt.vs.ctrl\", ref=\"C\", infer=c(T,T)))\nCI.con\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n```\n\n\n:::\n:::\n\n\n\n\nIm nächsten Schritt wird zur besseren Visualisierung die Information aus die Spalte `contrast` aufbereitet und in eine neue Spalte `contrast2` geschrieben: Aus den Namen wie `E - C` oder `A - C` wird das ` - C` entfernt. Gleichzeitig wird mit `levels=c(\"E\",\"A\",\"B\")` eine gewünschte Reihenfolge der Gruppen festgelegt. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCI.con$contrast2=factor(str_replace_all(CI.con$contrast, \" - C\", \"\"), levels=c(\"E\", \"A\", \"B\"))\nCI.con\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2\n1         A\n2         B\n3         E\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=CI.con, aes(y=estimate, x=contrast2))+\n  geom_hline(yintercept=0, linetype=\"dashed\")+\n  geom_errorbar(aes(ymin=lower.CL, ymax=upper.CL), width=0.1)+\n  geom_point(size=3)+\n  coord_flip()+\n  theme_bw() +\n  ylab(\"Differenz im mittleren Proteingehalt und 95%-Konfidenzintervall \\n im Vergleich zur C-Qualität\")+\n  scale_x_discrete(limits=rev, name=\"Qualitätsklasse\")\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n\n\nDie Grafik zeigt die geschätzten Differenzen im mittleren Proteingehalt der Qualitätsklassen `E`, `A` und `B` im Vergleich zur Referenz `C`, jeweils mit 95%-Konfidenzintervallen. Die gestrichelte Linie markiert den Referenzwert (kein Unterschied zu `C`).\n\n\n### add on: Unterschiede zu einer Kontrolle darstellen (Cohen’s d)\n\nUm die Größenordnung der Unterschiede zur C-Qualität unabhängig von der absoluten Skala der Messwerte zu veranschaulichen, können wir Cohen’s d-ähnliche Effektstärken berechnen.\n**Cohen’s d** ist eine **standardisierte Effektgröße**, die den Unterschied zweier Mittelwerte ins Verhältnis zur Streuung setzt. Mit der Funktion `eff_size` kann Cohen’s d aus dem Modell berechnet werden, d.h. aus den geschätzten Mittelwerten und der geschätzten Residual-Standardabweichung. \n\nMit `sigma = sigma(mod)` und `edf = df.residual(mod)` werden die Residual-Standardabweichung und die geschätzten Freiheitsgrade aus dem Modell übergeben. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\neff_size(emmeans(mod, ~Quali), sigma = sigma(mod), edf = df.residual(mod), \n                        method = \"trt.vs.ctrl\", ref = \"C\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast effect.size    SE df lower.CL upper.CL\n A - C          1.019 0.518 28  -0.0421     2.08\n B - C          0.347 0.502 28  -0.6811     1.38\n E - C          1.806 0.555 28   0.6690     2.94\n\nsigma used for effect sizes: 1.53 \nConfidence level used: 0.95 \n```\n\n\n:::\n:::\n\n\n\nPrinzipiell gilt für Cohen`s d: \n\n+ kleiner Effekt: d ≈ 0.2\n+ mittlerer Effekt: d ≈ 0.5\n+ großer Effekt: d ≈ 0.8\n\nFür obiges Beispiel bedeutet das: \n\n+ `A` zeigt einen großen, aber statistisch unsicheren Effekt (das Konfidenzintervall schließt die 0 mit ein).\n+ `B` zeigt nur einen kleinen, statistisch unsicheren Effekt.\n+ `E` unterscheidet sich klar und deutlich von `C` (großer, signifikanter Effekt, das Konfidenzintervall liegt vollständig über 0).\n\n\n### add on: Unterschiede zu einer Kontrolle darstellen (prozentual)\n\nUm die Unterschiede zu einer Referenzgruppe anschaulicher darzustellen, können die Mittelwertsdifferenzen **prozentual** zur C-Qualität angegeben werden. So wird sichtbar, um wie viel Prozent die anderen Qualitätsklassen vom Standard abweichen.\n\nProzentuale Unterschiede sind oft intuitiver verständlich als Rohwerte oder standardisierte Effektgrößen. Sie sind insbesondere für Präsentationen oder für praxisorientierte Zielgruppen (z. B. Landwirte, Praktiker) besser geeignet. Auch beim Vergleich unterschiedlicher Messgrößen (z. B. Proteingehalt, Gewicht, usw) in Relation zur Behandlung kann die Berechnung der prozentualen Unterschiede eine gute Grundlage für die Interpretation liefern. \n\nZu beachten ist jedoch, dass prozentuale Änderungen immer relativ zur Referenz zu interpretieren sind. Sind diese sehr klein, können die Prozentwerte stark verzerrt werden. Daher empfiehlt es sich, immer auch die geschätzten Werte (`emmeans`) oder Rohdifferenzen (wie oben) anzugeben.  \n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemm1=data.frame(emmeans(mod, ~Quali))\nemm1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Quali   emmean        SE df lower.CL upper.CL\n1     A 13.27277 0.5407972 28 12.16500 14.38055\n2     B 12.24490 0.5407972 28 11.13712 13.35267\n3     C 11.71337 0.5407972 28 10.60560 12.82114\n4     E 14.47638 0.5407972 28 13.36861 15.58416\n```\n\n\n:::\n\n```{.r .cell-code}\nC.p=emm1$emmean[emm1$Quali==\"C\"]\nC.p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11.71337\n```\n\n\n:::\n:::\n\n\n\n\nHier werden die geschätzten Mittelwerte der Qualitätsklassen berechnet und der Mittelwert der C-Qualität (`C.p`) als Referenz gespeichert.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCI.con\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2\n1         A\n2         B\n3         E\n```\n\n\n:::\n\n```{.r .cell-code}\nCI.con$p.change=CI.con$estimate/C.p*100\nCI.con$p.change.low=CI.con$lower.CL/C.p*100\nCI.con$p.change.up=CI.con$upper.CL/C.p*100\nCI.con\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  contrast  estimate        SE df   lower.CL upper.CL   t.ratio     p.value\n1    A - C 1.5594041 0.7648028 28 -0.3507964 3.469605 2.0389624 0.129460665\n2    B - C 0.5315255 0.7648028 28 -1.3786750 2.441726 0.6949838 0.802070212\n3    E - C 2.7630126 0.7648028 28  0.8528121 4.673213 3.6127127 0.003349563\n  contrast2  p.change p.change.low p.change.up\n1         A 13.313027    -2.994838    29.62089\n2         B  4.537768   -11.770097    20.84563\n3         E 23.588537     7.280673    39.89640\n```\n\n\n:::\n:::\n\n\n\n\nDie absoluten Differenzen zu C werden in prozentuale Abweichungen umgerechnet. Neben dem Schätzwert (`p.change`) werden auch die unteren (`p.change.low`) und oberen (`p.change.up`) Konfidenzgrenzen in Prozent berechnet.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data=CI.con, aes(y=p.change, x=contrast2))+\n  geom_hline(yintercept=0, linetype=\"dashed\")+\n  geom_errorbar(aes(ymin=p.change.low, ymax=p.change.up), width=0.1)+\n  geom_point(size=3)+\n  coord_flip()+\n  theme_bw() +\n  ylab(\"prozentualer Unterschied im mittleren Proteingehalt und 95%-Konfidenzintervall \\n im Vergleich zur C-Qualität\")+\n  scale_x_discrete(limits=rev, name=\"Qualitätsklasse\")#+  xlab()\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n\n### add on: Faktorlevels in Grafik umsortieren\n\nZurück zu unseren emmeans und Originaldaten: Schön wäre es, die Qualitäten in absteigender Reihenfolge darzustellen. E steht für Elite und ist die beste Qualität.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(forcats)\nmd %>% \nggplot(aes(x=fct_relevel(Quali, \"E\"), y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n           shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 20, label =.group))+\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\n\n\noder in aufsteigender Reihenfolge, basierend auf den Messwerten.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCIs$Prot=CIs$emmean\nmd %>% \nggplot(aes(x=fct_reorder(Quali, Prot), y=Prot)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=emmean), \n           shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=emmean, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 20, label =.group))+\n  theme_bw() \n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n:::\n\n\n\n\n## Übung 4\n\nIn einem Gefäßversuch wurde die pflanzenliche Biomasse (`BM`) in den 4 Düngemittelvarianten (`DM`: Kontrolle, Düngemittel A, B und C) an jeweils 10 Proben gemessen.\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n-   Importiere bitte die Daten [Gefaessversuch.xlsx](https://github.com/DoreenGabriel/Kurs/blob/main/Themen/04/Gefaessversuch.xlsx){target=\"_blank\"} in R und mach Dich mit dem Datensatz vertraut.\n\n::: {.callout-tip collapse=\"true\"}\n### Daten einlesen und prüfen\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(openxlsx)\ng<-read.xlsx(\"Gefaessversuch.xlsx\")\nstr(g)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t40 obs. of  3 variables:\n $ ID: num  1 2 3 4 5 6 7 8 9 10 ...\n $ DM: chr  \"K\" \"K\" \"K\" \"K\" ...\n $ BM: num  118.3 122.4 96.7 86.9 119 ...\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\n\n\nwir können die Kontrolle als erstes Level definieren.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng$DM=fct_relevel(g$DM, \"K\")\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") \n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\n-   Unterscheidet sich die Biomasse zwischen den Varianten?\n\n::: {.callout-tip collapse=\"true\"}\n### Modell formulieren\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod<-lm(BM ~ DM, data=g)\nanova(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: BM\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nDM         3 431421  143807  67.744 7.084e-15 ***\nResiduals 36  76421    2123                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\nJa, aber bevor wir das Modell interpretieren, müssen wir uns unbedingt die Residuen anschauen.\n:::\n\n-   Sind die Voraussetzung für eine ANOVA gegeben? Prüfe die Residuen.\n\n::: {.callout-tip collapse=\"true\"}\n### Modelldiagnostik\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DHARMa)\nsimulationOutput <- simulateResiduals(fittedModel = mod, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = g$DM)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\n\n\nNein, das sieht nicht gut aus. Die Varianz wird mit jedem Level etwas größer. Hier könnte man nun die Abhängige Variable transformieren, um die Varianz zu stabilisieren.\n\nPlotten wir die Daten mit einer Wurzel-transformierten Y-Achse:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  stat_summary(fun = \"mean\", colour = \"red\", size = 2, geom = \"point\") +\n  scale_y_sqrt()\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-43-1.png){width=672}\n:::\n:::\n\n\n\n\nDas sieht besser aus. Die Boxen der Boxplots weisen eine ähnliche Höhe auf.\n\nNun können wir entweder\n\n-   eine neue Variable in unseren `data.frame` definieren, die die wurzel-transformierten Werte enthält, z.B. `g$BM.sq=sqrt(g$BM)`\n-   und mit dieser Variable das Modell fitten `mod<-lm(BM.sq ~ DM, data=g)`\n-   und später die emmeans und CIs zurücktransformieren `CIs$emmean.2=CIs$emmean^2` (gleiches für die Konfidenzintervalle)\n\noder\n\n-   die Transformation im Modell definieren. Das hat bei der späteren Nutzung von `emmeans()` den Vorteil, dass die Werte auf die *Response Skala* automatisch tranformiert werden können.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod1<-lm(sqrt(BM) ~ DM, data=g)\nanova(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Variance Table\n\nResponse: sqrt(BM)\n          Df Sum Sq Mean Sq F value    Pr(>F)    \nDM         3 495.26 165.086  69.415 4.885e-15 ***\nResiduals 36  85.62   2.378                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsimulationOutput <- simulateResiduals(fittedModel = mod1, plot = F)\nplot(simulationOutput)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\nWarning in newton(lsp = lsp, X = G$X, y = G$y, Eb = G$Eb, UrS = G$UrS, L = G$L,\n: Anpassung beendet mit Schrittweitenfehler - Ergebnisse sorgfältig prüfen\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-45-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplotResiduals(simulationOutput, form = g$DM)\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-45-2.png){width=672}\n:::\n:::\n\n\n\n\nAuch wenn wir Warnmeldungen für die obigen Plots erhalten, so ist doch die Annahme der Varianzhomogenität und annähernede Normalverteilung der Residuen erfüllt. Wir können das Modell nun interpretieren.\n\n### Modellinterpretation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(emmeans)\nlibrary(multcomp)\nlibrary(multcompView)\ncld(emmeans(mod1, ~DM), adjust = \"sidak\", Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n DM emmean    SE df lower.CL upper.CL .group\n K     9.8 0.488 36     8.52     11.1  a    \n A    11.4 0.488 36    10.15     12.7  a    \n B    14.1 0.488 36    12.85     15.4   b   \n C    19.1 0.488 36    17.81     20.4    c  \n\nResults are given on the sqrt (not the response) scale. \nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\nDie emmeans sind recht niedrig, was an der Wurzeltransformation liegt.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncld(emmeans(mod1, ~DM, type=\"response\"), adjust = \"sidak\", Letters=letters)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n DM response    SE df lower.CL upper.CL .group\n K      96.1  9.56 36     72.6      123  a    \n A     130.6 11.10 36    103.0      161  a    \n B     199.5 13.80 36    165.0      237   b   \n C     364.3 18.60 36    317.1      415    c  \n\nConfidence level used: 0.95 \nConf-level adjustment: sidak method for 4 estimates \nIntervals are back-transformed from the sqrt scale \nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n```\n\n\n:::\n:::\n\n\n\n\nMit dem Argument `type=\"response\"` werden die emmeans auf die Originalskala zurücktransformiert. Beachte, dass jetzt die Variable `reponse` heißt und der Code für die Grafik angepasst werden muss. Die p-Werte der paarweisen Vergleiche können wir über die `contrast()`-Funktion erhalten. Alternativ kann mit dem Argument `method=\"trt.vs.ctrl\"` ein Dunnett-Test durchgeführt werden, der die Düngemittel A, B und C gegen die **Kontrolle** testet.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(emmeans(mod1, ~DM), method=\"pairwise\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE df t.ratio p.value\n K - A       -1.63 0.69 36  -2.361  0.1032\n K - B       -4.32 0.69 36  -6.270  <.0001\n K - C       -9.29 0.69 36 -13.464  <.0001\n A - B       -2.70 0.69 36  -3.909  0.0021\n A - C       -7.66 0.69 36 -11.103  <.0001\n B - C       -4.96 0.69 36  -7.194  <.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: tukey method for comparing a family of 4 estimates \n```\n\n\n:::\n\n```{.r .cell-code}\ncontrast(emmeans(mod1, ~DM), method=\"trt.vs.ctrl\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE df t.ratio p.value\n A - K        1.63 0.69 36   2.361  0.0633\n B - K        4.32 0.69 36   6.270  <.0001\n C - K        9.29 0.69 36  13.464  <.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: dunnettx method for 3 tests \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrast(emmeans(mod1, ~DM), adjust = \"sidak\", method=\"pairwise\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE df t.ratio p.value\n K - A       -1.63 0.69 36  -2.361  0.1343\n K - B       -4.32 0.69 36  -6.270  <.0001\n K - C       -9.29 0.69 36 -13.464  <.0001\n A - B       -2.70 0.69 36  -3.909  0.0024\n A - C       -7.66 0.69 36 -11.103  <.0001\n B - C       -4.96 0.69 36  -7.194  <.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 6 tests \n```\n\n\n:::\n\n```{.r .cell-code}\ncontrast(emmeans(mod1, ~DM), adjust = \"sidak\", method=\"trt.vs.ctrl\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast estimate   SE df t.ratio p.value\n A - K        1.63 0.69 36   2.361  0.0696\n B - K        4.32 0.69 36   6.270  <.0001\n C - K        9.29 0.69 36  13.464  <.0001\n\nNote: contrasts are still on the sqrt scale. Consider using\n      regrid() if you want contrasts of back-transformed estimates. \nP value adjustment: sidak method for 3 tests \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nCIs=cld(emmeans(mod1, ~DM, type = \"response\" ), adjust = \"sidak\", sort = FALSE, Letters=letters)\nCIs$.group # hier sind noch Leerzeichen enthalten, die die Zentrierung der Buchstaben erschwert\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \" a  \" \" a  \" \"  b \" \"   c\"\n```\n\n\n:::\n\n```{.r .cell-code}\nCIs$.group =gsub(\" \", \"\", CIs$.group, fixed = TRUE)# entfernen der Leerzeichen\nCIs$.group # besser\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"a\" \"a\" \"b\" \"c\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(CIs)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'summary_emm' and 'data.frame':\t4 obs. of  7 variables:\n $ DM      : Factor w/ 4 levels \"K\",\"A\",\"B\",\"C\": 1 2 3 4\n $ response: num  96.1 130.6 199.5 364.3\n $ SE      : num  9.56 11.15 13.78 18.62\n $ df      : num  36 36 36 36\n $ lower.CL: num  72.6 103 165 317.1\n $ upper.CL: num  123 161 237 415\n $ .group  : chr  \"a\" \"a\" \"b\" \"c\"\n - attr(*, \"estName\")= chr \"response\"\n - attr(*, \"clNames\")= chr [1:2] \"lower.CL\" \"upper.CL\"\n - attr(*, \"pri.vars\")= chr \"DM\"\n - attr(*, \"adjust\")= chr \"sidak\"\n - attr(*, \"side\")= num 0\n - attr(*, \"delta\")= num 0\n - attr(*, \"type\")= chr \"response\"\n - attr(*, \"mesg\")= chr [1:7] \"Confidence level used: 0.95\" \"Conf-level adjustment: sidak method for 4 estimates\" \"Intervals are back-transformed from the sqrt scale\" \"Note: contrasts are still on the sqrt scale. Consider using\\n      regrid() if you want contrasts of back-trans\"| __truncated__ ...\n - attr(*, \"linkname\")= chr \"sqrt\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(g, aes(x=DM, y=BM)) +\n  stat_boxplot(geom =\"errorbar\", width = 0.5)+\n  geom_boxplot(outlier.shape=NA, width = 0.6) +\n  geom_jitter(width=0.25, height=0, shape=1)+\n  geom_point(data=CIs, aes(y=response), \n             shape=16,  size=2, col=2, \n             position = position_nudge(x = 0.4))+\n  geom_errorbar(data=CIs, aes(y=response, ymin=lower.CL, ymax=upper.CL), \n                width=0.1, col=2, position = position_nudge(x = 0.4))+\n  geom_text(data=CIs, aes(y = 550, label =.group))+\n  theme_bw() +\n  scale_y_sqrt(breaks=c(50, 100,200,300,400,500))+\n  ylab(\"Biomasse (g)\")+\n  xlab(\"Düngemittel\")\n```\n\n::: {.cell-output-display}\n![](04_Anova_files/figure-html/unnamed-chunk-51-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\nEnde Übung 4\n",
    "supporting": [
      "04_Anova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}